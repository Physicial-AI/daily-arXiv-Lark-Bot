<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 18]
- [cs.RO](#cs.RO) [Total: 15]
- [cs.LG](#cs.LG) [Total: 18]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [VISION-ICE: Video-based Interpretation and Spatial Identification of Arrhythmia Origins via Neural Networks in Intracardiac Echocardiography](https://arxiv.org/abs/2602.20165)
*Dorsa EPMoghaddam,Feng Gao,Drew Bernard,Kavya Sinha,Mehdi Razavi,Behnaam Aazhang*

Main category: cs.CV

TL;DR: 本文提出了一种基于AI的框架，利用心内超声（ICE）视频数据，通过3D卷积神经网络进行三类分类（正常窦性心律、左侧心律失常、右侧心律失常），实现心律失常的自动定位，以指导临床医生进行靶向电生理干预。


<details>
  <summary>Details</summary>
Motivation: 目前高密度标测技术和术前CT/MRI在定位心律失常方面耗时且资源密集。AI已被验证可作为超声心动图图像的快速实时分析临床决策辅助。基于此，作者希望利用电生理手术常规部分的心内超声（ICE），开发AI框架来指导临床医生定位心律失常起源区域，减少手术时间。

Method: 将心律失常源定位制定为三类分类任务：正常窦性心律、左侧心律失常和右侧心律失常。基于ICE视频数据，开发了一个3D卷积神经网络来区分这三类。在十折交叉验证中，对四名未见过的患者进行评估。

Result: 模型在十折交叉验证中达到平均准确率66.2%，显著优于33.3%的随机基线。这表明利用ICE视频结合深度学习进行自动心律失常定位具有可行性和临床前景。

Conclusion: 利用ICE成像可以实现更快、更靶向的电生理干预，减少心脏消融手术负担。未来工作将集中于扩展数据集以提高模型在不同患者群体中的鲁棒性和泛化能力。

Abstract: Contemporary high-density mapping techniques and preoperative CT/MRI remain time and resource intensive in localizing arrhythmias. AI has been validated as a clinical decision aid in providing accurate, rapid real-time analysis of echocardiographic images. Building on this, we propose an AI-enabled framework that leverages intracardiac echocardiography (ICE), a routine part of electrophysiology procedures, to guide clinicians toward areas of arrhythmogenesis and potentially reduce procedural time. Arrhythmia source localization is formulated as a three-class classification task, distinguishing normal sinus rhythm, left-sided, and right-sided arrhythmias, based on ICE video data. We developed a 3D Convolutional Neural Network trained to discriminate among the three aforementioned classes. In ten-fold cross-validation, the model achieved a mean accuracy of 66.2% when evaluated on four previously unseen patients (substantially outperforming the 33.3% random baseline). These results demonstrate the feasibility and clinical promise of using ICE videos combined with deep learning for automated arrhythmia localization. Leveraging ICE imaging could enable faster, more targeted electrophysiological interventions and reduce the procedural burden of cardiac ablation. Future work will focus on expanding the dataset to improve model robustness and generalizability across diverse patient populations.

</details>


### [2] [OTPrune: Distribution-Aligned Visual Token Pruning via Optimal Transport](https://arxiv.org/abs/2602.20205)
*Xiwen Chen,Wenhui Zhu,Gen Li,Xuanzhao Dong,Yujian Xiong,Hao Wang,Peijie Qiu,Qingquan Song,Zhipeng Wang,Shao Tang,Yalin Wang,Abolfazl Razi*

Main category: cs.CV

TL;DR: OTPrune：一种基于最优传输的无训练视觉令牌剪枝框架，通过分布对齐实现推理加速，在保持语义准确性的同时提升效率。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型存在推理成本高的问题，现有视觉令牌剪枝方法忽视了视觉表示的分布结构，需要更有效的剪枝方法。

Method: 提出OTPrune框架，将剪枝建模为通过最优传输进行分布对齐的问题，最小化完整令牌与剪枝后令牌分布之间的2-Wasserstein距离，并推导出可处理的次模优化目标。

Result: 在多个基准测试中，OTPrune在性能-效率权衡方面优于现有方法，实现了更稳定的剪枝效果。

Conclusion: OTPrune通过分布对齐为视觉令牌剪枝提供了理论基础，实现了高效且语义保持的推理加速。

Abstract: Multi-modal large language models (MLLMs) achieve strong visual-language reasoning but suffer from high inference cost due to redundant visual tokens. Recent work explores visual token pruning to accelerate inference, while existing pruning methods overlook the underlying distributional structure of visual representations. We propose OTPrune, a training-free framework that formulates pruning as distribution alignment via optimal transport (OT). By minimizing the 2-Wasserstein distance between the full and pruned token distributions, OTPrune preserves both local diversity and global representativeness while reducing inference cost. Moreover, we derive a tractable submodular objective that enables efficient optimization, and theoretically prove its monotonicity and submodularity, providing a principled foundation for stable and efficient pruning. We further provide a comprehensive analysis that explains how distributional alignment contributes to stable and semantically faithful pruning. Comprehensive experiments on wider benchmarks demonstrate that OTPrune achieves superior performance-efficiency tradeoffs compared to state-of-the-art methods. The code is available at https://github.com/xiwenc1/OTPrune.

</details>


### [3] [De-rendering, Reasoning, and Repairing Charts with Vision-Language Models](https://arxiv.org/abs/2602.20291)
*Valentin Bonas,Martin Sinnona,Viviana Siless,Emmanuel Iarussi*

Main category: cs.CV

TL;DR: 提出一个结合图表反渲染、自动分析和迭代改进的框架，为可视化设计提供可操作、可解释的反馈，通过LLM驱动的推荐系统提升可视化质量和用户设计素养。


<details>
  <summary>Details</summary>
Motivation: 当前数据可视化常出现错误，但基于规则的检查工具缺乏上下文且无法提供有意义的改进建议，而通用LLM在可视化质量评估上不可靠，需要系统化的解决方案。

Method: 框架包含三个核心组件：1）从图像重建图表结构（反渲染）；2）使用视觉-语言推理识别设计缺陷；3）基于可视化研究原则提出具体修改建议，并支持用户选择性应用和重新渲染。

Result: 在Chart2Code基准的1000个图表上测试，系统生成了10452条设计建议，聚类为10个连贯类别（如轴格式化、颜色可访问性、图例一致性），验证了系统有效性。

Conclusion: LLM驱动的推荐系统能够为可视化设计提供结构化、基于原则的反馈，为开发更智能、易用的可视化创作工具开辟了新途径。

Abstract: Data visualizations are central to scientific communication, journalism, and everyday decision-making, yet they are frequently prone to errors that can distort interpretation or mislead audiences. Rule-based visualization linters can flag violations, but they miss context and do not suggest meaningful design changes. Directly querying general-purpose LLMs about visualization quality is unreliable: lacking training to follow visualization design principles, they often produce inconsistent or incorrect feedback. In this work, we introduce a framework that combines chart de-rendering, automated analysis, and iterative improvement to deliver actionable, interpretable feedback on visualization design. Our system reconstructs the structure of a chart from an image, identifies design flaws using vision-language reasoning, and proposes concrete modifications supported by established principles in visualization research. Users can selectively apply these improvements and re-render updated figures, creating a feedback loop that promotes both higher-quality visualizations and the development of visualization literacy. In our evaluation on 1,000 charts from the Chart2Code benchmark, the system generated 10,452 design recommendations, which clustered into 10 coherent categories (e.g., axis formatting, color accessibility, legend consistency). These results highlight the promise of LLM-driven recommendation systems for delivering structured, principle-based feedback on visualization design, opening the door to more intelligent and accessible authoring tools.

</details>


### [4] [N4MC: Neural 4D Mesh Compression](https://arxiv.org/abs/2602.20312)
*Guodong Chen,Huanshuo Dong,Mallesham Dasari*

Main category: cs.CV

TL;DR: N4MC是首个4D神经压缩框架，通过利用时间冗余来高效压缩时变网格序列，在率失真性能上优于现有方法并支持实时解码。


<details>
  <summary>Details</summary>
Motivation: 现有神经网格压缩方法独立处理每一帧网格，未能充分利用时变网格序列中的时间冗余。受2D视频编解码器中帧间压缩的启发，需要开发能够学习长网格序列中运动补偿的压缩方法。

Method: 1.将连续的不规则网格帧转换为规则的4D张量以提供统一紧凑表示；2.使用自动解码器压缩这些张量，捕捉空间和时间相关性以消除冗余；3.引入基于Transformer的插值模型，通过跟踪体积中心的潜在嵌入预测中间网格帧，消除运动模糊性。

Result: N4MC在率失真性能上优于现有最先进方法，同时能够实现4D网格序列的实时解码。代码已在GitHub开源。

Conclusion: N4MC是首个利用时间冗余的4D神经网格压缩框架，通过将不规则网格转换为4D张量、使用自动解码器压缩以及引入Transformer插值模型，实现了优越的压缩性能和实时解码能力。

Abstract: We present N4MC, the first 4D neural compression framework to efficiently compress time-varying mesh sequences by exploiting their temporal redundancy. Unlike prior neural mesh compression methods that treat each mesh frame independently, N4MC takes inspiration from inter-frame compression in 2D video codecs, and learns motion compensation in long mesh sequences. Specifically, N4MC converts consecutive irregular mesh frames into regular 4D tensors to provide a uniform and compact representation. These tensors are then condensed using an auto-decoder, which captures both spatial and temporal correlations for redundancy removal. To enhance temporal coherence, we introduce a transformer-based interpolation model that predicts intermediate mesh frames conditioned on latent embeddings derived from tracked volume centers, eliminating motion ambiguities. Extensive evaluations show that N4MC outperforms state-of-the-art in rate-distortion performance, while enabling real-time decoding of 4D mesh sequences. The implementation of our method is available at: https://github.com/frozzzen3/N4MC.

</details>


### [5] [GSNR: Graph Smooth Null-Space Representation for Inverse Problems](https://arxiv.org/abs/2602.20328)
*Romario Gualdrón-Hurtado,Roman Jacome,Rafael S. Suarez,Henry Arguello*

Main category: cs.CV

TL;DR: 该论文提出了一种名为GSNR的方法，通过图拉普拉斯算子构建空域受限拉普拉斯矩阵，利用最平滑的谱图模式来约束逆问题中的不可见分量，从而提升图像重建质量。


<details>
  <summary>Details</summary>
Motivation: 图像逆问题由于感知矩阵存在非平凡零空间而具有病态性，传统图像先验（如稀疏性、平滑性或得分函数）无法约束零空间分量，可能导致重建结果偏差。因此需要将有意义的零空间信息纳入重建框架。

Method: 提出图平滑零空间表示(GSNR)：基于图平滑图像表示，给定图拉普拉斯算子，构建空域受限拉普拉斯矩阵，编码零空间信号中相邻像素的相似性，并设计从最平滑谱图模式（最低图频率）到低维投影矩阵的方法。

Result: GSNR方法在图像去模糊、压缩感知、去马赛克和图像超分辨率四种场景中，结合PnP、DIP和扩散求解器等逆问题求解器，相比基线方法PSNR提升达4.3dB，相比端到端学习模型提升达1dB。

Conclusion: GSNR通过约束逆问题中的零空间分量，提供理论支撑和实践改进，包括改进收敛性、更好的覆盖范围和高预测性，显著提升图像重建质量。

Abstract: Inverse problems in imaging are ill-posed, leading to infinitely many solutions consistent with the measurements due to the non-trivial null-space of the sensing matrix. Common image priors promote solutions on the general image manifold, such as sparsity, smoothness, or score function. However, as these priors do not constrain the null-space component, they can bias the reconstruction. Thus, we aim to incorporate meaningful null-space information in the reconstruction framework. Inspired by smooth image representation on graphs, we propose Graph-Smooth Null-Space Representation (GSNR), a mechanism that imposes structure only into the invisible component. Particularly, given a graph Laplacian, we construct a null-restricted Laplacian that encodes similarity between neighboring pixels in the null-space signal, and we design a low-dimensional projection matrix from the $p$-smoothest spectral graph modes (lowest graph frequencies). This approach has strong theoretical and practical implications: i) improved convergence via a null-only graph regularizer, ii) better coverage, how much null-space variance is captured by $p$ modes, and iii) high predictability, how well these modes can be inferred from the measurements. GSNR is incorporated into well-known inverse problem solvers, e.g., PnP, DIP, and diffusion solvers, in four scenarios: image deblurring, compressed sensing, demosaicing, and image super-resolution, providing consistent improvement of up to 4.3 dB over baseline formulations and up to 1 dB compared with end-to-end learned models in terms of PSNR.

</details>


### [6] [3DSPA: A 3D Semantic Point Autoencoder for Evaluating Video Realism](https://arxiv.org/abs/2602.20354)
*Bhavik Chandna,Kelsey R. Allen*

Main category: cs.CV

TL;DR: 3DSPA是一个用于自动评估视频真实性的框架，它结合3D点轨迹、深度线索和语义特征，无需参考视频即可检测物理规律违反和运动伪影。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型的真实性评估主要依赖人工标注或特定数据集，这些方法范围有限且效率低下。需要一种自动化的评估框架来捕捉视频的语义和连贯3D结构，以更全面地评估生成视频的真实性。

Method: 提出3DSPA（3D时空点自编码器），将3D点轨迹、深度线索和DINO语义特征整合到统一表示中。该方法建模物体运动和场景内容，支持对真实性、时间一致性和物理合理性的鲁棒评估。

Result: 实验表明，3DSPA能可靠识别违反物理规律的视频，对运动伪影更敏感，在多个数据集上与人类对视频质量和真实性的判断更一致。

Conclusion: 将3D语义信息融入轨迹表示，为生成视频模型的基准测试提供了更强的基础，并能隐式捕捉物理规则违反。该方法为自动化视频真实性评估提供了有效解决方案。

Abstract: AI video generation is evolving rapidly. For video generators to be useful for applications ranging from robotics to film-making, they must consistently produce realistic videos. However, evaluating the realism of generated videos remains a largely manual process -- requiring human annotation or bespoke evaluation datasets which have restricted scope. Here we develop an automated evaluation framework for video realism which captures both semantics and coherent 3D structure and which does not require access to a reference video. Our method, 3DSPA, is a 3D spatiotemporal point autoencoder which integrates 3D point trajectories, depth cues, and DINO semantic features into a unified representation for video evaluation. 3DSPA models how objects move and what is happening in the scene, enabling robust assessments of realism, temporal consistency, and physical plausibility. Experiments show that 3DSPA reliably identifies videos which violate physical laws, is more sensitive to motion artifacts, and aligns more closely with human judgments of video quality and realism across multiple datasets. Our results demonstrate that enriching trajectory-based representations with 3D semantics offers a stronger foundation for benchmarking generative video models, and implicitly captures physical rule violations. The code and pretrained model weights will be available at https://github.com/TheProParadox/3dspa_code.

</details>


### [7] [LESA: Learnable Stage-Aware Predictors for Diffusion Model Acceleration](https://arxiv.org/abs/2602.20497)
*Peiliang Cai,Jiacheng Liu,Haowen Xu,Xinyu Wang,Chang Zou,Linfeng Zhang*

Main category: cs.CV

TL;DR: 本文提出LEarnable Stage-Aware (LESA)预测器框架，通过两阶段训练解决扩散模型中特征缓存加速时难以适应复杂阶段依赖动态的问题，在保持高质量生成的同时实现显著加速。


<details>
  <summary>Details</summary>
Motivation: 扩散变换器(DiTs)的高计算需求限制了实际部署。现有基于简单重用或无训练预测的特征缓存方法难以适应扩散过程的复杂阶段依赖动态，常导致质量下降且无法保持标准去噪过程的一致性。

Method: 提出可学习的阶段感知(LESA)预测器框架，采用两阶段训练。利用Kolmogorov-Arnold Network (KAN)从数据中准确学习时间特征映射，并引入多阶段多专家架构，为不同噪声水平阶段分配专门的预测器，实现更精确和鲁棒的特征预测。

Result: 在多个模型上实现显著加速：FLUX.1-dev上5.00倍加速且质量仅下降1.0%；Qwen-Image上6.25倍加速且质量比前SOTA(TaylorSeer)提升20.2%；HunyuanVideo上5.00倍加速且PSNR比TaylorSeer提升24.7%。在文本到图像和文本到视频合成上均达到最先进性能。

Conclusion: LESA框架通过基于训练的方法有效解决了扩散模型加速中的特征缓存问题，在保持高保真生成的同时实现显著加速，验证了该框架在不同模型上的有效性和泛化能力。

Abstract: Diffusion models have achieved remarkable success in image and video generation tasks. However, the high computational demands of Diffusion Transformers (DiTs) pose a significant challenge to their practical deployment. While feature caching is a promising acceleration strategy, existing methods based on simple reusing or training-free forecasting struggle to adapt to the complex, stage-dependent dynamics of the diffusion process, often resulting in quality degradation and failing to maintain consistency with the standard denoising process. To address this, we propose a LEarnable Stage-Aware (LESA) predictor framework based on two-stage training. Our approach leverages a Kolmogorov-Arnold Network (KAN) to accurately learn temporal feature mappings from data. We further introduce a multi-stage, multi-expert architecture that assigns specialized predictors to different noise-level stages, enabling more precise and robust feature forecasting. Extensive experiments show our method achieves significant acceleration while maintaining high-fidelity generation. Experiments demonstrate 5.00x acceleration on FLUX.1-dev with minimal quality degradation (1.0% drop), 6.25x speedup on Qwen-Image with a 20.2% quality improvement over the previous SOTA (TaylorSeer), and 5.00x acceleration on HunyuanVideo with a 24.7% PSNR improvement over TaylorSeer. State-of-the-art performance on both text-to-image and text-to-video synthesis validates the effectiveness and generalization capability of our training-based framework across different models. Our code is included in the supplementary materials and will be released on GitHub.

</details>


### [8] [WildGHand: Learning Anti-Perturbation Gaussian Hand Avatars from Monocular In-the-Wild Videos](https://arxiv.org/abs/2602.20556)
*Hanhui Li,Xuan Huang,Wanquan Liu,Yuhao Cheng,Long Chen,Yiqiang Yan,Xiaodan Liang,Chenqiang Gao*

Main category: cs.CV

TL;DR: WildGHand是一个优化框架，通过动态扰动解耦模块和扰动感知优化策略，在野外单目视频中进行自适应的3D高斯泼溅，实现高质量3D手部重建。


<details>
  <summary>Details</summary>
Motivation: 现有3D手部重建方法在受控环境下表现良好，但在真实世界场景中（如手物交互、极端姿态、光照变化、运动模糊等扰动下）性能会显著下降。需要一种能在野外视频中鲁棒重建高质量3D手部化身的方法。

Method: 提出WildGHand框架，包含两个关键组件：1) 动态扰动解耦模块，将扰动表示为3D高斯属性上的时变偏差；2) 扰动感知优化策略，生成逐帧各向异性加权掩码来指导优化。这些组件共同在空间和时间维度上识别和抑制扰动。

Result: 在自建数据集和两个公共数据集上的实验表明，WildGHand达到最先进性能，相比基础模型在多个指标上显著提升（如PSNR相对增益达15.8%，LPIPS相对减少23.1%）。

Conclusion: WildGHand通过显式建模扰动并采用扰动感知优化，成功解决了野外视频中3D手部重建的挑战，实现了高质量的手部化身生成，为真实世界应用提供了有效解决方案。

Abstract: Despite recent progress in 3D hand reconstruction from monocular videos, most existing methods rely on data captured in well-controlled environments and therefore degrade in real-world settings with severe perturbations, such as hand-object interactions, extreme poses, illumination changes, and motion blur. To tackle these issues, we introduce WildGHand, an optimization-based framework that enables self-adaptive 3D Gaussian splatting on in-the-wild videos and produces high-fidelity hand avatars. WildGHand incorporates two key components: (i) a dynamic perturbation disentanglement module that explicitly represents perturbations as time-varying biases on 3D Gaussian attributes during optimization, and (ii) a perturbation-aware optimization strategy that generates per-frame anisotropic weighted masks to guide optimization. Together, these components allow the framework to identify and suppress perturbations across both spatial and temporal dimensions. We further curate a dataset of monocular hand videos captured under diverse perturbations to benchmark in-the-wild hand avatar reconstruction. Extensive experiments on this dataset and two public datasets demonstrate that WildGHand achieves state-of-the-art performance and substantially improves over its base model across multiple metrics (e.g., up to a $15.8\%$ relative gain in PSNR and a $23.1\%$ relative reduction in LPIPS). Our implementation and dataset are available at https://github.com/XuanHuang0/WildGHand.

</details>


### [9] [Efficient and Explainable End-to-End Autonomous Driving via Masked Vision-Language-Action Diffusion](https://arxiv.org/abs/2602.20577)
*Jiaru Zhang,Manav Gagvani,Can Cui,Juntong Peng,Ruqi Zhang,Ziran Wang*

Main category: cs.CV

TL;DR: MVLAD-AD是一个用于自动驾驶的掩码视觉-语言-动作扩散框架，通过离散动作标记化和几何感知嵌入学习，实现高效规划与语义可解释性


<details>
  <summary>Details</summary>
Motivation: 当前LLMs和VLMs在自动驾驶中存在推理延迟、动作精度和可解释性挑战，现有自回归方法生成慢，扩散方法缺乏显式几何结构

Method: 提出掩码视觉-语言-动作扩散模型，采用离散动作标记化策略构建紧凑的动力学可行路径点码本，几何感知嵌入学习确保潜在空间嵌入近似物理几何度量，动作优先解码策略优先生成轨迹

Result: 在nuScenes及其衍生基准测试中，MVLAD-AD在规划精度上优于最先进的自回归和扩散基线，同时提供高保真和可解释的推理

Conclusion: MVLAD-AD通过创新的动作标记化和几何感知学习，成功平衡了自动驾驶规划的效率与可解释性，为端到端自动驾驶提供了有前景的解决方案

Abstract: Large Language Models (LLMs) and Vision-Language Models (VLMs) have emerged as promising candidates for end-to-end autonomous driving. However, these models typically face challenges in inference latency, action precision, and explainability. Existing autoregressive approaches struggle with slow token-by-token generation, while prior diffusion-based planners often rely on verbose, general-purpose language tokens that lack explicit geometric structure. In this work, we propose Masked Vision-Language-Action Diffusion for Autonomous Driving (MVLAD-AD), a novel framework designed to bridge the gap between efficient planning and semantic explainability via a masked vision-language-action diffusion model. Unlike methods that force actions into the language space, we introduce a discrete action tokenization strategy that constructs a compact codebook of kinematically feasible waypoints from real-world driving distributions. Moreover, we propose geometry-aware embedding learning to ensure that embeddings in the latent space approximate physical geometric metrics. Finally, an action-priority decoding strategy is introduced to prioritize trajectory generation. Extensive experiments on nuScenes and derived benchmarks demonstrate that MVLAD-AD achieves superior efficiency and outperforms state-of-the-art autoregressive and diffusion baselines in planning precision, while providing high-fidelity and explainable reasoning.

</details>


### [10] [PropFly: Learning to Propagate via On-the-Fly Supervision from Pre-trained Video Diffusion Models](https://arxiv.org/abs/2602.20583)
*Wonyong Seo,Jaeho Moon,Jaehyup Lee,Soo Ye Kim,Munchurl Kim*

Main category: cs.CV

TL;DR: PropFly：一种无需成对视频编辑数据集的训练管道，通过预训练视频扩散模型生成即时监督，学习传播式视频编辑。


<details>
  <summary>Details</summary>
Motivation: 现有的传播式视频编辑方法需要大规模成对的（原始和编辑后）视频数据集进行训练，这些数据集获取成本高且复杂。因此需要一种不依赖现成或预计算成对视频编辑数据集的训练方法。

Method: 提出PropFly训练管道，利用预训练视频扩散模型（VDMs）的即时监督：通过不同分类器自由引导（CFG）尺度的一步干净潜在估计，动态生成多样化的"源"（低CFG）和"编辑"（高CFG）潜在对。源潜在提供视频结构信息，编辑潜在提供目标变换。通过附加适配器和引导调制流匹配（GMFM）损失学习编辑传播。

Result: 在多个视频编辑任务上显著优于最先进方法，产生高质量的编辑结果，模型能够学习时间一致且动态的变换。

Conclusion: PropFly通过预训练视频扩散模型的即时监督，无需成对视频编辑数据集即可有效训练传播式视频编辑模型，在保持原始视频结构和运动的同时实现精确的编辑传播。

Abstract: Propagation-based video editing enables precise user control by propagating a single edited frame into following frames while maintaining the original context such as motion and structures. However, training such models requires large-scale, paired (source and edited) video datasets, which are costly and complex to acquire. Hence, we propose the PropFly, a training pipeline for Propagation-based video editing, relying on on-the-Fly supervision from pre-trained video diffusion models (VDMs) instead of requiring off-the-shelf or precomputed paired video editing datasets. Specifically, our PropFly leverages one-step clean latent estimations from intermediate noised latents with varying Classifier-Free Guidance (CFG) scales to synthesize diverse pairs of 'source' (low-CFG) and 'edited' (high-CFG) latents on-the-fly. The source latent serves as structural information of the video, while the edited latent provides the target transformation for learning propagation. Our pipeline enables an additional adapter attached to the pre-trained VDM to learn to propagate edits via Guidance-Modulated Flow Matching (GMFM) loss, which guides the model to replicate the target transformation. Our on-the-fly supervision ensures the model to learn temporally consistent and dynamic transformations. Extensive experiments demonstrate that our PropFly significantly outperforms the state-of-the-art methods on various video editing tasks, producing high-quality editing results.

</details>


### [11] [Large-scale Photorealistic Outdoor 3D Scene Reconstruction from UAV Imagery Using Gaussian Splatting Techniques](https://arxiv.org/abs/2602.20342)
*Christos Maikos,Georgios Angelidis,Georgios Th. Papadopoulos*

Main category: cs.CV

TL;DR: 本文提出了一个端到端管道，能够将无人机捕获的视频流转换为高保真3D重建，并实现最小延迟。该系统结合了RTMP流媒体、传感器融合、相机姿态估计和3DGS优化，适用于实时增强感知和AR/VR应用。


<details>
  <summary>Details</summary>
Motivation: 虽然无人机广泛用于空中实时感知应用，且3D高斯泼溅技术在实时神经渲染方面显示出巨大潜力，但将其集成到端到端的无人机重建和可视化系统中仍未被充分探索。本文旨在填补这一空白。

Method: 提出了一种高效架构，结合了RTMP流媒体实时视频采集、同步传感器融合、相机姿态估计和3D高斯泼溅优化，实现了连续模型更新和在交互式可视化环境中的低延迟部署。

Result: 实验结果表明，与基于NeRF的方法相比，该方法实现了具有竞争力的视觉保真度，同时显著提高了渲染性能并大幅降低了端到端延迟。重建质量保持在离线高保真参考的4-7%范围内。

Conclusion: 所提出的系统适用于从空中平台进行实时、可扩展的增强感知，为AR/VR应用提供了有效的解决方案。

Abstract: In this study, we present an end-to-end pipeline capable of converting drone-captured video streams into high-fidelity 3D reconstructions with minimal latency. Unmanned aerial vehicles (UAVs) are extensively used in aerial real-time perception applications. Moreover, recent advances in 3D Gaussian Splatting (3DGS) have demonstrated significant potential for real-time neural rendering. However, their integration into end-to-end UAV-based reconstruction and visualization systems remains underexplored. Our goal is to propose an efficient architecture that combines live video acquisition via RTMP streaming, synchronized sensor fusion, camera pose estimation, and 3DGS optimization, achieving continuous model updates and low-latency deployment within interactive visualization environments that supports immersive augmented and virtual reality (AR/VR) applications. Experimental results demonstrate that the proposed method achieves competitive visual fidelity, while delivering significantly higher rendering performance and substantially reduced end-to-end latency, compared to NeRF-based approaches. Reconstruction quality remains within 4-7\% of high-fidelity offline references, confirming the suitability of the proposed system for real-time, scalable augmented perception from aerial platforms.

</details>


### [12] [VAGNet: Grounding 3D Affordance from Human-Object Interactions in Videos](https://arxiv.org/abs/2602.20608)
*Aihua Mao,Kaihang Huang,Yong-Jin Liu,Chee Seng Chan,Ying He*

Main category: cs.CV

TL;DR: 论文提出视频引导的3D物体功能感知定位，利用动态交互序列解决静态方法无法处理的功能歧义问题，并构建了首个HOI视频-3D配对数据集PVAD。


<details>
  <summary>Details</summary>
Motivation: 现有3D物体功能感知定位方法依赖静态视觉或文本线索，但功能本质由动态动作定义，导致难以准确定位真实交互接触区域。人类通过观察和模仿动作学习使用物体，而非仅靠形状分析。

Method: 提出VAGNet框架，将视频提取的交互线索与3D结构对齐，解决静态线索无法处理的歧义问题。同时构建了首个HOI视频-3D配对数据集PVAD，提供先前工作中缺失的功能监督。

Result: 在PVAD数据集上的大量实验表明，VAGNet实现了最先进的性能，显著优于基于静态线索的基线方法。

Conclusion: 通过视频引导的3D功能感知定位，利用动态交互序列提供功能监督，能更准确地定位真实交互接触区域，代码和数据集将公开。

Abstract: 3D object affordance grounding aims to identify regions on 3D objects that support human-object interaction (HOI), a capability essential to embodied visual reasoning. However, most existing approaches rely on static visual or textual cues, neglecting that affordances are inherently defined by dynamic actions. As a result, they often struggle to localize the true contact regions involved in real interactions. We take a different perspective. Humans learn how to use objects by observing and imitating actions, not just by examining shapes. Motivated by this intuition, we introduce video-guided 3D affordance grounding, which leverages dynamic interaction sequences to provide functional supervision. To achieve this, we propose VAGNet, a framework that aligns video-derived interaction cues with 3D structure to resolve ambiguities that static cues cannot address. To support this new setting, we introduce PVAD, the first HOI video-3D pairing affordance dataset, providing functional supervision unavailable in prior works. Extensive experiments on PVAD show that VAGNet achieves state-of-the-art performance, significantly outperforming static-based baselines. The code and dataset will be open publicly.

</details>


### [13] [Vision-Language Models for Ergonomic Assessment of Manual Lifting Tasks: Estimating Horizontal and Vertical Hand Distances from RGB Video](https://arxiv.org/abs/2602.20658)
*Mohammad Sadra Rajabi,Aanuoluwapo Ojelade,Sunwook Kim,Maury A. Nussbaum*

Main category: cs.CV

TL;DR: 研究评估了使用视觉语言模型从RGB视频流中非侵入式估计NIOSH举升方程中水平(H)和垂直(V)手部距离的可行性，开发了两种多阶段VLM流程，分割式多视角流程表现最佳。


<details>
  <summary>Details</summary>
Motivation: 手动举升任务是工作相关肌肉骨骼疾病的主要原因，需要有效的工效学风险评估。NIOSH举升方程依赖于六个任务变量，包括水平和垂直手部距离，这些距离通常通过手动测量或专业传感系统获取，在实际环境中难以使用。

Method: 开发了两种多阶段视觉语言模型流程：文本引导的仅检测流程和检测加分割流程。两种流程都使用文本引导定位感兴趣区域，从这些区域提取视觉特征，并使用基于transformer的时间回归来估计举升开始和结束时的H和V值。

Result: 结果因流程和相机视角条件而异，分割式多视角流程表现最稳定，估计H的平均绝对误差约为6-8厘米，V为5-8厘米。像素级分割将估计误差相对于仅检测流程降低了约20-30%（H）和35-40%（V）。

Conclusion: 研究结果支持基于VLM的流程用于视频估计RNLE距离参数的可行性，分割式多视角方法在准确性和稳定性方面表现最佳。

Abstract: Manual lifting tasks are a major contributor to work-related musculoskeletal disorders, and effective ergonomic risk assessment is essential for quantifying physical exposure and informing ergonomic interventions. The Revised NIOSH Lifting Equation (RNLE) is a widely used ergonomic risk assessment tool for lifting tasks that relies on six task variables, including horizontal (H) and vertical (V) hand distances; such distances are typically obtained through manual measurement or specialized sensing systems and are difficult to use in real-world environments. We evaluated the feasibility of using innovative vision-language models (VLMs) to non-invasively estimate H and V from RGB video streams. Two multi-stage VLM-based pipelines were developed: a text-guided detection-only pipeline and a detection-plus-segmentation pipeline. Both pipelines used text-guided localization of task-relevant regions of interest, visual feature extraction from those regions, and transformer-based temporal regression to estimate H and V at the start and end of a lift. For a range of lifting tasks, estimation performance was evaluated using leave-one-subject-out validation across the two pipelines and seven camera view conditions. Results varied significantly across pipelines and camera view conditions, with the segmentation-based, multi-view pipeline consistently yielding the smallest errors, achieving mean absolute errors of approximately 6-8 cm when estimating H and 5-8 cm when estimating V. Across pipelines and camera view configurations, pixel-level segmentation reduced estimation error by approximately 20-30% for H and 35-40% for V relative to the detection-only pipeline. These findings support the feasibility of VLM-based pipelines for video-based estimation of RNLE distance parameters.

</details>


### [14] [AnimeAgent: Is the Multi-Agent via Image-to-Video models a Good Disney Storytelling Artist?](https://arxiv.org/abs/2602.20664)
*Hailong Yan,Shice Liu,Tao Wang,Xiangtao Zhang,Yijie Zhong,Jinwei Chen,Le Zhang,Bo Li*

Main category: cs.CV

TL;DR: AnimeAgent：首个基于图像到视频（I2V）的多智能体框架，用于定制故事板生成，解决了现有静态扩散模型在动态表现力、迭代修正和评估方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前基于静态扩散模型的故事板生成方法存在三个关键问题：1）静态模型缺乏动态表现力，常出现"复制粘贴"模式；2）一次性推理无法迭代修正缺失属性或提示词遵从度差的问题；3）多智能体框架依赖不稳健的评估器，不适合评估风格化、非现实动画。

Method: 提出AnimeAgent框架，受迪士尼"组合式前进与姿势到姿势"工作流程启发，利用I2V的隐式运动先验来增强一致性和表现力，同时采用混合主观-客观评估器实现可靠的迭代精炼。

Result: 实验表明AnimeAgent在一致性、提示词保真度和风格化方面达到了最先进的性能。团队还收集了带人工标注真实值的故事板生成基准数据集。

Conclusion: AnimeAgent通过结合I2V的运动先验和混合评估机制，有效解决了定制故事板生成中的关键挑战，实现了高质量、多角色一致的故事讲述。

Abstract: Custom Storyboard Generation (CSG) aims to produce high-quality, multi-character consistent storytelling. Current approaches based on static diffusion models, whether used in a one-shot manner or within multi-agent frameworks, face three key limitations: (1) Static models lack dynamic expressiveness and often resort to "copy-paste" pattern. (2) One-shot inference cannot iteratively correct missing attributes or poor prompt adherence. (3) Multi-agents rely on non-robust evaluators, ill-suited for assessing stylized, non-realistic animation. To address these, we propose AnimeAgent, the first Image-to-Video (I2V)-based multi-agent framework for CSG. Inspired by Disney's "Combination of Straight Ahead and Pose to Pose" workflow, AnimeAgent leverages I2V's implicit motion prior to enhance consistency and expressiveness, while a mixed subjective-objective reviewer enables reliable iterative refinement. We also collect a human-annotated CSG benchmark with ground-truth. Experiments show AnimeAgent achieves SOTA performance in consistency, prompt fidelity, and stylization.

</details>


### [15] [LongVideo-R1: Smart Navigation for Low-cost Long Video Understanding](https://arxiv.org/abs/2602.20913)
*Jihao Qiu,Lingxi Xie,Xinyue Huo,Qi Tian,Qixiang Ye*

Main category: cs.CV

TL;DR: LongVideo-R1 是一个用于长视频理解的多模态大语言模型代理，通过推理模块选择信息最丰富的视频片段进行处理，在低计算预算下实现高效视频理解。


<details>
  <summary>Details</summary>
Motivation: 解决长视频理解中计算成本高的问题，避免传统方法对整段视频进行详尽搜索的冗余计算，在有限计算预算下实现高效视频内容理解。

Method: 1. 构建基于推理模块的主动代理，利用高层视觉线索推断最信息丰富的视频片段 2. 从CGBench提取分层视频描述，用GPT-5生成3.3万条高质量思维链轨迹 3. 采用两阶段训练：监督微调(SFT)后接强化学习(RL)，使用专门设计的奖励函数优化片段选择效率

Result: 在多个长视频基准测试中验证了有效性，在问答准确性和计算效率之间取得了优越的平衡。

Conclusion: LongVideo-R1通过主动推理和迭代优化，为低计算预算下的长视频理解提供了有效解决方案，显著提升了计算效率。

Abstract: This paper addresses the critical and underexplored challenge of long video understanding with low computational budgets. We propose LongVideo-R1, an active, reasoning-equipped multimodal large language model (MLLM) agent designed for efficient video context navigation, avoiding the redundancy of exhaustive search. At the core of LongVideo-R1 lies a reasoning module that leverages high-level visual cues to infer the most informative video clip for subsequent processing. During inference, the agent initiates traversal from top-level visual summaries and iteratively refines its focus, immediately halting the exploration process upon acquiring sufficient knowledge to answer the query. To facilitate training, we first extract hierarchical video captions from CGBench, a video corpus with grounding annotations, and guide GPT-5 to generate 33K high-quality chain-of-thought-with-tool trajectories. The LongVideo-R1 agent is fine-tuned upon the Qwen-3-8B model through a two-stage paradigm: supervised fine-tuning (SFT) followed by reinforcement learning (RL), where RL employs a specifically designed reward function to maximize selective and efficient clip navigation. Experiments on multiple long video benchmarks validate the effectiveness of name, which enjoys superior tradeoff between QA accuracy and efficiency. All curated data and source code are provided in the supplementary material and will be made publicly available. Code and data are available at: https://github.com/qiujihao19/LongVideo-R1

</details>


### [16] [From Perception to Action: An Interactive Benchmark for Vision Reasoning](https://arxiv.org/abs/2602.21015)
*Yuhao Wu,Maojia Song,Yihuai Lan,Lei Wang,Zhiqiang Hu,Yao Xiao,Heng Zhou,Weihua Zheng,Dylan Raharja,Soujanya Poria,Roy Ka-Wei Lee*

Main category: cs.CV

TL;DR: CHAIN是一个交互式3D物理驱动基准，用于评估模型理解和规划基于物理约束的结构化动作序列的能力，发现现有模型在物理结构和因果约束理解上仍存在困难。


<details>
  <summary>Details</summary>
Motivation: 现有VLM评估主要关注结构无关的单轮设置（如VQA），无法评估智能体在动态环境中理解几何、接触和支持关系如何共同约束可能动作的能力，需要新的评估框架来填补这一空白。

Method: 引入CHAIN基准，这是一个交互式3D物理驱动测试平台，设计用于评估模型能否理解、规划和执行基于物理约束的结构化动作序列，包括机械拼图和3D堆叠打包等任务。

Result: 对最先进的VLM和基于扩散的模型在统一交互设置下的综合研究表明，表现最佳的模型仍然难以内化物理结构和因果约束，经常无法产生可靠的长时程计划，也无法将感知到的结构稳健地转化为有效动作。

Conclusion: CHAIN基准将评估从被动感知转向主动问题解决，揭示了现有模型在物理推理方面的局限性，为未来模型开发提供了重要的评估框架。

Abstract: Understanding the physical structure is essential for real-world applications such as embodied agents, interactive design, and long-horizon manipulation. Yet, prevailing Vision-Language Model (VLM) evaluations still center on structure-agnostic, single-turn setups (e.g., VQA), which fail to assess agents' ability to reason about how geometry, contact, and support relations jointly constrain what actions are possible in a dynamic environment. To address this gap, we introduce the Causal Hierarchy of Actions and Interactions (CHAIN) benchmark, an interactive 3D, physics-driven testbed designed to evaluate whether models can understand, plan, and execute structured action sequences grounded in physical constraints. CHAIN shifts evaluation from passive perception to active problem solving, spanning tasks such as interlocking mechanical puzzles and 3D stacking and packing. We conduct a comprehensive study of state-of-the-art VLMs and diffusion-based models under unified interactive settings. Our results show that top-performing models still struggle to internalize physical structure and causal constraints, often failing to produce reliable long-horizon plans and cannot robustly translate perceived structure into effective actions. The project is available at https://social-ai-studio.github.io/CHAIN/.

</details>


### [17] [VAUQ: Vision-Aware Uncertainty Quantification for LVLM Self-Evaluation](https://arxiv.org/abs/2602.21054)
*Seongheon Park,Changdae Oh,Hyeong Kyu Choi,Xuefeng Du,Sharon Li*

Main category: cs.CV

TL;DR: VAUQ是一个视觉感知的不确定性量化框架，通过图像信息分数和核心区域掩码策略来增强大视觉语言模型的自我评估能力，减少幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 大视觉语言模型经常产生幻觉，限制了其在现实应用中的安全部署。现有的LLM自我评估方法主要依赖语言先验，不适合评估视觉条件预测，需要一种能显式衡量模型输出对视觉证据依赖程度的评估框架。

Method: 提出VAUQ框架：1) 引入图像信息分数(IS)，捕捉视觉输入带来的预测不确定性减少；2) 采用无监督核心区域掩码策略，放大显著区域的影响；3) 结合预测熵和核心掩码IS，形成无需训练的打分函数来可靠反映答案正确性。

Result: 综合实验表明，VAUQ在多个数据集上持续优于现有的自我评估方法，能够更可靠地反映答案的正确性。

Conclusion: VAUQ通过显式量化模型输出对视觉证据的依赖，为LVLM提供了一种有效的自我评估框架，提高了模型部署的可靠性，减少了幻觉问题。

Abstract: Large Vision-Language Models (LVLMs) frequently hallucinate, limiting their safe deployment in real-world applications. Existing LLM self-evaluation methods rely on a model's ability to estimate the correctness of its own outputs, which can improve deployment reliability; however, they depend heavily on language priors and are therefore ill-suited for evaluating vision-conditioned predictions. We propose VAUQ, a vision-aware uncertainty quantification framework for LVLM self-evaluation that explicitly measures how strongly a model's output depends on visual evidence. VAUQ introduces the Image-Information Score (IS), which captures the reduction in predictive uncertainty attributable to visual input, and an unsupervised core-region masking strategy that amplifies the influence of salient regions. Combining predictive entropy with this core-masked IS yields a training-free scoring function that reliably reflects answer correctness. Comprehensive experiments show that VAUQ consistently outperforms existing self-evaluation methods across multiple datasets.

</details>


### [18] [Circuit Tracing in Vision-Language Models: Understanding the Internal Mechanisms of Multimodal Thinking](https://arxiv.org/abs/2602.20330)
*Jingcheng Yang,Tianhu Xiong,Shengyi Qian,Klara Nahrstedt,Mingyuan Wu*

Main category: cs.CV

TL;DR: 该论文提出了首个用于视觉语言模型(VLMs)的透明电路追踪框架，通过分析多模态推理过程来揭示VLMs的内部工作机制。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型虽然强大，但仍然是黑盒系统，缺乏可解释性。为了理解VLMs如何进行多模态推理，需要开发系统化的分析方法来揭示其内部工作机制。

Method: 采用转换器、属性图和基于注意力的方法，系统地分析VLMs如何层次化地整合视觉和语义概念。通过特征导向和电路修补技术进行验证。

Result: 发现不同的视觉特征电路可以处理数学推理并支持跨模态关联。验证表明这些电路具有因果关系且可控制。

Conclusion: 该框架为构建更可解释和可靠的视觉语言模型奠定了基础，通过电路追踪技术揭示了VLMs的多模态推理机制。

Abstract: Vision-language models (VLMs) are powerful but remain opaque black boxes. We introduce the first framework for transparent circuit tracing in VLMs to systematically analyze multimodal reasoning. By utilizing transcoders, attribution graphs, and attention-based methods, we uncover how VLMs hierarchically integrate visual and semantic concepts. We reveal that distinct visual feature circuits can handle mathematical reasoning and support cross-modal associations. Validated through feature steering and circuit patching, our framework proves these circuits are causal and controllable, laying the groundwork for more explainable and reliable VLMs.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [19] [Global Prior Meets Local Consistency: Dual-Memory Augmented Vision-Language-Action Model for Efficient Robotic Manipulation](https://arxiv.org/abs/2602.20200)
*Zaijing Li,Bing Hu,Rui Shao,Gongwei Chen,Dongmei Jiang,Pengwei Xie,Jianye Hao,Liqiang Nie*

Main category: cs.RO

TL;DR: OptimusVLA通过全局先验记忆和局部一致性记忆解决VLA模型在机器人操作中的推理效率低和鲁棒性差问题，在多个仿真和真实世界基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前分层视觉-语言-动作（VLA）模型在机器人操作中存在两个主要瓶颈：1）推理效率低，由于各向同性噪声先验与目标动作分布之间存在显著分布差距，导致去噪步骤增加和不可行样本增多；2）鲁棒性差，现有策略仅基于当前观察，忽略历史序列约束，缺乏任务进度感知和时间一致性。

Method: 提出OptimusVLA双记忆VLA框架，包含全局先验记忆（GPM）和局部一致性记忆（LCM）。GPM用从语义相似轨迹检索的任务级先验替代高斯噪声，缩短生成路径并减少函数评估次数。LCM动态建模已执行的动作序列以推断任务进度，并注入学习到的一致性约束来强制轨迹的时间连贯性和平滑性。

Result: 在三个仿真基准测试中：LIBERO上平均成功率98.6%，CALVIN上比pi_0提高13.5%，RoboTwin 2.0 Hard上平均成功率38%。在真实世界评估中，在泛化和长时程任务套件上表现最佳，分别超越pi_0 42.9%和52.4%，同时实现2.9倍推理加速。

Conclusion: OptimusVLA通过引入双记忆机制有效解决了VLA模型在动作生成中的效率和鲁棒性问题，在仿真和真实场景中都取得了显著性能提升，为机器人操作任务提供了更高效的解决方案。

Abstract: Hierarchical Vision-Language-Action (VLA) models have rapidly become a dominant paradigm for robotic manipulation. It typically comprising a Vision-Language backbone for perception and understanding, together with a generative policy for action generation. However, its performance is increasingly bottlenecked by the action generation proceess. (i) Low inference efficiency. A pronounced distributional gap between isotropic noise priors and target action distributions, which increases denoising steps and the incidence of infeasible samples. (ii) Poor robustness. Existing policies condition solely on the current observation, neglecting the constraint of history sequence and thus lacking awareness of task progress and temporal consistency. To address these issues, we introduce OptimusVLA, a dual-memory VLA framework with Global Prior Memory (GPM) and Local Consistency Memory (LCM). GPM replaces Gaussian noise with task-level priors retrieved from semantically similar trajectories, thereby shortening the generative path and reducing the umber of function evaluations (NFE). LCM dynamically models executed action sequence to infer task progress and injects a learned consistency constraint that enforces temporal coherence and smoothness of trajectory. Across three simulation benchmarks, OptimusVLA consistently outperforms strong baselines: it achieves 98.6% average success rate on LIBERO, improves over pi_0 by 13.5% on CALVIN, and attains 38% average success rate on RoboTwin 2.0 Hard. In Real-World evaluation, OptimusVLA ranks best on Generalization and Long-horizon suites, surpassing pi_0 by 42.9% and 52.4%, respectively, while delivering 2.9x inference speedup.

</details>


### [20] [Vision-Based Reasoning with Topology-Encoded Graphs for Anatomical Path Disambiguation in Robot-Assisted Endovascular Navigation](https://arxiv.org/abs/2602.20215)
*Jiyuan Zhao,Zhengyu Shi,Wentong Tian,Tianliang Yao,Dong Liu,Tao Liu,Yizhe Wu,Peng Qi*

Main category: cs.RO

TL;DR: 本文提出SCAR-UNet-GAT框架，用于解决机器人辅助PCI中2D DSA图像导致的血管分叉投影模糊问题，实现实时路径规划。


<details>
  <summary>Details</summary>
Motivation: 机器人辅助PCI受限于2D DSA图像，缺乏空间信息和触觉反馈，导致血管分叉处出现投影诱导的模糊性，影响手术精度和安全性。

Method: 采用两阶段框架：1) SCAR-UNet进行血管分割，结合多级注意力机制增强细弯血管识别；2) GAT网络基于血管图推理，融合几何特征和局部DSA信息，识别解剖一致且临床可行的轨迹。

Result: SCAR-UNet Dice系数达93.1%；GAT路径消歧成功率95.0%，目标到达成功率90.0%，显著优于传统最短路径（60.0%/55.0%）和启发式方法（75.0%/70.0%）。机器人平台验证证实了实用可行性。

Conclusion: SCAR-UNet-GAT框架有效解决了机器人PCI中的投影模糊问题，实现了高精度的实时路径规划，为机器人辅助心血管介入提供了可靠的技术支持。

Abstract: Robotic-assisted percutaneous coronary intervention (PCI) is constrained by the inherent limitations of 2D Digital Subtraction Angiography (DSA). Unlike physicians, who can directly manipulate guidewires and integrate tactile feedback with their prior anatomical knowledge, teleoperated robotic systems must rely solely on 2D projections. This mode of operation, simultaneously lacking spatial context and tactile sensation, may give rise to projection-induced ambiguities at vascular bifurcations. To address this challenge, we propose a two-stage framework (SCAR-UNet-GAT) for real-time robotic path planning. In the first stage, SCAR-UNet, a spatial-coordinate-attention-regularized U-Net, is employed for accurate coronary vessel segmentation. The integration of multi-level attention mechanisms enhances the delineation of thin, tortuous vessels and improves robustness against imaging noise. From the resulting binary masks, vessel centerlines and bifurcation points are extracted, and geometric descriptors (e.g., branch diameter, intersection angles) are fused with local DSA patches to construct node features. In the second stage, a Graph Attention Network (GAT) reasons over the vessel graph to identify anatomically consistent and clinically feasible trajectories, effectively distinguishing true bifurcations from projection-induced false crossings. On a clinical DSA dataset, SCAR-UNet achieved a Dice coefficient of 93.1%. For path disambiguation, the proposed GAT-based method attained a success rate of 95.0% and a target-arrival success rate of 90.0%, substantially outperforming conventional shortest-path planning (60.0% and 55.0%) and heuristic-based planning (75.0% and 70.0%). Validation on a robotic platform further confirmed the practical feasibility and robustness of the proposed framework.

</details>


### [21] [Sample-Efficient Learning with Online Expert Correction for Autonomous Catheter Steering in Endovascular Bifurcation Navigation](https://arxiv.org/abs/2602.20216)
*Hao Wang,Tianliang Yao,Bo Lu,Zhiqiang Pei,Liu Dong,Lei Ma,Peng Qi*

Main category: cs.RO

TL;DR: 提出结合在线专家修正的样本高效强化学习框架，用于血管分叉导航中的自主导管操控，相比基线方法训练收敛更快、定位误差更小。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习方法在自主导管操控中存在奖励稀疏、依赖静态血管模型的问题，导致样本效率低且难以适应术中变化。需要解决这些限制以实现高效、鲁棒的血管分叉导航。

Method: 提出三部分框架：1) 基于分割的位姿估计模块提供实时状态反馈；2) 模糊控制器进行分叉感知的方向调整；3) 结合专家先验的结构化奖励生成器指导策略学习。通过在线专家修正提高探索效率。

Result: 在机器人平台上使用透明血管模型验证：仅需123个训练回合即可收敛（比基线SAC算法减少25.9%），平均位置误差降至基线的83.8%。

Conclusion: 结合样本高效强化学习与在线专家修正的框架能够实现可靠、准确的导管操控，特别是在血管分叉等解剖结构复杂的场景中，为血管内导航提供了有效解决方案。

Abstract: Robot-assisted endovascular intervention offers a safe and effective solution for remote catheter manipulation, reducing radiation exposure while enabling precise navigation. Reinforcement learning (RL) has recently emerged as a promising approach for autonomous catheter steering; however, conventional methods suffer from sparse reward design and reliance on static vascular models, limiting their sample efficiency and generalization to intraoperative variations. To overcome these challenges, this paper introduces a sample-efficient RL framework with online expert correction for autonomous catheter steering in endovascular bifurcation navigation. The proposed framework integrates three key components: (1) A segmentation-based pose estimation module for accurate real-time state feedback, (2) A fuzzy controller for bifurcation-aware orientation adjustment, and (3) A structured reward generator incorporating expert priors to guide policy learning. By leveraging online expert correction, the framework reduces exploration inefficiency and enhances policy robustness in complex vascular structures. Experimental validation on a robotic platform using a transparent vascular phantom demonstrates that the proposed approach achieves convergence in 123 training episodes -- a 25.9% reduction compared to the baseline Soft Actor-Critic (SAC) algorithm -- while reducing average positional error to 83.8% of the baseline. These results indicate that combining sample-efficient RL with online expert correction enables reliable and accurate catheter steering, particularly in anatomically challenging bifurcation scenarios critical for endovascular navigation.

</details>


### [22] [An Approach to Combining Video and Speech with Large Language Models in Human-Robot Interaction](https://arxiv.org/abs/2602.20219)
*Guanting Shen,Zi Tian*

Main category: cs.RO

TL;DR: 提出一个结合视觉语言模型、语音处理和模糊逻辑的多模态人机交互框架，用于控制Dobot机械臂，实现通过语音命令进行物体操作，实验显示75%的命令执行准确率。


<details>
  <summary>Details</summary>
Motivation: 准确解释人类意图是人机交互的核心挑战，也是实现更自然直观人机协作的关键要求。当前需要更可靠、自适应的系统来提升人机协作的自然性和效率。

Method: 采用多模态HRI框架，整合Florence-2进行物体检测、Llama 3.1进行自然语言理解、Whisper进行语音识别，并结合模糊逻辑实现精确自适应控制。通过联合处理场景感知和动作规划来提升命令解释和执行的可靠性。

Result: 在消费级硬件上的实验评估显示，系统实现了75%的命令执行准确率，证明了系统的鲁棒性和适应性。该架构为未来HRI研究提供了灵活可扩展的基础。

Conclusion: 该框架通过紧密耦合的语音和视觉语言处理，为更复杂自然的人机协作提供了实用途径，可作为未来HRI研究的灵活可扩展基础。

Abstract: Interpreting human intent accurately is a central challenge in human-robot interaction (HRI) and a key requirement for achieving more natural and intuitive collaboration between humans and machines. This work presents a novel multimodal HRI framework that combines advanced vision-language models, speech processing, and fuzzy logic to enable precise and adaptive control of a Dobot Magician robotic arm. The proposed system integrates Florence-2 for object detection, Llama 3.1 for natural language understanding, and Whisper for speech recognition, providing users with a seamless and intuitive interface for object manipulation through spoken commands. By jointly addressing scene perception and action planning, the approach enhances the reliability of command interpretation and execution. Experimental evaluations conducted on consumer-grade hardware demonstrate a command execution accuracy of 75\%, highlighting both the robustness and adaptability of the system. Beyond its current performance, the proposed architecture serves as a flexible and extensible foundation for future HRI research, offering a practical pathway toward more sophisticated and natural human-robot collaboration through tightly coupled speech and vision-language processing.

</details>


### [23] [What Matters for Simulation to Online Reinforcement Learning on Real Robots](https://arxiv.org/abs/2602.20220)
*Yarden As,Dhruva Tirumala,René Zurbrügg,Chenhao Li,Stelian Coros,Andreas Krause,Markus Wulfmeier*

Main category: cs.RO

TL;DR: 通过100次真实机器人训练实验，系统研究了在线强化学习在物理机器人上的成功设计选择，发现一些常用默认设置有害，而一组稳健的设计选择能在不同任务和硬件上实现稳定学习


<details>
  <summary>Details</summary>
Motivation: 研究在物理机器人上成功实现在线强化学习的具体设计选择，填补先前工作中通常隐含的算法、系统和实验决策的实证研究空白

Method: 在三个不同机器人平台上进行100次真实世界训练运行，系统性地消融分析算法、系统和实验决策，这些决策在先前工作中通常被隐含处理

Result: 发现一些广泛使用的默认设置可能有害，而一组稳健的、易于采用的标准RL实践设计选择能在不同任务和硬件上实现稳定学习

Conclusion: 提供了首个关于此类设计选择的大样本实证研究，使从业者能够以更低的工程努力部署在线强化学习

Abstract: We investigate what specific design choices enable successful online reinforcement learning (RL) on physical robots. Across 100 real-world training runs on three distinct robotic platforms, we systematically ablate algorithmic, systems, and experimental decisions that are typically left implicit in prior work. We find that some widely used defaults can be harmful, while a set of robust, readily adopted design choices within standard RL practice yield stable learning across tasks and hardware. These results provide the first large-sample empirical study of such design choices, enabling practitioners to deploy online RL with lower engineering effort.

</details>


### [24] [FACTO: Function-space Adaptive Constrained Trajectory Optimization for Robotic Manipulators](https://arxiv.org/abs/2602.20225)
*Yichang Feng,Xiao Liang,Minghui Zheng*

Main category: cs.RO

TL;DR: FACTO是一种用于单臂和多臂机械臂轨迹优化的新算法，直接在系数空间进行优化，采用高斯-牛顿近似和自适应约束更新，在约束场景下表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前轨迹优化方法在单臂和多臂机械臂的约束场景中，解决方案质量和可行性有待提高，需要一种更有效的优化算法来处理非线性约束和轨迹全局约束。

Method: 将轨迹参数化为正交基函数的线性组合，直接在系数空间进行优化；使用高斯-牛顿近似配合指数移动平均处理非线性；通过系数空间映射处理轨迹全局约束；在活动约束的零空间中使用Levenberg-Marquardt算法进行自适应约束更新。

Result: 与优化型规划器（CHOMP、TrajOpt、GPMP2）和采样型规划器（RRT-Connect、RRT*、PRM）相比，FACTO在解决方案质量和可行性方面表现更优，特别是在约束单臂和多臂场景中；在Franka机器人上的实验验证了部署可行性。

Conclusion: FACTO是一种有效的轨迹优化算法，能够处理单臂和多臂机械臂的复杂约束场景，在解决方案质量和可行性方面优于现有方法，具有实际部署的可行性。

Abstract: This paper introduces Function-space Adaptive Constrained Trajectory Optimization (FACTO), a new trajectory optimization algorithm for both single- and multi-arm manipulators. Trajectory representations are parameterized as linear combinations of orthogonal basis functions, and optimization is performed directly in the coefficient space. The constrained problem formulation consists of both an objective functional and a finite-dimensional objective defined over truncated coefficients. To address nonlinearity, FACTO uses a Gauss-Newton approximation with exponential moving averaging, yielding a smoothed quadratic subproblem. Trajectory-wide constraints are addressed using coefficient-space mappings, and an adaptive constrained update using the Levenberg-Marquardt algorithm is performed in the null space of active constraints. Comparisons with optimization-based planners (CHOMP, TrajOpt, GPMP2) and sampling-based planners (RRT-Connect, RRT*, PRM) show the improved solution quality and feasibility, especially in constrained single- and multi-arm scenarios. The experimental evaluation of FACTO on Franka robots verifies the feasibility of deployment.

</details>


### [25] [UniLACT: Depth-Aware RGB Latent Action Learning for Vision-Language-Action Models](https://arxiv.org/abs/2602.20231)
*Manish Kumar Govind,Dominick Reilly,Pu Wang,Srijan Das*

Main category: cs.RO

TL;DR: 论文提出UniLACT模型，通过深度感知的潜在预训练将几何结构融入VLA模型，以及UniLARN框架学习RGB和深度的统一潜在动作表示，提升接触丰富的操作任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有从无标签视频学习的潜在动作表示主要基于RGB观测，编码外观驱动的动态，缺乏明确的3D几何结构，而几何结构对于精确和接触丰富的操作任务至关重要。

Method: 提出UniLACT：基于Transformer的VLA模型，通过深度感知潜在预训练融入几何结构；提出UniLARN：基于逆动态和前向动态目标的统一潜在动作学习框架，学习RGB和深度的共享嵌入空间并显式建模跨模态交互。

Result: 在仿真和真实世界实验中，UniLACT在领域内和领域外预训练、已见和未见操作任务上，均优于基于RGB的潜在动作基线方法，证明了深度感知统一潜在动作表示的有效性。

Conclusion: 通过深度感知潜在预训练将几何结构融入VLA模型能显著提升操作性能，特别是对于需要精确空间感知的接触丰富操作任务，为机器人学习提供了更强大的空间先验。

Abstract: Latent action representations learned from unlabeled videos have recently emerged as a promising paradigm for pretraining vision-language-action (VLA) models without explicit robot action supervision. However, latent actions derived solely from RGB observations primarily encode appearance-driven dynamics and lack explicit 3D geometric structure, which is essential for precise and contact-rich manipulation. To address this limitation, we introduce UniLACT, a transformer-based VLA model that incorporates geometric structure through depth-aware latent pretraining, enabling downstream policies to inherit stronger spatial priors. To facilitate this process, we propose UniLARN, a unified latent action learning framework based on inverse and forward dynamics objectives that learns a shared embedding space for RGB and depth while explicitly modeling their cross-modal interactions. This formulation produces modality-specific and unified latent action representations that serve as pseudo-labels for the depth-aware pretraining of UniLACT. Extensive experiments in both simulation and real-world settings demonstrate the effectiveness of depth-aware unified latent action representations. UniLACT consistently outperforms RGB-based latent action baselines under in-domain and out-of-domain pretraining regimes, as well as on both seen and unseen manipulation tasks.

</details>


### [26] [Smoothly Differentiable and Efficiently Vectorizable Contact Manifold Generation](https://arxiv.org/abs/2602.20304)
*Onur Beker,Andreas René Geist,Anselm Paulus,Nico Gürtler,Ji Shi,Sylvain Calinon,Georg Martius*

Main category: cs.RO

TL;DR: 提出一個專為向量化和可微分性設計的剛體動力學接觸模擬框架，解決現有框架在接觸流形生成上的瓶頸。


<details>
  <summary>Details</summary>
Motivation: 現有機器人模擬器的碰撞檢測程序未考慮向量化和可微分性，依賴邏輯和控制流，導致在快速、大規模向量化且平滑可微的剛體動力學模擬中成為瓶頸。

Method: 提出一個新框架，平衡凸基元方法和無符號距離方法：1) 使用平滑解析簽名距離基元實現頂點-面碰撞；2) 提出新穎的可微分邊緣-邊緣碰撞程序，提供簽名距離和簽名接觸法向量。

Result: 通過教學實驗評估，並與Mujoco XLA框架的碰撞檢測程序進行基準測試，觀察到顯著的速度提升。

Conclusion: 該框架在保持可微分性的同時實現了高效的接觸模擬，為機器人學中的快速、向量化且可微分的剛體動力學模擬提供了有效解決方案。

Abstract: Simulating rigid-body dynamics with contact in a fast, massively vectorizable, and smoothly differentiable manner is highly desirable in robotics. An important bottleneck faced by existing differentiable simulation frameworks is contact manifold generation: representing the volume of intersection between two colliding geometries via a discrete set of properly distributed contact points. A major factor contributing to this bottleneck is that the related routines of commonly used robotics simulators were not designed with vectorization and differentiability as a primary concern, and thus rely on logic and control flow that hinder these goals. We instead propose a framework designed from the ground up with these goals in mind, by trying to strike a middle ground between: i) convex primitive based approaches used by common robotics simulators (efficient but not differentiable), and ii) mollified vertex-face and edge-edge unsigned distance-based approaches used by barrier methods (differentiable but inefficient). Concretely, we propose: i) a representative set of smooth analytical signed distance primitives to implement vertex-face collisions, and ii) a novel differentiable edge-edge collision routine that can provide signed distances and signed contact normals. The proposed framework is evaluated via a set of didactic experiments and benchmarked against the collision detection routine of the well-established Mujoco XLA framework, where we observe a significant speedup. Supplementary videos can be found at https://github.com/bekeronur/contax, where a reference implementation in JAX will also be made available at the conclusion of the review process.

</details>


### [27] [Learning Physical Principles from Interaction: Self-Evolving Planning via Test-Time Memory](https://arxiv.org/abs/2602.20323)
*Haoyang Li,Yang You,Hao Su,Leonidas Guibas*

Main category: cs.RO

TL;DR: PhysMem：一种基于记忆框架的视觉-语言模型机器人规划器，通过交互学习物理原理，无需更新模型参数


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型（VLM）规划器虽然能够推理摩擦、稳定性等物理概念，但无法准确预测特定物体在具体环境中的具体物理行为，需要直接经验才能做出可靠决策

Method: 提出PhysMem记忆框架，系统记录交互经验，生成候选假设，并通过针对性交互验证假设，验证通过的知识才用于指导未来决策。关键设计是"先验证后应用"原则

Result: 在砖块插入任务中，基于原则抽象的方法达到76%成功率，而直接经验检索仅23%。真实世界实验在30分钟部署会话中持续改进，在三个真实世界操作任务和四个VLM骨干的仿真基准上表现一致提升

Conclusion: PhysMem框架使VLM机器人规划器能够在测试时通过交互学习物理原理，验证机制减少了物理条件变化时对先前经验的僵化依赖，提高了机器人操作的可靠性和适应性

Abstract: Reliable object manipulation requires understanding physical properties that vary across objects and environments. Vision-language model (VLM) planners can reason about friction and stability in general terms; however, they often cannot predict how a specific ball will roll on a particular surface or which stone will provide a stable foundation without direct experience. We present PhysMem, a memory framework that enables VLM robot planners to learn physical principles from interaction at test time, without updating model parameters. The system records experiences, generates candidate hypotheses, and verifies them through targeted interaction before promoting validated knowledge to guide future decisions. A central design choice is verification before application: the system tests hypotheses against new observations rather than applying retrieved experience directly, reducing rigid reliance on prior experience when physical conditions change. We evaluate PhysMem on three real-world manipulation tasks and simulation benchmarks across four VLM backbones. On a controlled brick insertion task, principled abstraction achieves 76% success compared to 23% for direct experience retrieval, and real-world experiments show consistent improvement over 30-minute deployment sessions.

</details>


### [28] [Cooperative-Competitive Team Play of Real-World Craft Robots](https://arxiv.org/abs/2602.21119)
*Rui Zhao,Xihui Li,Yizheng Zhang,Yuzhen Liu,Zhong Zhang,Yufeng Zhang,Cheng Zhou,Zhengyou Zhang,Lei Han*

Main category: cs.RO

TL;DR: 该论文提出一个综合机器人系统，通过强化学习训练多智能体协同与竞争策略，并引入OODSI方法提升仿真到现实的迁移性能，在真实环境中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 多智能体深度强化学习在游戏智能体方面取得进展，但集体机器人的高效训练以及学习策略到现实应用的迁移仍是开放研究问题。

Method: 开发了包含仿真、分布式学习框架和物理机器人组件的综合机器人系统；提出并评估了针对该平台高效训练协同与竞争策略的强化学习技术；引入OODSI方法缓解仿真到现实的差距影响。

Result: OODSI将仿真到现实的性能提升了20%；在多机器人汽车竞争游戏和协同任务的真实环境实验中证明了方法的有效性。

Conclusion: 提出的综合机器人系统和OODSI方法有效解决了多智能体强化学习的仿真到现实迁移挑战，为集体机器人的高效训练提供了实用解决方案。

Abstract: Multi-agent deep Reinforcement Learning (RL) has made significant progress in developing intelligent game-playing agents in recent years. However, the efficient training of collective robots using multi-agent RL and the transfer of learned policies to real-world applications remain open research questions. In this work, we first develop a comprehensive robotic system, including simulation, distributed learning framework, and physical robot components. We then propose and evaluate reinforcement learning techniques designed for efficient training of cooperative and competitive policies on this platform. To address the challenges of multi-agent sim-to-real transfer, we introduce Out of Distribution State Initialization (OODSI) to mitigate the impact of the sim-to-real gap. In the experiments, OODSI improves the Sim2Real performance by 20%. We demonstrate the effectiveness of our approach through experiments with a multi-robot car competitive game and a cooperative task in real-world settings.

</details>


### [29] [A Micro-Macro Model of Encounter-Driven Information Diffusion in Robot Swarms](https://arxiv.org/abs/2602.21148)
*Davis S. Catherman,Carlo Pinciroli*

Main category: cs.RO

TL;DR: 提出了一种名为"相遇驱动信息扩散(EDID)"的新问题，研究机器人在仅能通过相遇交换信息且无法预知相遇时间、地点和对象的情况下如何进行信息传播。


<details>
  <summary>Details</summary>
Motivation: 研究在现实机器人系统中常见的信息传播场景，即机器人只能在实际相遇时交换信息，且无法主动安排相遇。这种情况在缺乏集中调度或通信基础设施的分布式机器人系统中很常见。

Method: 提出一个基于第一原理的两层信息扩散模型：微观模型基于"平均自由程"概念的推广；宏观模型捕捉信息扩散的全局动态。通过广泛的机器人模拟验证模型，考虑群体大小、通信范围、环境大小和不同随机运动模式。

Result: 建立了一个能够准确捕捉EDID动态的数学模型，并通过模拟验证了模型的有效性。模型能够描述在不同参数设置下信息在机器人群体中的传播过程。

Conclusion: 该模型为设计EDID场景下的存储和路由算法提供了理论基础，并讨论了模型参数对信息扩散算法设计的影响，为未来算法开发指明了方向。

Abstract: In this paper, we propose the problem of Encounter-Driven Information Diffusion (EDID). In EDID, robots are allowed to exchange information only upon meeting. Crucially, EDID assumes that the robots are not allowed to schedule their meetings. As such, the robots have no means to anticipate when, where, and who they will meet. As a step towards the design of storage and routing algorithms for EDID, in this paper we propose a model of information diffusion that captures the essential dynamics of EDID. The model is derived from first principles and is composed of two levels: a micro model, based on a generalization of the concept of `mean free path'; and a macro model, which captures the global dynamics of information diffusion. We validate the model through extensive robot simulations, in which we consider swarm size, communication range, environment size, and different random motion regimes. We conclude the paper with a discussion of the implications of this model on the algorithms that best support information diffusion according to the parameters of interest.

</details>


### [30] [HALO: A Unified Vision-Language-Action Model for Embodied Multimodal Chain-of-Thought Reasoning](https://arxiv.org/abs/2602.21157)
*Quanxin Shou,Fangqi Zhu,Shawn Chen,Puxin Yan,Zhengyang Yan,Yikun Miao,Xiaoyi Pang,Zicong Hong,Ruikai Shi,Hao Huang,Jie Zhang,Song Guo*

Main category: cs.RO

TL;DR: 提出HALO模型，通过多模态思维链推理（EM-CoT）实现文本推理、视觉子目标预测和动作预测的统一框架，在长视野任务中表现优异


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在长视野和分布外场景中表现不佳，缺乏统一的多模态推理和动作预测框架，需要更接近人类推理方式的解决方案

Method: 提出HALO模型，采用EM-CoT推理流程：文本任务推理→视觉子目标预测→增强动作预测；使用混合Transformer架构分离专家模块，并开发自动化数据合成管道

Result: 在模拟和真实环境中表现优异，比基线策略提升34.1%；所有组件均有效提升任务成功率；在未见环境随机化下展现强泛化能力

Conclusion: HALO通过统一的EM-CoT推理框架显著提升了VLA模型在复杂机器人操作任务中的性能，为多模态推理提供了新范式

Abstract: Vision-Language-Action (VLA) models have shown strong performance in robotic manipulation, but often struggle in long-horizon or out-of-distribution scenarios due to the lack of explicit mechanisms for multimodal reasoning and anticipating how the world will evolve under action. Recent works introduce textual chain-of-thought or visual subgoal prediction within VLA models to reason, but still fail to offer a unified human-like reasoning framework for joint textual reasoning, visual foresight, and action prediction. To this end, we propose HALO, a unified VLA model that enables embodied multimodal chain-of-thought (EM-CoT) reasoning through a sequential process of textual task reasoning, visual subgoal prediction for fine-grained guidance, and EM-CoT-augmented action prediction. We instantiate HALO with a Mixture-of-Transformers (MoT) architecture that decouples semantic reasoning, visual foresight, and action prediction into specialized experts while allowing seamless cross-expert collaboration. To enable HALO learning at scale, we introduce an automated pipeline to synthesize EM-CoT training data along with a carefully crafted training recipe. Extensive experiments demonstrate that: (1) HALO achieves superior performance in both simulated and real-world environments, surpassing baseline policy pi_0 by 34.1% on RoboTwin benchmark; (2) all proposed components of the training recipe and EM-CoT design help improve task success rate; and (3) HALO exhibits strong generalization capabilities under aggressive unseen environmental randomization with our proposed EM-CoT reasoning.

</details>


### [31] [ActionReasoning: Robot Action Reasoning in 3D Space with LLM for Robotic Brick Stacking](https://arxiv.org/abs/2602.21161)
*Guangming Wang,Qizhen Ying,Yixiong Jing,Olaf Wysocki,Brian Sheil*

Main category: cs.RO

TL;DR: 论文提出ActionReasoning框架，利用LLM进行显式动作推理，生成物理一致、先验引导的机器人操作决策，通过多智能体架构在积木堆叠任务中验证有效性。


<details>
  <summary>Details</summary>
Motivation: 传统机器人系统依赖定制规划器，在受限环境中有效但泛化能力差。当前基于VLA的数据驱动方法面临连续动作空间超出语言标记表示能力的问题，需要新的框架来弥合感知与执行之间的鸿沟。

Method: 提出ActionReasoning框架，利用LLM中已编码的物理先验和现实世界知识，构建多智能体架构进行显式动作推理。在积木堆叠案例中，将环境状态序列化后输入多智能体LLM框架，生成物理感知的动作计划。

Result: 实验证明该多智能体LLM框架能实现稳定的积木放置，将工作重心从低级的领域特定编码转移到高级工具调用和提示工程，展示了更广泛泛化的潜力。

Conclusion: 该工作通过将物理推理与LLM结合，为机器人操作中感知与执行的融合提供了有前景的方法，有望推动具身AI和通用机器人的可扩展性发展。

Abstract: Classical robotic systems typically rely on custom planners designed for constrained environments. While effective in restricted settings, these systems lack generalization capabilities, limiting the scalability of embodied AI and general-purpose robots. Recent data-driven Vision-Language-Action (VLA) approaches aim to learn policies from large-scale simulation and real-world data. However, the continuous action space of the physical world significantly exceeds the representational capacity of linguistic tokens, making it unclear if scaling data alone can yield general robotic intelligence. To address this gap, we propose ActionReasoning, an LLM-driven framework that performs explicit action reasoning to produce physics-consistent, prior-guided decisions for robotic manipulation. ActionReasoning leverages the physical priors and real-world knowledge already encoded in Large Language Models (LLMs) and structures them within a multi-agent architecture. We instantiate this framework on a tractable case study of brick stacking, where the environment states are assumed to be already accurately measured. The environmental states are then serialized and passed to a multi-agent LLM framework that generates physics-aware action plans. The experiments demonstrate that the proposed multi-agent LLM framework enables stable brick placement while shifting effort from low-level domain-specific coding to high-level tool invocation and prompting, highlighting its potential for broader generalization. This work introduces a promising approach to bridging perception and execution in robotic manipulation by integrating physical reasoning with LLMs.

</details>


### [32] [Efficient Hierarchical Any-Angle Path Planning on Multi-Resolution 3D Grids](https://arxiv.org/abs/2602.21174)
*Victor Reijgwart,Cesar Cadena,Roland Siegwart,Lionel Ott*

Main category: cs.RO

TL;DR: 提出一种利用多分辨率体素地图进行任意角度路径规划的方法，兼具最优性和完备性，同时解决搜索方法计算复杂度问题


<details>
  <summary>Details</summary>
Motivation: 现有的分层多分辨率体素地图虽然能高效表示大范围复杂环境，但主流路径规划方法（如采样法、轨迹优化）未充分利用其显式连接信息，而A*等搜索方法在大规模高分辨率地图中面临可扩展性问题

Method: 利用多分辨率表示的优势，结合任意角度规划方法（通过障碍物角点连接直线段寻找最优路径），在保持最优性和完备性的同时提升计算效率

Result: 在真实和合成环境中的大量实验表明，该方法在解质量和速度上均表现优异，甚至优于基于采样的方法

Conclusion: 该方法为机器人路径规划提供了一种高效解决方案，已开源供社区使用

Abstract: Hierarchical, multi-resolution volumetric mapping approaches are widely used to represent large and complex environments as they can efficiently capture their occupancy and connectivity information. Yet widely used path planning methods such as sampling and trajectory optimization do not exploit this explicit connectivity information, and search-based methods such as A* suffer from scalability issues in large-scale high-resolution maps. In many applications, Euclidean shortest paths form the underpinning of the navigation system. For such applications, any-angle planning methods, which find optimal paths by connecting corners of obstacles with straight-line segments, provide a simple and efficient solution. In this paper, we present a method that has the optimality and completeness properties of any-angle planners while overcoming computational tractability issues common to search-based methods by exploiting multi-resolution representations. Extensive experiments on real and synthetic environments demonstrate the proposed approach's solution quality and speed, outperforming even sampling-based methods. The framework is open-sourced to allow the robotics and planning community to build on our research.

</details>


### [33] [Squint: Fast Visual Reinforcement Learning for Sim-to-Real Robotics](https://arxiv.org/abs/2602.21203)
*Abdulaziz Almuzairee,Henrik I. Christensen*

Main category: cs.RO

TL;DR: Squint是一种视觉软演员-评论家方法，通过并行模拟、分布评论家、分辨率压缩等技术，在单GPU上15分钟内完成视觉强化学习训练，比现有方法更快。


<details>
  <summary>Details</summary>
Motivation: 视觉强化学习在机器人应用中很有前景但计算昂贵：离策略方法样本效率高但训练慢；同策略方法可并行化但浪费样本。现有工作表明离策略方法在状态控制中能比同策略方法训练更快，但扩展到视觉领域仍面临挑战，高维图像输入使训练动态复杂化并带来存储和编码开销。

Method: 提出Squint方法，基于视觉软演员-评论家框架，采用以下关键技术：1) 并行模拟；2) 分布评论家；3) 分辨率压缩（squinting）；4) 层归一化；5) 优化的更新-数据比率；6) 高效实现。在SO-101任务集（ManiSkill3中的8个操作任务）上评估，包含大量领域随机化。

Result: 在单RTX 3090 GPU上训练15分钟，大多数任务在6分钟内收敛，比现有视觉离策略和同策略方法训练更快。实现了从仿真到真实SO-101机器人的迁移。

Conclusion: Squint通过一系列优化技术成功解决了视觉强化学习训练速度慢的问题，在保持离策略方法样本效率的同时实现了快速并行训练，为机器人视觉控制提供了高效的解决方案。

Abstract: Visual reinforcement learning is appealing for robotics but expensive -- off-policy methods are sample-efficient yet slow; on-policy methods parallelize well but waste samples. Recent work has shown that off-policy methods can train faster than on-policy methods in wall-clock time for state-based control. Extending this to vision remains challenging, where high-dimensional input images complicate training dynamics and introduce substantial storage and encoding overhead. To address these challenges, we introduce Squint, a visual Soft Actor Critic method that achieves faster wall-clock training than prior visual off-policy and on-policy methods. Squint achieves this via parallel simulation, a distributional critic, resolution squinting, layer normalization, a tuned update-to-data ratio, and an optimized implementation. We evaluate on the SO-101 Task Set, a new suite of eight manipulation tasks in ManiSkill3 with heavy domain randomization, and demonstrate sim-to-real transfer to a real SO-101 robot. We train policies for 15 minutes on a single RTX 3090 GPU, with most tasks converging in under 6 minutes.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [34] [Tensor Network Generator-Enhanced Optimization for Traveling Salesman Problem](https://arxiv.org/abs/2602.20175)
*Ryo Sakai,Chen-Yu Liu*

Main category: cs.LG

TL;DR: TN-GEO框架应用于旅行商问题，使用基于可自动微分矩阵积态的张量网络Born机器作为生成模型，通过自回归采样和掩码保证生成有效路径，k-site变体提升局部相关性建模，在TSPLIB基准测试中超越经典启发式算法。


<details>
  <summary>Details</summary>
Motivation: 解决旅行商问题这一基础组合优化挑战，传统二进制编码方法需要N²变量和惩罚项来保证有效路径约束，需要更高效的方法来直接生成有效路径并提升优化性能。

Method: 采用基于置换的整数变量表述，使用基于可自动微分矩阵积态的张量网络Born机器作为生成模型，通过Born规则定义候选解的概率分布，使用自回归采样和掩码保证生成有效路径，并引入k-site MPS变体通过滑动窗口学习k-gram分布。

Result: 在TSPLIB基准测试中（最多52个城市），TN-GEO能够超越包括swap和2-opt爬山法在内的经典启发式算法，k-site变体由于更关注局部相关性，相比完整MPS获得更好结果。

Conclusion: TN-GEO框架为组合优化问题提供了有效的生成式方法，通过直接生成有效路径避免了约束处理，k-site MPS变体通过关注局部相关性实现了参数高效建模，在TSP问题上展现了优越性能。

Abstract: We present an application of the tensor network generator-enhanced optimization (TN-GEO) framework to address the traveling salesman problem (TSP), a fundamental combinatorial optimization challenge. Our approach employs a tensor network Born machine based on automatically differentiable matrix product states (MPS) as the generative model, using the Born rule to define probability distributions over candidate solutions. Unlike approaches based on binary encoding, which require $N^2$ variables and penalty terms to enforce valid tour constraints, we adopt a permutation-based formulation with integer variables and use autoregressive sampling with masking to guarantee that every generated sample is a valid tour by construction. We also introduce a $k$-site MPS variant that learns distributions over $k$-grams (consecutive city subsequences) using a sliding window approach, enabling parameter-efficient modeling for larger instances. Experimental validation on TSPLIB benchmark instances with up to 52 cities demonstrates that TN-GEO can outperform classical heuristics including swap and 2-opt hill-climbing. The $k$-site variants, which put more focus on local correlations, show better results compared to the full-MPS case.

</details>


### [35] [MoBiQuant: Mixture-of-Bits Quantization for Token-Adaptive Elastic LLMs](https://arxiv.org/abs/2602.20191)
*Dongwei Wang,Jinhee Kim,Seokho Han,Denis Gudovskiy,Yohei Nakata,Tomoyuki Okuno,KhayTze Peong,Kang Eun Jeon,Jong Hwan Ko,Yiran Chen,Huanrui Yang*

Main category: cs.LG

TL;DR: MoBiQuant是一个混合比特量化框架，通过基于token敏感性的权重精度调整，实现弹性LLM推理，无需重复校准即可在不同精度间平滑切换。


<details>
  <summary>Details</summary>
Motivation: 云和边缘设备的运行时复杂性变化需要弹性LLM部署，但传统量化方法中校准参数与特定精度绑定，导致弹性精度校准和运行时精度切换困难。

Method: 提出MoBiQuant框架：1) 多合一递归残差量化，迭代重构高精度权重；2) token感知路由器，动态选择残差比特切片数量。通过调整token敏感性相关的权重精度实现弹性推理。

Result: 实验结果显示MoBiQuant表现出强弹性，在LLaMA3-8B上无需重复校准即可达到比特特定校准PTQ的性能。

Conclusion: MoBiQuant通过解决精度相关异常值迁移导致的token级敏感性变化问题，实现了弹性量化，支持平滑精度切换并提升对token异常值分布的泛化能力。

Abstract: Changing runtime complexity on cloud and edge devices necessitates elastic large language model (LLM) deployment, where an LLM can be inferred with various quantization precisions based on available computational resources. However, it has been observed that the calibration parameters for quantization are typically linked to specific precisions, which presents challenges during elastic-precision calibration and precision switching at runtime. In this work, we attribute the source of varying calibration parameters to the varying token-level sensitivity caused by a precision-dependent outlier migration phenomenon.Motivated by this observation, we propose \texttt{MoBiQuant}, a novel Mixture-of-Bits quantization framework that adjusts weight precision for elastic LLM inference based on token sensitivity. Specifically, we propose the many-in-one recursive residual quantization that can iteratively reconstruct higher-precision weights and the token-aware router to dynamically select the number of residual bit slices. MoBiQuant enables smooth precision switching while improving generalization for the distribution of token outliers. Experimental results demonstrate that MoBiQuant exhibits strong elasticity, enabling it to match the performance of bit-specific calibrated PTQ on LLaMA3-8B without repeated calibration.

</details>


### [36] [FedAvg-Based CTMC Hazard Model for Federated Bridge Deterioration Assessment](https://arxiv.org/abs/2602.20194)
*Takato Yasuno*

Main category: cs.LG

TL;DR: 提出基于联邦学习的桥梁退化连续时间马尔可夫链风险模型估计框架，实现跨组织数据协作训练而不共享原始检测数据


<details>
  <summary>Details</summary>
Motivation: 桥梁定期检测记录包含敏感基础设施信息，现有数据治理约束下跨组织数据共享不可行，需要保护数据主权的同时实现协作建模

Method: 采用联邦学习框架，每个用户本地训练对数线性风险模型，仅上传12维伪梯度向量；服务器使用带动量和梯度裁剪的加权FedAvg聚合更新；所有实验基于已知真实参数生成的合成数据

Result: 在异构用户场景下实现平均负对数似然一致收敛，聚合梯度范数随用户规模增加而减小；联邦更新机制提供自然参与激励

Conclusion: 该框架使市政部门能在不放弃数据主权的情况下协作训练共享基准模型，获得仅凭本地数据无法获得的全局基准参数，支持基于证据的生命周期规划

Abstract: Bridge periodic inspection records contain sensitive information about public infrastructure, making cross-organizational data sharing impractical under existing data governance constraints. We propose a federated framework for estimating a Continuous-Time Markov Chain (CTMC) hazard model of bridge deterioration, enabling municipalities to collaboratively train a shared benchmark model without transferring raw inspection records. Each User holds local inspection data and trains a log-linear hazard model over three deterioration-direction transitions -- Good$\to$Minor, Good$\to$Severe, and Minor$\to$Severe -- with covariates for bridge age, coastline distance, and deck area. Local optimization is performed via mini-batch stochastic gradient descent on the CTMC log-likelihood, and only a 12-dimensional pseudo-gradient vector is uploaded to a central server per communication round. The server aggregates User updates using sample-weighted Federated Averaging (FedAvg) with momentum and gradient clipping. All experiments in this paper are conducted on fully synthetic data generated from a known ground-truth parameter set with region-specific heterogeneity, enabling controlled evaluation of federated convergence behaviour. Simulation results across heterogeneous Users show consistent convergence of the average negative log-likelihood, with the aggregated gradient norm decreasing as User scale increases. Furthermore, the federated update mechanism provides a natural participation incentive: Users who register their local inspection datasets on a shared technical-standard platform receive in return the periodically updated global benchmark parameters -- information that cannot be obtained from local data alone -- thereby enabling evidence-based life-cycle planning without surrendering data sovereignty.

</details>


### [37] [Controllable Exploration in Hybrid-Policy RLVR for Multi-Modal Reasoning](https://arxiv.org/abs/2602.20197)
*Zhuoxu Huang,Mengxi Jia,Hao Sun,Xuelong Li,Jungong Han*

Main category: cs.LG

TL;DR: CalibRL是一个基于专家指导的可控探索混合策略RLVR框架，通过分布感知优势加权和LeakyReLU激活函数缓解MLLM训练中的熵崩溃和策略退化问题。


<details>
  <summary>Details</summary>
Motivation: MLLM在RL训练中面临巨大状态空间和稀疏奖励导致的熵崩溃、策略退化或次优行为过度利用问题，需要一种既能保持生产性随机性又避免无控制随机采样的低效探索策略。

Method: 提出CalibRL框架，包含两个关键机制：1) 分布感知优势加权，根据组稀有度缩放更新以校准分布；2) 非对称激活函数(LeakyReLU)，利用专家知识作为校准基线，调节过度自信更新同时保持其修正方向。

Result: 在八个基准测试(包括域内和域外设置)上的广泛实验显示了一致的改进，验证了可控混合策略RLVR训练的有效性。

Conclusion: CalibRL通过引导方式增加策略熵，澄清目标分布，缓解模型策略与专家轨迹之间的分布不匹配，实现了探索与利用的更稳定平衡。

Abstract: Reinforcement Learning with verifiable rewards (RLVR) has emerged as a primary learning paradigm for enhancing the reasoning capabilities of multi-modal large language models (MLLMs). However, during RL training, the enormous state space of MLLM and sparse rewards often leads to entropy collapse, policy degradation, or over-exploitation of suboptimal behaviors. This necessitates an exploration strategy that maintains productive stochasticity while avoiding the drawbacks of uncontrolled random sampling, yielding inefficient exploration. In this paper, we propose CalibRL, a hybrid-policy RLVR framework that supports controllable exploration with expert guidance, enabled by two key mechanisms. First, a distribution-aware advantage weighting scales updates by group rareness to calibrate the distribution, therefore preserving exploration. Meanwhile, the asymmetric activation function (LeakyReLU) leverages the expert knowledge as a calibration baseline to moderate overconfident updates while preserving their corrective direction. CalibRL increases policy entropy in a guided manner and clarifies the target distribution by estimating the on-policy distribution through online sampling. Updates are driven by these informative behaviors, avoiding convergence to erroneous patterns. Importantly, these designs help alleviate the distributional mismatch between the model's policy and expert trajectories, thereby achieving a more stable balance between exploration and exploitation. Extensive experiments across eight benchmarks, including both in-domain and out-of-domain settings, demonstrate consistent improvements, validating the effectiveness of our controllable hybrid-policy RLVR training. Code is available at https://github.com/zhh6425/CalibRL.

</details>


### [38] [IMOVNO+: A Regional Partitioning and Meta-Heuristic Ensemble Framework for Imbalanced Multi-Class Learning](https://arxiv.org/abs/2602.20199)
*Soufiane Bacha,Laouni Djafri,Sahraoui Dhelim,Huansheng Ning*

Main category: cs.LG

TL;DR: IMOVNO+ 是一个处理类别不平衡、重叠和噪声的两级框架，通过数据级优化和算法级集成剪枝，在二元和多类分类任务中显著提升性能


<details>
  <summary>Details</summary>
Motivation: 类别不平衡、重叠和噪声会降低数据质量、模型可靠性和泛化能力。虽然在二元分类中已有广泛研究，但在多类场景中这些问题仍未被充分探索，因为复杂的类间关系使得少数-多数结构不清晰，传统聚类方法难以捕捉分布形状。现有方法要么只依赖几何距离（可能移除信息样本并生成低质量合成数据），要么使用二值化方法（仅局部处理不平衡而忽略全局类间依赖）。在算法层面，集成方法难以有效整合弱分类器，导致鲁棒性有限。

Method: IMOVNO+ 是一个两级框架。数据级：1) 使用条件概率量化每个样本的信息性；2) 将数据集划分为核心、重叠和噪声区域；3) 引入结合Z-score度量和big-jump间隙距离的重叠清理算法；4) 提出基于多正则化的智能过采样算法，控制合成样本的邻近度以防止新重叠。算法级：使用元启发式方法剪枝集成分类器，减少弱学习器的影响。

Result: 在35个数据集（13个多类，22个二元）上评估，IMOVNO+ 始终优于最先进方法，在多个案例中接近100%性能。对于多类数据，G-mean提升37-57%，F1-score提升25-44%，精确率提升25-39%，召回率提升26-43%。在二元任务中，达到接近完美的性能，提升14-39%。

Conclusion: IMOVNO+ 有效处理了数据稀缺性和由收集和隐私限制导致的不平衡问题，通过联合优化数据质量和算法鲁棒性，在二元和多类分类任务中实现了显著性能改进。

Abstract: Class imbalance, overlap, and noise degrade data quality, reduce model reliability, and limit generalization. Although widely studied in binary classification, these issues remain underexplored in multi-class settings, where complex inter-class relationships make minority-majority structures unclear and traditional clustering fails to capture distribution shape. Approaches that rely only on geometric distances risk removing informative samples and generating low-quality synthetic data, while binarization approaches treat imbalance locally and ignore global inter-class dependencies. At the algorithmic level, ensembles struggle to integrate weak classifiers, leading to limited robustness. This paper proposes IMOVNO+ (IMbalance-OVerlap-NOise+ Algorithm-Level Optimization), a two-level framework designed to jointly enhance data quality and algorithmic robustness for binary and multi-class tasks. At the data level, first, conditional probability is used to quantify the informativeness of each sample. Second, the dataset is partitioned into core, overlapping, and noisy regions. Third, an overlapping-cleaning algorithm is introduced that combines Z-score metrics with a big-jump gap distance. Fourth, a smart oversampling algorithm based on multi-regularization controls synthetic sample proximity, preventing new overlaps. At the algorithmic level, a meta-heuristic prunes ensemble classifiers to reduce weak-learner influence. IMOVNO+ was evaluated on 35 datasets (13 multi-class, 22 binary). Results show consistent superiority over state-of-the-art methods, approaching 100% in several cases. For multi-class data, IMOVNO+ achieves gains of 37-57% in G-mean, 25-44% in F1-score, 25-39% in precision, and 26-43% in recall. In binary tasks, it attains near-perfect performance with improvements of 14-39%. The framework handles data scarcity and imbalance from collection and privacy limits.

</details>


### [39] [Golden Layers and Where to Find Them: Improved Knowledge Editing for Large Language Models Via Layer Gradient Analysis](https://arxiv.org/abs/2602.20207)
*Shrestha Datta,Hongfu Liu,Anshuman Chhabra*

Main category: cs.LG

TL;DR: 该论文提出了Layer Gradient Analysis (LGA)方法，通过梯度归因分析来高效识别知识编辑中的"黄金层"，避免传统方法需要多次试验的缺点。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的知识编辑通常涉及两个阶段：确定编辑层和执行参数更新。不同查询的知识可能定位在模型的不同深度，导致固定编辑层的性能差异。论文假设存在固定的"黄金层"，能够实现接近样本最优层的编辑性能。

Method: 提出了Layer Gradient Analysis (LGA)方法，通过梯度归因分析来高效估计黄金层，避免了在多个编辑运行中进行大量试验和错误。该方法使用代理数据集来识别黄金层，并能有效推广到未见过的测试集查询。

Result: 在多个基准数据集上的实验表明，LGA方法在不同类型的LLM和各种知识编辑方法中都具有有效性和鲁棒性。黄金层确实存在，且能够通过代理数据集可靠识别，并能有效推广到测试集查询。

Conclusion: 证明了固定黄金层的存在性，提出的LGA方法能够高效识别这些层，为大型语言模型的知识编辑提供了一种更有效的层选择策略，避免了传统方法的计算开销。

Abstract: Knowledge editing in Large Language Models (LLMs) aims to update the model's prediction for a specific query to a desired target while preserving its behavior on all other inputs. This process typically involves two stages: identifying the layer to edit and performing the parameter update. Intuitively, different queries may localize knowledge at different depths of the model, resulting in different sample-wise editing performance for a fixed editing layer. In this work, we hypothesize the existence of fixed golden layers that can achieve near-optimal editing performance similar to sample-wise optimal layers. To validate this hypothesis, we provide empirical evidence by comparing golden layers against ground-truth sample-wise optimal layers. Furthermore, we show that golden layers can be reliably identified using a proxy dataset and generalize effectively to unseen test set queries across datasets. Finally, we propose a novel method, namely Layer Gradient Analysis (LGA) that estimates golden layers efficiently via gradient-attribution, avoiding extensive trial-and-error across multiple editing runs. Extensive experiments on several benchmark datasets demonstrate the effectiveness and robustness of our LGA approach across different LLM types and various knowledge editing methods.

</details>


### [40] [Model Merging in the Essential Subspace](https://arxiv.org/abs/2602.20208)
*Longhua Li,Lei Qi,Qi Tian,Xin Geng*

Main category: cs.LG

TL;DR: ESM提出了一种基于特征移位主成分分析的低秩分解模型融合框架，通过多级极化缩放策略有效缓解任务干扰问题。


<details>
  <summary>Details</summary>
Motivation: 现有模型融合方法在将多个任务特定微调模型整合为多任务模型时，普遍面临任务干扰问题，导致性能下降。需要一种能够有效缓解干扰、保持核心功能的方法。

Method: 首先对参数更新引起的特征移位进行主成分分析，构建主导特征表示的本质子空间。将每个任务的参数更新矩阵投影到相应的本质子空间进行低秩分解后再融合。同时引入多级极化缩放策略，放大包含关键知识的参数，抑制冗余参数。

Result: 在多个任务集和模型规模上的广泛实验表明，该方法在多任务模型融合中实现了最先进的性能表现。

Conclusion: ESM框架通过本质子空间分析和多级极化缩放，有效缓解了模型融合中的任务干扰问题，为多任务模型融合提供了稳健的解决方案。

Abstract: Model merging aims to integrate multiple task-specific fine-tuned models derived from a shared pre-trained checkpoint into a single multi-task model without additional training. Despite extensive research, task interference remains a major obstacle that often undermines the performance of merged models. In this paper, we propose ESM (Essential Subspace Merging) , a robust framework for effective model merging. We begin by performing Principal Component Analysis (PCA) on feature shifts induced by parameter updates. The resulting principal directions span an essential subspace that dominantly influences feature representations. Each task's parameter update matrix is projected onto its respective essential subspace for low-rank decomposition before merging. This methodology mitigates inter-task interference while preserving core task-specific functionality. Furthermore, we introduce a multi-level polarized scaling strategy that amplifies parameters containing critical knowledge and suppresses redundant ones, preventing essential knowledge from being overwhelmed during fusion. Extensive experiments across multiple task sets and model scales demonstrate that our method achieves state-of-the-art performance in multi-task model merging.

</details>


### [41] [Multimodal Crystal Flow: Any-to-Any Modality Generation for Unified Crystal Modeling](https://arxiv.org/abs/2602.20210)
*Kiyoung Seong,Sungsoo Ahn,Sehui Han,Changyoung Park*

Main category: cs.LG

TL;DR: MCFlow是一个统一的多模态流模型，通过独立的原子类型和晶体结构时间变量，实现多种晶体生成任务作为不同的推理轨迹。


<details>
  <summary>Details</summary>
Motivation: 现有深度生成模型在晶体建模中大多是任务特定的，缺乏一个能跨不同生成任务共享晶体表征的统一框架。

Method: 提出多模态晶体流(MCFlow)，使用独立的原子类型和晶体结构时间变量；引入基于组成和对称性的原子排序与层次置换增强，在标准Transformer中注入强组成和晶体学先验。

Result: 在MP-20和MPTS-52基准测试中，MCFlow在多个晶体生成任务上实现了与任务特定基线竞争的性能。

Conclusion: MCFlow为晶体建模提供了一个统一的多模态框架，能够有效处理多种晶体生成任务，同时保持竞争性的性能表现。

Abstract: Crystal modeling spans a family of conditional and unconditional generation tasks across different modalities, including crystal structure prediction (CSP) and \emph{de novo} generation (DNG). While recent deep generative models have shown promising performance, they remain largely task-specific, lacking a unified framework that shares crystal representations across different generation tasks. To address this limitation, we propose \emph{Multimodal Crystal Flow (MCFlow)}, a unified multimodal flow model that realizes multiple crystal generation tasks as distinct inference trajectories via independent time variables for atom types and crystal structures. To enable multimodal flow in a standard transformer model, we introduce a composition- and symmetry-aware atom ordering with hierarchical permutation augmentation, injecting strong compositional and crystallographic priors without explicit structural templates. Experiments on the MP-20 and MPTS-52 benchmarks show that MCFlow achieves competitive performance against task-specific baselines across multiple crystal generation tasks.

</details>


### [42] [KnapSpec: Self-Speculative Decoding via Adaptive Layer Selection as a Knapsack Problem](https://arxiv.org/abs/2602.20217)
*Seongjin Cha,Gyuwan Kim,Dongsu Han,Tao Yang,Insu Han*

Main category: cs.LG

TL;DR: KnapSpec：一种无需训练的框架，通过将草稿模型选择重新表述为背包问题来最大化吞吐量，在长上下文场景中自适应选择最优草稿配置，实现高达1.47倍的加速。


<details>
  <summary>Details</summary>
Motivation: 现有的自推测解码（SSD）方法通常依赖静态启发式方法，忽略了长上下文场景中注意力的动态计算开销，导致无法充分利用硬件潜力。

Method: 将草稿模型选择重新表述为背包问题，解耦注意力层和MLP层，建模其硬件特定延迟作为上下文长度的函数，通过并行动态规划算法在线自适应识别最优草稿配置。

Result: 在Qwen3和Llama3上的实验表明，KnapSpec始终优于最先进的SSD基线，在各种基准测试中实现高达1.47倍的实时加速。

Conclusion: KnapSpec提供了一种即插即用的方法，无需额外训练或损害目标模型输出分布，即可在长序列中实现高速推理，同时首次建立了隐藏状态余弦相似度与令牌接受率之间的理论联系。

Abstract: Self-speculative decoding (SSD) accelerates LLM inference by skipping layers to create an efficient draft model, yet existing methods often rely on static heuristics that ignore the dynamic computational overhead of attention in long-context scenarios. We propose KnapSpec, a training-free framework that reformulates draft model selection as a knapsack problem to maximize tokens-per-time throughput. By decoupling Attention and MLP layers and modeling their hardware-specific latencies as functions of context length, KnapSpec adaptively identifies optimal draft configurations on the fly via a parallel dynamic programming algorithm. Furthermore, we provide the first rigorous theoretical analysis establishing cosine similarity between hidden states as a mathematically sound proxy for the token acceptance rate. This foundation allows our method to maintain high drafting faithfulness while navigating the shifting bottlenecks of real-world hardware. Our experiments on Qwen3 and Llama3 demonstrate that KnapSpec consistently outperforms state-of-the-art SSD baselines, achieving up to 1.47x wall-clock speedup across various benchmarks. Our plug-and-play approach ensures high-speed inference for long sequences without requiring additional training or compromising the target model's output distribution.

</details>


### [43] [MultiModalPFN: Extending Prior-Data Fitted Networks for Multimodal Tabular Learning](https://arxiv.org/abs/2602.20223)
*Wall Kim,Chaeyoung Song,Hanul Kim*

Main category: cs.LG

TL;DR: MMPFN扩展了TabPFN，通过模态投影器统一处理表格与非表格数据（如图像、文本），在多模态任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: TabPFN在处理表格数据方面表现良好，但无法有效整合图像、文本等异构模态数据，限制了其在医疗、营销等领域的应用。

Method: 提出MMPFN，包含每模态编码器、模态投影器和预训练基础模型。模态投影器通过多头门控MLP和交叉注意力池化器，将非表格嵌入转换为表格兼容的标记，解决多模态学习中的注意力不平衡问题。

Result: 在医疗和通用多模态数据集上的实验表明，MMPFN始终优于现有最先进方法，能有效利用非表格模态与表格特征。

Conclusion: MMPFN将先验数据拟合网络扩展到多模态场景，为异构数据学习提供了一个可扩展且有效的框架。

Abstract: Recently, TabPFN has gained attention as a foundation model for tabular data. However, it struggles to integrate heterogeneous modalities such as images and text, which are common in domains like healthcare and marketing, thereby limiting its applicability. To address this, we present the Multi-Modal Prior-data Fitted Network (MMPFN), which extends TabPFN to handle tabular and non-tabular modalities in a unified manner. MMPFN comprises per-modality encoders, modality projectors, and pre-trained foundation models. The modality projectors serve as the critical bridge, transforming non-tabular embeddings into tabular-compatible tokens for unified processing. To this end, we introduce a multi-head gated MLP and a cross-attention pooler that extract richer context from non-tabular inputs while mitigates attention imbalance issue in multimodal learning. Extensive experiments on medical and general-purpose multimodal datasets demonstrate that MMPFN consistently outperforms competitive state-of-the-art methods and effectively exploits non-tabular modalities alongside tabular features. These results highlight the promise of extending prior-data fitted networks to the multimodal setting, offering a scalable and effective framework for heterogeneous data learning. The source code is available at https://github.com/too-z/MultiModalPFN.

</details>


### [44] [Exploring Anti-Aging Literature via ConvexTopics and Large Language Models](https://arxiv.org/abs/2602.20224)
*Lana E. Yeganova,Won G. Kim,Shubo Tian,Natalie Xie,Donald C. Comeau,W. John Wilbur,Zhiyong Lu*

Main category: cs.LG

TL;DR: 提出一种基于凸优化的聚类算法，通过选择数据中的代表点来生成稳定、细粒度的主题，保证全局最优解，应用于生物医学文献分析。


<details>
  <summary>Details</summary>
Motivation: 生物医学文献的快速增长给知识组织和趋势检测带来挑战，需要可扩展且可解释的方法。传统的K-means或LDA等方法对初始化敏感且容易陷入局部最优，限制了可重复性和评估。

Method: 重新设计基于凸优化的聚类算法，通过选择数据中的代表点来生成主题，保证全局最优解，应用于约12,000篇PubMed关于衰老和长寿的文章。

Result: 该方法在衰老和长寿文献中发现经医学专家验证的主题，涵盖分子机制、膳食补充剂、体力活动和肠道微生物群等可解释主题。性能优于K-means、LDA和BERTopic，具有更好的可重复性和可解释性。

Conclusion: 该工作为开发可扩展、网络可访问的知识发现工具提供了基础，其可重复性和可解释性使其区别于常见的聚类方法。

Abstract: The rapid expansion of biomedical publications creates challenges for organizing knowledge and detecting emerging trends, underscoring the need for scalable and interpretable methods. Common clustering and topic modeling approaches such as K-means or LDA remain sensitive to initialization and prone to local optima, limiting reproducibility and evaluation. We propose a reformulation of a convex optimization based clustering algorithm that produces stable, fine-grained topics by selecting exemplars from the data and guaranteeing a global optimum. Applied to about 12,000 PubMed articles on aging and longevity, our method uncovers topics validated by medical experts. It yields interpretable topics spanning from molecular mechanisms to dietary supplements, physical activity, and gut microbiota. The method performs favorably, and most importantly, its reproducibility and interpretability distinguish it from common clustering approaches, including K-means, LDA, and BERTopic. This work provides a basis for developing scalable, web-accessible tools for knowledge discovery.

</details>


### [45] [Shape-informed cardiac mechanics surrogates in data-scarce regimes via geometric encoding and generative augmentation](https://arxiv.org/abs/2602.20306)
*Davide Carrara,Marc Hirschvogel,Francesca Bonizzoni,Stefano Pagani,Simone Pezzuto,Francesco Regazzoni*

Main category: cs.LG

TL;DR: 提出一个两阶段框架，将几何表示与物理响应学习解耦，用于数据稀缺条件下的形状感知代理建模，实现跨不同解剖结构的高效心脏力学模拟。


<details>
  <summary>Details</summary>
Motivation: 高保真心脏力学计算模型计算成本高，难以临床常规使用。代理模型可加速模拟，但在数据稀缺条件下难以泛化到不同解剖结构。

Method: 两阶段框架：1) 形状模型学习左心室几何的紧凑潜在表示，支持数据增强；2) 基于神经场的代理模型，以几何编码为条件，预测外部载荷下的心室位移。使用通用心室坐标进行位置编码，比较PCA和DeepSDF两种几何编码策略。

Result: 在理想化和患者特定数据集上，该方法实现了精确预测，能泛化到未见几何结构，并对噪声或稀疏采样输入具有鲁棒性。

Conclusion: 提出的两阶段框架在数据稀缺条件下实现了形状感知的代理建模，能够准确预测并泛化到不同解剖结构，为临床心脏力学模拟提供了实用解决方案。

Abstract: High-fidelity computational models of cardiac mechanics provide mechanistic insight into the heart function but are computationally prohibitive for routine clinical use. Surrogate models can accelerate simulations, but generalization across diverse anatomies is challenging, particularly in data-scarce settings. We propose a two-step framework that decouples geometric representation from learning the physics response, to enable shape-informed surrogate modeling under data-scarce conditions. First, a shape model learns a compact latent representation of left ventricular geometries. The learned latent space effectively encodes anatomies and enables synthetic geometries generation for data augmentation. Second, a neural field-based surrogate model, conditioned on this geometric encoding, is trained to predict ventricular displacement under external loading. The proposed architecture performs positional encoding by using universal ventricular coordinates, which improves generalization across diverse anatomies. Geometric variability is encoded using two alternative strategies, which are systematically compared: a PCA-based approach suitable for working with point cloud representations of geometries, and a DeepSDF-based implicit neural representation learned directly from point clouds. Overall, our results, obtained on idealized and patient-specific datasets, show that the proposed approaches allow for accurate predictions and generalization to unseen geometries, and robustness to noisy or sparsely sampled inputs.

</details>


### [46] [Quantitative Approximation Rates for Group Equivariant Learning](https://arxiv.org/abs/2602.20370)
*Jonathan W. Siegel,Snir Hordan,Hannah Lawrence,Ali Syed,Nadav Dym*

Main category: cs.LG

TL;DR: 该论文将传统神经网络近似理论扩展到等变学习领域，证明了等变架构与同等规模ReLU MLP在近似等变函数时具有同等表达能力。


<details>
  <summary>Details</summary>
Motivation: 尽管等变学习模型在理论上已被证明具有通用近似性质，但缺乏定量的近似速率分析。本文旨在填补这一空白，为多种等变架构提供定量的近似速率结果。

Method: 采用数学分析框架，推导了几种重要等变架构的定量近似速率，包括：置换不变的Deep Sets架构、置换等变的Sumformer和Transformer架构、基于帧平均的置换和刚体运动联合不变网络，以及一般的双Lipschitz不变模型。

Result: 证明等变架构与同等规模的ReLU多层感知机在近似等变函数时具有同等的表达能力，硬编码等变性不会导致这些模型表达能力或近似能力的损失。

Conclusion: 等变架构在保持等变性的同时，与标准神经网络具有同等的近似能力，这为等变学习模型的理论基础提供了重要的定量支持。

Abstract: The universal approximation theorem establishes that neural networks can approximate any continuous function on a compact set. Later works in approximation theory provide quantitative approximation rates for ReLU networks on the class of $α$-Hölder functions $f: [0,1]^N \to \mathbb{R}$. The goal of this paper is to provide similar quantitative approximation results in the context of group equivariant learning, where the learned $α$-Hölder function is known to obey certain group symmetries. While there has been much interest in the literature in understanding the universal approximation properties of equivariant models, very few quantitative approximation results are known for equivariant models.
  In this paper, we bridge this gap by deriving quantitative approximation rates for several prominent group-equivariant and invariant architectures. The architectures that we consider include: the permutation-invariant Deep Sets architecture; the permutation-equivariant Sumformer and Transformer architectures; joint invariance to permutations and rigid motions using invariant networks based on frame averaging; and general bi-Lipschitz invariant models. Overall, we show that equally-sized ReLU MLPs and equivariant architectures are equally expressive over equivariant functions. Thus, hard-coding equivariance does not result in a loss of expressivity or approximation power in these models.

</details>


### [47] [Learning from Trials and Errors: Reflective Test-Time Planning for Embodied LLMs](https://arxiv.org/abs/2602.21198)
*Yining Hong,Huang Huang,Manling Li,Li Fei-Fei,Jiajun Wu,Yejin Choi*

Main category: cs.LG

TL;DR: 该论文提出了一种反射性测试时间规划方法，通过反射-行动中和反射-行动后两种模式，让机器人能够在执行前生成并评估多个候选动作，在执行后更新模型，从而从错误中学习积累经验。


<details>
  <summary>Details</summary>
Motivation: 现有具身LLM虽然赋予机器人高级任务推理能力，但缺乏反思能力，导致部署时错误重复出现而无法积累成经验。受人类反思实践者启发，需要让机器人能够反思错误原因。

Method: 提出反射性测试时间规划：1) 反射-行动中：使用测试时间缩放生成并评分多个候选动作；2) 反射-行动后：使用测试时间训练更新内部反思模型和动作策略；3) 回顾性反思：重新评估早期决策并进行后见之明模型更新。

Result: 在新设计的长时域家庭基准和MuJoCo橱柜装配基准上，相比基线模型有显著提升，消融研究验证了反射-行动中和反射-行动后的互补作用。真实机器人试验展示了通过反思实现的行为修正。

Conclusion: 反射性测试时间规划使机器人能够从错误中学习，将独立试验转化为经验积累，显著提升了长期任务性能，为具身智能的持续学习提供了新思路。

Abstract: Embodied LLMs endow robots with high-level task reasoning, but they cannot reflect on what went wrong or why, turning deployment into a sequence of independent trials where mistakes repeat rather than accumulate into experience. Drawing upon human reflective practitioners, we introduce Reflective Test-Time Planning, which integrates two modes of reflection: \textit{reflection-in-action}, where the agent uses test-time scaling to generate and score multiple candidate actions using internal reflections before execution; and \textit{reflection-on-action}, which uses test-time training to update both its internal reflection model and its action policy based on external reflections after execution. We also include retrospective reflection, allowing the agent to re-evaluate earlier decisions and perform model updates with hindsight for proper long-horizon credit assignment. Experiments on our newly-designed Long-Horizon Household benchmark and MuJoCo Cupboard Fitting benchmark show significant gains over baseline models, with ablative studies validating the complementary roles of reflection-in-action and reflection-on-action. Qualitative analyses, including real-robot trials, highlight behavioral correction through reflection.

</details>


### [48] [Untied Ulysses: Memory-Efficient Context Parallelism via Headwise Chunking](https://arxiv.org/abs/2602.21196)
*Ravi Ghadia,Maksim Abraham,Sergei Vorobyov,Max Ryabinin*

Main category: cs.LG

TL;DR: UPipe是一种高效的上下文并行技术，通过注意力头级别的细粒度分块，显著减少自注意力层的激活内存使用，支持更长的上下文长度训练。


<details>
  <summary>Details</summary>
Motivation: 现有的上下文并行方法（如Ring Attention、DeepSpeed Ulysses）虽然能扩展上下文维度，但内存效率不高，限制了支持的序列长度。更先进的技术（如Fully Pipelined Distributed Transformer或激活卸载）虽然能进一步扩展上下文长度，但会牺牲训练吞吐量。

Method: UPipe采用注意力头级别的细粒度分块技术，通过更精细的内存管理来减少自注意力层的中间张量内存使用，在保持训练速度的同时突破激活内存瓶颈。

Result: UPipe将32B Transformer的注意力层中间张量内存使用减少了87.5%，在单个8×H100节点上训练Llama3-8B时支持500万token的上下文长度，比先前方法提高了25%以上，同时保持与先前上下文并行技术相当的训练速度。

Conclusion: UPipe通过注意力头级别的细粒度分块，在保持训练吞吐量的同时显著降低了内存使用，为训练超长上下文Transformer模型提供了有效的解决方案。

Abstract: Efficiently processing long sequences with Transformer models usually requires splitting the computations across accelerators via context parallelism. The dominant approaches in this family of methods, such as Ring Attention or DeepSpeed Ulysses, enable scaling over the context dimension but do not focus on memory efficiency, which limits the sequence lengths they can support. More advanced techniques, such as Fully Pipelined Distributed Transformer or activation offloading, can further extend the possible context length at the cost of training throughput. In this paper, we present UPipe, a simple yet effective context parallelism technique that performs fine-grained chunking at the attention head level. This technique significantly reduces the activation memory usage of self-attention, breaking the activation memory barrier and unlocking much longer context lengths. Our approach reduces intermediate tensor memory usage in the attention layer by as much as 87.5$\%$ for 32B Transformers, while matching previous context parallelism techniques in terms of training speed. UPipe can support the context length of 5M tokens when training Llama3-8B on a single 8$\times$H100 node, improving upon prior methods by over 25$\%$.

</details>


### [49] [Test-Time Training with KV Binding Is Secretly Linear Attention](https://arxiv.org/abs/2602.21204)
*Junchen Liu,Sven Elflein,Or Litany,Zan Gojcic,Ruilong Li*

Main category: cs.LG

TL;DR: 该论文重新审视了测试时训练（TTT）机制，挑战了传统的记忆化解释，提出TTT实际上是一种学习到的线性注意力算子，这一新视角带来了架构简化、效率提升和统一理解等实际好处。


<details>
  <summary>Details</summary>
Motivation: 当前对测试时训练（TTT）中KV绑定作为序列建模层的常见解释是将其视为在线元学习，在测试时记忆键值映射。但作者发现多个现象与这种记忆化解释相矛盾，因此需要重新审视TTT的表述。

Method: 作者重新审视TTT的表述，展示了一类广泛的TTT架构可以表达为学习到的线性注意力算子的形式。这一视角不仅解释了先前令人困惑的模型行为，还带来了架构简化、并行化实现等实际好处。

Result: 研究结果表明，TTT不应被理解为测试时记忆化，而是具有增强表示能力的学习线性注意力。这一新视角使得能够进行原则性的架构简化，提出完全并行的公式化方法，并将不同的TTT变体系统性地简化为标准线性注意力形式。

Conclusion: 该论文重新框架了TTT，将其视为学习到的线性注意力而非测试时记忆化，这一新理解不仅解释了先前难以理解的现象，还带来了架构简化、效率提升和统一理论框架等实际好处。

Abstract: Test-time training (TTT) with KV binding as sequence modeling layer is commonly interpreted as a form of online meta-learning that memorizes a key-value mapping at test time. However, our analysis reveals multiple phenomena that contradict this memorization-based interpretation. Motivated by these findings, we revisit the formulation of TTT and show that a broad class of TTT architectures can be expressed as a form of learned linear attention operator. Beyond explaining previously puzzling model behaviors, this perspective yields multiple practical benefits: it enables principled architectural simplifications, admits fully parallel formulations that preserve performance while improving efficiency, and provides a systematic reduction of diverse TTT variants to a standard linear attention form. Overall, our results reframe TTT not as test-time memorization, but as learned linear attention with enhanced representational capacity.

</details>


### [50] [From Isolation to Integration: Building an Adaptive Expert Forest for Pre-Trained Model-based Class-Incremental Learning](https://arxiv.org/abs/2602.20911)
*Ruiqi Liu,Boyu Diao,Hangda Liu,Zhulin An,Fei Wang,Yongjun Xu*

Main category: cs.LG

TL;DR: 提出SAEF方法，通过语义引导的专家森林结构组织适配器，实现更好的知识共享和类增量学习


<details>
  <summary>Details</summary>
Motivation: 现有方法冻结预训练模型并训练轻量级适配器，但将学到的知识视为简单无结构的集合，未能利用任务间的关系

Method: SAEF首先基于语义关系将任务分组为概念簇，然后在每个簇内通过合并相似任务的适配器构建平衡专家树，推理时找到并激活相关专家集，加权组合输出

Result: 在多个基准数据集上的实验表明SAEF达到了最先进的性能

Conclusion: SAEF通过结构化组织适配器实现更好的知识共享，有效提升类增量学习性能

Abstract: Class-Incremental Learning (CIL) requires models to learn new classes without forgetting old ones. A common method is to freeze a pre-trained model and train a new, lightweight adapter for each task. While this prevents forgetting, it treats the learned knowledge as a simple, unstructured collection and fails to use the relationships between tasks. To this end, we propose the Semantic-guided Adaptive Expert Forest (SAEF), a new method that organizes adapters into a structured hierarchy for better knowledge sharing. SAEF first groups tasks into conceptual clusters based on their semantic relationships. Then, within each cluster, it builds a balanced expert tree by creating new adapters from merging the adapters of similar tasks. At inference time, SAEF finds and activates a set of relevant experts from the forest for any given input. The final prediction is made by combining the outputs of these activated experts, weighted by how confident each expert is. Experiments on several benchmark datasets show that SAEF achieves SOTA performance.

</details>


### [51] [Estimation of Confidence Bounds in Binary Classification using Wilson Score Kernel Density Estimation](https://arxiv.org/abs/2602.20947)
*Thorbjørn Mosekjær Iversen,Zebin Duan,Frederik Hagelskjær*

Main category: cs.LG

TL;DR: 提出Wilson Score Kernel Density Classification方法，用于估计二元分类的置信边界，在关键检查任务中实现可靠的自动化分类。


<details>
  <summary>Details</summary>
Motivation: 深度学习二元分类器性能提升，但关键检查任务需要可靠的置信边界估计来确保系统性能达到统计显著性要求。

Method: 提出Wilson Score Kernel Density Estimator，这是一种基于核的方法，用于估计条件变化成功概率的伯努利实验置信边界。该方法可作为任何特征提取器（包括视觉基础模型）的分类头。

Result: 在四个数据集上的选择性分类评估显示，该方法性能与高斯过程分类相似，但计算复杂度更低。

Conclusion: Wilson Score Kernel Density Classification为关键操作中的二元分类提供了有效的置信边界估计方法，平衡了性能与计算效率。

Abstract: The performance and ease of use of deep learning-based binary classifiers have improved significantly in recent years. This has opened up the potential for automating critical inspection tasks, which have traditionally only been trusted to be done manually. However, the application of binary classifiers in critical operations depends on the estimation of reliable confidence bounds such that system performance can be ensured up to a given statistical significance. We present Wilson Score Kernel Density Classification, which is a novel kernel-based method for estimating confidence bounds in binary classification. The core of our method is the Wilson Score Kernel Density Estimator, which is a function estimator for estimating confidence bounds in Binomial experiments with conditionally varying success probabilities. Our method is evaluated in the context of selective classification on four different datasets, illustrating its use as a classification head of any feature extractor, including vision foundation models. Our proposed method shows similar performance to Gaussian Process Classification, but at a lower computational complexity.

</details>
