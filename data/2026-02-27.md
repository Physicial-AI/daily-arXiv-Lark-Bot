<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 30]
- [cs.LG](#cs.LG) [Total: 21]
- [cs.RO](#cs.RO) [Total: 12]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Enabling clinical use of foundation models in histopathology](https://arxiv.org/abs/2602.22347)
*Audun L. Henriksen,Ole-Johan Skrede,Lisa van der Schee,Enric Domingo,Sepp De Raedt,Ilyá Kostolomov,Jennifer Hay,Karolina Cyll,Wanja Kildal,Joakim Kalsnes,Robert W. Williams,Manohar Pradhan,John Arne Nesheim,Hanne A. Askautrud,Maria X. Isaksen,Karmele Saez de Gordoa,Miriam Cuatrecasas,Joanne Edwards,TransSCOT group,Arild Nesbakken,Neil A. Shepherd,Ian Tomlinson,Daniel-Christoph Wagner,Rachel S. Kerr,Tarjei Sveinsgjerd Hveem,Knut Liestøl,Yoshiaki Nakamura,Marco Novelli,Masaaki Miyo,Sebastian Foersch,David N. Church,Miangela M. Lacle,David J. Kerr,Andreas Kleppe*

Main category: cs.CV

TL;DR: 该研究提出了一种通过引入新颖的鲁棒性损失函数来减少计算病理学基础模型对技术变异敏感性的方法，无需重新训练基础模型本身。


<details>
  <summary>Details</summary>
Motivation: 当前计算病理学基础模型不仅捕获了生物学相关特征，还包含了前分析和扫描仪特异性变异，这些变异会偏置基于基础模型特征训练的任务特定模型的预测结果。

Method: 在训练下游任务特定模型时引入新颖的鲁棒性损失函数，使用来自8个流行计算病理学基础模型的特征，在包含27,042个WSI和6,155名患者的综合实验设置中训练数千个模型。

Result: 该方法显著提高了模型对技术变异的鲁棒性，同时通过关注生物学相关特征提高了预测准确性，成功缓解了计算病理学基础模型的鲁棒性问题。

Conclusion: 无需重新训练基础模型本身，该方法就能有效减轻计算病理学基础模型对技术变异的敏感性，使得开发适用于常规临床实践的真实世界数据的鲁棒计算病理学模型成为可能。

Abstract: Foundation models in histopathology are expected to facilitate the development of high-performing and generalisable deep learning systems. However, current models capture not only biologically relevant features, but also pre-analytic and scanner-specific variation that bias the predictions of task-specific models trained from the foundation model features. Here we show that introducing novel robustness losses during training of downstream task-specific models reduces sensitivity to technical variability. A purpose-designed comprehensive experimentation setup with 27,042 WSIs from 6155 patients is used to train thousands of models from the features of eight popular foundation models for computational pathology. In addition to a substantial improvement in robustness, we observe that prediction accuracy improves by focusing on biologically relevant features. Our approach successfully mitigates robustness issues of foundation models for computational pathology without retraining the foundation models themselves, enabling development of robust computational pathology models applicable to real-world data in routine clinical practice.

</details>


### [2] [Optimizing Neural Network Architecture for Medical Image Segmentation Using Monte Carlo Tree Search](https://arxiv.org/abs/2602.22361)
*Liping Meng,Fan Nie,Yunyun Zhang,Chao Han*

Main category: cs.CV

TL;DR: MNAS-Unet结合MCTS和NAS的动态架构搜索框架，在多个医学图像数据集上超越现有方法，搜索预算减少54%，模型参数仅0.6M且GPU内存消耗更低。


<details>
  <summary>Details</summary>
Motivation: 针对医学图像分割中神经网络架构搜索效率低、计算资源消耗大的问题，需要一种既能提升搜索效率又能保持分割精度的轻量级解决方案。

Method: 提出MNAS-Unet框架，结合蒙特卡洛树搜索(MCTS)和神经架构搜索(NAS)，动态探索有前景的网络架构；优化DownSC和UpSC单元结构，实现快速精确的模型调整。

Result: 在PROMISE12、Ultrasound Nerve、CHAOS等数据集上分割精度超越NAS-Unet和其他SOTA模型；相比NAS-Unet，架构搜索预算减少54%（139轮vs300轮）；模型仅0.6M参数，GPU内存消耗更低。

Conclusion: MNAS-Unet能在实际资源约束下提高搜索效率，同时保持有竞争力的分割精度，提升了医学图像分割模型的实用性和部署可行性。

Abstract: This paper proposes a novel medical image segmentation framework, MNAS-Unet, which combines Monte Carlo Tree Search (MCTS) and Neural Architecture Search (NAS). MNAS-Unet dynamically explores promising network architectures through MCTS, significantly enhancing the efficiency and accuracy of architecture search. It also optimizes the DownSC and UpSC unit structures, enabling fast and precise model adjustments. Experimental results demonstrate that MNAS-Unet outperforms NAS-Unet and other state-of-the-art models in segmentation accuracy on several medical image datasets, including PROMISE12, Ultrasound Nerve, and CHAOS. Furthermore, compared with NAS-Unet, MNAS-Unet reduces the architecture search budget by 54% (early stopping at 139 epochs versus 300 epochs under the same search setting), while achieving a lightweight model with only 0.6M parameters and lower GPU memory consumption, which further improves its practical applicability. These results suggest that MNAS-Unet can improve search efficiency while maintaining competitive segmentation accuracy under practical resource constraints.

</details>


### [3] [AeroDGS: Physically Consistent Dynamic Gaussian Splatting for Single-Sequence Aerial 4D Reconstruction](https://arxiv.org/abs/2602.22376)
*Hanyang Liu,Rongjun Qin*

Main category: cs.CV

TL;DR: AeroDGS是一个基于物理引导的4D高斯泼溅框架，用于单目无人机视频的动态场景重建，通过引入几何提升模块和物理引导优化来解决单目航拍中的深度模糊和运动估计问题。


<details>
  <summary>Details</summary>
Motivation: 现有4D场景重建方法在单视角航拍条件下存在局限：空间范围广、动态物体空间足迹小、运动差异大，导致深度模糊和运动估计不稳定，使得单目航拍重建成为不适定问题。

Method: 提出AeroDGS框架，包含两个核心模块：1）单目几何提升模块，从单目航拍序列重建可靠的静态和动态几何；2）物理引导优化模块，引入可微分的地面支撑、垂直稳定性和轨迹平滑性先验，将模糊图像线索转化为物理一致的运动。

Result: 在合成和真实无人机场景上的实验表明，AeroDGS在动态航拍环境中优于现有最先进方法，实现了更优的重建保真度。作者还构建了一个包含不同高度和运动条件的真实无人机数据集用于评估。

Conclusion: AeroDGS通过结合几何重建和物理引导优化，有效解决了单目无人机视频中的动态场景重建问题，为航拍条件下的4D场景建模提供了鲁棒且一致的解决方案。

Abstract: Recent advances in 4D scene reconstruction have significantly improved dynamic modeling across various domains. However, existing approaches remain limited under aerial conditions with single-view capture, wide spatial range, and dynamic objects of limited spatial footprint and large motion disparity. These challenges cause severe depth ambiguity and unstable motion estimation, making monocular aerial reconstruction inherently ill-posed. To this end, we present AeroDGS, a physics-guided 4D Gaussian splatting framework for monocular UAV videos. AeroDGS introduces a Monocular Geometry Lifting module that reconstructs reliable static and dynamic geometry from a single aerial sequence, providing a robust basis for dynamic estimation. To further resolve monocular ambiguity, we propose a Physics-Guided Optimization module that incorporates differentiable ground-support, upright-stability, and trajectory-smoothness priors, transforming ambiguous image cues into physically consistent motion. The framework jointly refines static backgrounds and dynamic entities with stable geometry and coherent temporal evolution. We additionally build a real-world UAV dataset that spans various altitudes and motion conditions to evaluate dynamic aerial reconstruction. Experiments on synthetic and real UAV scenes demonstrate that AeroDGS outperforms state-of-the-art methods, achieving superior reconstruction fidelity in dynamic aerial environments.

</details>


### [4] [Enhancing Renal Tumor Malignancy Prediction: Deep Learning with Automatic 3D CT Organ Focused Attention](https://arxiv.org/abs/2602.22381)
*Zhengkang Fan,Chengkun Sun,Russell Terry,Jie Xu,Longin Jan Latecki*

Main category: cs.CV

TL;DR: 提出一种基于器官聚焦注意力损失函数的深度学习框架，无需手动分割即可从3D肾CT图像预测恶性肿瘤，在多个数据集上优于传统需要分割的方法。


<details>
  <summary>Details</summary>
Motivation: 当前肾肿瘤恶性预测依赖3D CT图像，但传统方法需要手动分割肿瘤区域以减少噪声，这过程耗时、昂贵且依赖专家知识，限制了临床应用的效率。

Method: 开发了基于器官聚焦注意力损失函数的深度学习框架，通过修改图像补丁的注意力机制，使器官补丁仅关注其他器官补丁，从而无需在部署时进行3D肾CT图像分割。

Result: 在UF IDR私有数据集上获得AUC 0.685和F1分数0.872，在公开KiTS21数据集上获得AUC 0.760和F1分数0.852，性能超越依赖分割裁剪的传统模型。

Conclusion: 该框架提供了一种无需分割的高效可靠肾恶性肿瘤预测方法，能够提升临床诊断决策的准确性和实用性。

Abstract: Accurate prediction of malignancy in renal tumors is crucial for informing clinical decisions and optimizing treatment strategies. However, existing imaging modalities lack the necessary accuracy to reliably predict malignancy before surgical intervention. While deep learning has shown promise in malignancy prediction using 3D CT images, traditional approaches often rely on manual segmentation to isolate the tumor region and reduce noise, which enhances predictive performance. Manual segmentation, however, is labor-intensive, costly, and dependent on expert knowledge. In this study, a deep learning framework was developed utilizing an Organ Focused Attention (OFA) loss function to modify the attention of image patches so that organ patches attend only to other organ patches. Hence, no segmentation of 3D renal CT images is required at deployment time for malignancy prediction. The proposed framework achieved an AUC of 0.685 and an F1-score of 0.872 on a private dataset from the UF Integrated Data Repository (IDR), and an AUC of 0.760 and an F1-score of 0.852 on the publicly available KiTS21 dataset. These results surpass the performance of conventional models that rely on segmentation-based cropping for noise reduction, demonstrating the frameworks ability to enhance predictive accuracy without explicit segmentation input. The findings suggest that this approach offers a more efficient and reliable method for malignancy prediction, thereby enhancing clinical decision-making in renal cancer diagnosis.

</details>


### [5] [Vision Transformers Need More Than Registers](https://arxiv.org/abs/2602.22394)
*Cheng Shi,Yizhou Yu,Sibei Yang*

Main category: cs.CV

TL;DR: 本文发现ViT存在惰性聚合行为，使用语义无关的背景patch作为捷径来表征全局语义，并提出选择性集成patch特征的方法来改善性能。


<details>
  <summary>Details</summary>
Motivation: 尽管ViT在大规模预训练后能为下游任务提供通用表示，但不同监督范式和下游任务中广泛观察到ViT存在伪影。通过系统分析，发现这些伪影的根本机制尚未得到充分阐明。

Method: 通过系统分析发现ViT存在惰性聚合行为，即使用语义无关的背景patch作为捷径来表征全局语义。解决方案是选择性集成patch特征到CLS token中，减少背景主导捷径的影响。

Result: 在12个基准测试（包括标签监督、文本监督和自监督）上，该方法能持续改善性能。

Conclusion: 这项工作为理解ViT行为提供了新视角，揭示了惰性聚合行为是ViT伪影的根源，并提出了有效的解决方案。

Abstract: Vision Transformers (ViTs), when pre-trained on large-scale data, provide general-purpose representations for diverse downstream tasks. However, artifacts in ViTs are widely observed across different supervision paradigms and downstream tasks. Through systematic analysis of artifacts in ViTs, we find that their fundamental mechanisms have yet to be sufficiently elucidated. In this paper, through systematic analysis, we conclude that these artifacts originate from a lazy aggregation behavior: ViT uses semantically irrelevant background patches as shortcuts to represent global semantics, driven by global attention and Coarse-grained semantic supervision. Our solution selectively integrates patch features into the CLS token, reducing the influence of background-dominated shortcuts and consistently improving performance across 12 benchmarks under label-, text-, and self-supervision. We hope this work offers a new perspective on ViT behavior.

</details>


### [6] [CLIP Is Shortsighted: Paying Attention Beyond the First Sentence](https://arxiv.org/abs/2602.22419)
*Marc-Antoine Lavoie,Anas Mahmoud,Aldo Zaimi,Arsene Fansi Tchango,Steven L. Waslander*

Main category: cs.CV

TL;DR: DeBias-CLIP通过移除长文本训练中的开头摘要句，并应用句子子采样和文本标记填充，解决了CLIP模型在长文本对齐中的偏差问题，提升了长文本检索性能。


<details>
  <summary>Details</summary>
Motivation: CLIP模型在互联网规模数据上进行图像-文本对比学习，但其预训练主要依赖图像与短标题配对，导致模型偏向编码简单对象描述，在复杂场景和密集描述上对齐效果较差。虽然近期工作通过在小规模长标题数据集上微调来缓解此问题，但作者发现一个重要共同偏差：无论是人工还是LLM生成的长标题，通常以一句话摘要开头，然后才是详细描述。这种结构在训练中形成捷径，使注意力集中在开头句子和早期标记上，削弱了与标题其余部分的对齐。

Method: 提出DeBias-CLIP方法：1）在训练时移除摘要句；2）应用句子子采样，从标题中随机选择句子进行训练；3）使用文本标记填充，将监督信号分配到所有标记位置。该方法无需额外可训练参数，可作为Long-CLIP的即插即用替代方案。

Result: DeBias-CLIP在长文本检索任务上达到最先进水平，同时改善了短文本检索性能，并且对句子顺序排列的敏感性更低。

Conclusion: DeBias-CLIP通过解决长标题训练中的结构偏差问题，有效提升了CLIP模型在复杂文本对齐上的能力，为多模态检索提供了更好的解决方案。

Abstract: CLIP models learn transferable multi-modal features via image-text contrastive learning on internet-scale data. They are widely used in zero-shot classification, multi-modal retrieval, text-to-image diffusion, and as image encoders in large vision-language models. However, CLIP's pretraining is dominated by images paired with short captions, biasing the model toward encoding simple descriptions of salient objects and leading to coarse alignment on complex scenes and dense descriptions. While recent work mitigates this by fine-tuning on small-scale long-caption datasets, we identify an important common bias: both human- and LLM-generated long captions typically begin with a one-sentence summary followed by a detailed description. We show that this acts as a shortcut during training, concentrating attention on the opening sentence and early tokens and weakening alignment over the rest of the caption. To resolve this, we introduce DeBias-CLIP, which removes the summary sentence during training and applies sentence sub-sampling and text token padding to distribute supervision across all token positions. DeBias-CLIP achieves state-of-the-art long-text retrieval, improves short-text retrieval, and is less sensitive to sentence order permutations. It is a drop-in replacement for Long-CLIP with no additional trainable parameters.

</details>


### [7] [SimpleOCR: Rendering Visualized Questions to Teach MLLMs to Read](https://arxiv.org/abs/2602.22426)
*Yibo Peng,Peng Xia,Ding Zhong,Kaide Zeng,Siwei Han,Yiyang Zhou,Jiaqi Liu,Ruiyi Zhang,Huaxiu Yao*

Main category: cs.CV

TL;DR: 该论文提出SimpleOCR方法，通过可视化问题设置诊断MLLMs的视觉文本理解能力，发现模型存在"模态惰性"问题，即使具备OCR能力仍依赖文本提示中的参数捷径。


<details>
  <summary>Details</summary>
Motivation: 研究多模态大语言模型的视觉文本理解机制：这些模型是真正"读取"图像中的文本，还是仅仅依赖文本提示中的参数捷径？

Method: 提出可视化问题设置，将文本查询直接渲染到图像上，强制模型进行视觉参与。然后提出SimpleOCR训练策略，通过将训练样本转换为随机样式的VQ格式，使文本捷径失效，强制模型激活和优化其视觉文本提取路径。

Result: 在Qwen2.5-VL上发现能力-利用差距：尽管具备强OCR能力，但在VQ设置下性能下降高达12.7%。SimpleOCR在四个代表性OOD基准上超过基础模型5.4%，比基于原始图像的GRPO高出2.7%，且具有极高数据效率（仅需8.5K样本）。

Conclusion: MLLMs存在"模态惰性"问题，SimpleOCR通过结构约束有效解决了这一问题，无需架构修改即可获得稳健改进，并能与先进RL策略无缝集成。

Abstract: Despite the rapid advancements in Multimodal Large Language Models (MLLMs), a critical question regarding their visual grounding mechanism remains unanswered: do these models genuinely ``read'' text embedded in images, or do they merely rely on parametric shortcuts in the text prompt? In this work, we diagnose this issue by introducing the Visualized-Question (VQ) setting, where text queries are rendered directly onto images to structurally mandate visual engagement. Our diagnostic experiments on Qwen2.5-VL reveal a startling capability-utilization gap: despite possessing strong OCR capabilities, models suffer a performance degradation of up to 12.7% in the VQ setting, exposing a deep-seated ``modality laziness.'' To bridge this gap, we propose SimpleOCR, a plug-and-play training strategy that imposes a structural constraint on the learning process. By transforming training samples into the VQ format with randomized styles, SimpleOCR effectively invalidates text-based shortcuts, compelling the model to activate and optimize its visual text extraction pathways. Empirically, SimpleOCR yields robust gains without architectural modifications. On four representative OOD benchmarks, it surpasses the base model by 5.4% and GRPO based on original images by 2.7%, while exhibiting extreme data efficiency, achieving superior performance with 30x fewer samples (8.5K) than recent RL-based methods. Furthermore, its plug-and-play nature allows seamless integration with advanced RL strategies like NoisyRollout to yield complementary improvements. Code is available at https://github.com/aiming-lab/SimpleOCR.

</details>


### [8] [Exploring Multimodal LMMs for Online Episodic Memory Question Answering on the Edge](https://arxiv.org/abs/2602.22455)
*Giuseppe Lando,Rosario Forte,Antonino Furnari*

Main category: cs.CV

TL;DR: 该论文研究了在边缘设备上使用多模态大语言模型进行实时在线情景记忆问答的可行性，通过双线程异步架构在资源受限环境下实现隐私保护的记忆检索。


<details>
  <summary>Details</summary>
Motivation: 云卸载虽然常见，但会带来隐私和延迟问题，特别是对于可穿戴助手。因此需要在边缘设备上实现隐私保护的情景记忆检索系统。

Method: 采用双线程异步架构：描述符线程持续将视频转换为轻量化文本记忆，问答线程基于文本记忆推理回答查询。在资源受限条件下实现流式约束。

Result: 在QAEgo4D-Closed基准测试中，消费级8GB GPU配置达到51.76%准确率和0.41秒TTFT；企业级服务器达到54.40%准确率和0.88秒TTFT；云方案为56.00%准确率。

Conclusion: 边缘设备上的多模态大语言模型能够实现具有竞争力的情景记忆问答性能，在隐私保护和延迟方面具有优势，展示了边缘解决方案的潜力。

Abstract: We investigate the feasibility of using Multimodal Large Language Models (MLLMs) for real-time online episodic memory question answering. While cloud offloading is common, it raises privacy and latency concerns for wearable assistants, hence we investigate implementation on the edge. We integrated streaming constraints into our question answering pipeline, which is structured into two asynchronous threads: a Descriptor Thread that continuously converts video into a lightweight textual memory, and a Question Answering (QA) Thread that reasons over the textual memory to answer queries. Experiments on the QAEgo4D-Closed benchmark analyze the performance of Multimodal Large Language Models (MLLMs) within strict resource boundaries, showing promising results also when compared to clound-based solutions. Specifically, an end-to-end configuration running on a consumer-grade 8GB GPU achieves 51.76% accuracy with a Time-To-First-Token (TTFT) of 0.41s. Scaling to a local enterprise-grade server yields 54.40% accuracy with a TTFT of 0.88s. In comparison, a cloud-based solution obtains an accuracy of 56.00%. These competitive results highlight the potential of edge-based solutions for privacy-preserving episodic memory retrieval.

</details>


### [9] [MammoWise: Multi-Model Local RAG Pipeline for Mammography Report Generation](https://arxiv.org/abs/2602.22462)
*Raiyan Jahangir,Nafiz Imtiaz Khan,Amritanand Sudheerkumar,Vladimir Filkov*

Main category: cs.CV

TL;DR: MammoWise是一个本地多模型管道，将开源视觉语言模型转化为乳腺X光片报告生成器和多任务分类器，支持多种提示方法和检索增强生成，在保护隐私的同时提高报告质量。


<details>
  <summary>Details</summary>
Motivation: 乳腺X光筛查工作量大、时间敏感且文档要求高，放射科医生需要将细微视觉发现转化为一致的BI-RADS评估、乳腺密度分类和结构化报告。现有视觉语言模型多依赖封闭云系统或紧耦合架构，限制了隐私性、可重复性和适应性。

Method: 开发了MammoWise本地多模型管道，支持任何Ollama托管的视觉语言模型和乳腺X光数据集，支持零样本、少样本和思维链提示，可选多模态检索增强生成（RAG）。评估了MedGemma、LLaVA-Med和Qwen2.5-VL模型，使用参数高效微调（QLoRA）提升性能。

Result: 报告生成质量稳定且通过少样本提示和RAG得到改善。分类任务可行但对模型和数据集选择敏感。MedGemma经QLoRA微调后可靠性显著提升：BI-RADS准确率0.7545，密度准确率0.8840，钙化准确率0.9341，同时保持报告质量。

Conclusion: MammoWise为部署本地视觉语言模型进行乳腺X光报告提供了一个实用且可扩展的框架，在统一且可重复的工作流程中平衡了隐私保护、适应性和性能。

Abstract: Screening mammography is high volume, time sensitive, and documentation heavy. Radiologists must translate subtle visual findings into consistent BI-RADS assessments, breast density categories, and structured narrative reports. While recent Vision Language Models (VLMs) enable image-to-text reporting, many rely on closed cloud systems or tightly coupled architectures that limit privacy, reproducibility, and adaptability. We present MammoWise, a local multi-model pipeline that transforms open source VLMs into mammogram report generators and multi-task classifiers. MammoWise supports any Ollama-hosted VLM and mammography dataset, and enables zero-shot, few-shot, and Chain-of-Thought prompting, with optional multimodal Retrieval Augmented Generation (RAG) using a vector database for case-specific context. We evaluate MedGemma, LLaVA-Med, and Qwen2.5-VL on VinDr-Mammo and DMID datasets, assessing report quality (BERTScore, ROUGE-L), BI-RADS classification, breast density, and key findings. Report generation is consistently strong and improves with few-shot prompting and RAG. Classification is feasible but sensitive to model and dataset choice. Parameter-efficient fine-tuning (QLoRA) of MedGemma improves reliability, achieving BI-RADS accuracy of 0.7545, density accuracy of 0.8840, and calcification accuracy of 0.9341 while preserving report quality. MammoWise provides a practical and extensible framework for deploying local VLMs for mammography reporting within a unified and reproducible workflow.

</details>


### [10] [SwiftNDC: Fast Neural Depth Correction for High-Fidelity 3D Reconstruction](https://arxiv.org/abs/2602.22565)
*Kang Han,Wei Xiang,Lu Yu,Mathew Wyatt,Gaowen Liu,Ramana Rao Kompella*

Main category: cs.CV

TL;DR: SwiftNDC是一个快速3D重建框架，通过神经深度修正场生成跨视图一致深度图，然后通过反投影和重投影误差过滤生成密集点云，显著加速3D高斯溅射的网格重建和提升新视角合成质量。


<details>
  <summary>Details</summary>
Motivation: 现有深度引导的3D重建方法存在尺度漂移、多视图不一致、需要大量细化才能获得高保真几何的问题，需要一个快速且通用的框架来解决这些问题。

Method: 提出神经深度修正场生成跨视图一致的深度图，通过反投影和鲁棒的重投影误差过滤生成密集点云，为下游重建提供干净均匀的几何初始化，显著加速3D高斯溅射的网格重建。

Result: 在五个数据集上的综合研究表明，SwiftNDC能持续减少精确网格重建的运行时间，提升新视角合成的渲染保真度，证明了神经深度修正与鲁棒几何初始化结合的有效性。

Conclusion: SwiftNDC通过神经深度修正和鲁棒几何初始化的结合，实现了高保真且高效的3D重建，显著加速了网格重建过程并提升了新视角合成的质量。

Abstract: Depth-guided 3D reconstruction has gained popularity as a fast alternative to optimization-heavy approaches, yet existing methods still suffer from scale drift, multi-view inconsistencies, and the need for substantial refinement to achieve high-fidelity geometry. Here, we propose SwiftNDC, a fast and general framework built around a Neural Depth Correction field that produces cross-view consistent depth maps. From these refined depths, we generate a dense point cloud through back-projection and robust reprojection-error filtering, obtaining a clean and uniformly distributed geometric initialization for downstream reconstruction. This reliable dense geometry substantially accelerates 3D Gaussian Splatting (3DGS) for mesh reconstruction, enabling high-quality surfaces with significantly fewer optimization iterations. For novel-view synthesis, SwiftNDC can also improve 3DGS rendering quality, highlighting the benefits of strong geometric initialization. We conduct a comprehensive study across five datasets, including two for mesh reconstruction, as well as three for novel-view synthesis. SwiftNDC consistently reduces running time for accurate mesh reconstruction and boosts rendering fidelity for view synthesis, demonstrating the effectiveness of combining neural depth refinement with robust geometric initialization for high-fidelity and efficient 3D reconstruction.

</details>


### [11] [Instruction-based Image Editing with Planning, Reasoning, and Generation](https://arxiv.org/abs/2602.22624)
*Liya Ji,Chenyang Qi,Qifeng Chen*

Main category: cs.CV

TL;DR: 提出了一种基于多模态思维链的指令图像编辑方法，通过分步推理提升复杂场景的编辑质量


<details>
  <summary>Details</summary>
Motivation: 现有指令图像编辑方法依赖单一模态理解模型，限制了编辑质量。本文旨在通过多模态模型连接理解和生成，为基于指令的图像编辑提供智能能力，处理更复杂场景

Method: 将指令编辑任务分解为三个多模态思维链步骤：1) CoT规划：大语言模型推理合适的子提示；2) 编辑区域推理：训练基于指令的编辑区域生成网络；3) 编辑：提出基于提示引导的指令编辑网络，在大规模文本到图像扩散模型基础上接受提示进行生成

Result: 在复杂真实世界图像上展示了具有竞争力的编辑能力

Conclusion: 通过多模态思维链方法有效连接理解和生成，提升了指令图像编辑在复杂场景下的性能

Abstract: Editing images via instruction provides a natural way to generate interactive content, but it is a big challenge due to the higher requirement of scene understanding and generation. Prior work utilizes a chain of large language models, object segmentation models, and editing models for this task. However, the understanding models provide only a single modality ability, restricting the editing quality. We aim to bridge understanding and generation via a new multi-modality model that provides the intelligent abilities to instruction-based image editing models for more complex cases. To achieve this goal, we individually separate the instruction editing task with the multi-modality chain of thought prompts, i.e., Chain-of-Thought (CoT) planning, editing region reasoning, and editing. For Chain-of-Thought planning, the large language model could reason the appropriate sub-prompts considering the instruction provided and the ability of the editing network. For editing region reasoning, we train an instruction-based editing region generation network with a multi-modal large language model. Finally, a hint-guided instruction-based editing network is proposed for editing image generations based on the sizeable text-to-image diffusion model to accept the hints for generation. Extensive experiments demonstrate that our method has competitive editing abilities on complex real-world images.

</details>


### [12] [QuadSync: Quadrifocal Tensor Synchronization via Tucker Decomposition](https://arxiv.org/abs/2602.22639)
*Daniel Miao,Gilad Lerman,Joe Kileel*

Main category: cs.CV

TL;DR: 该论文提出了一个基于四焦点张量的同步框架，通过Tucker分解和优化算法从多视图图像中恢复相机参数，挑战了四焦点张量不实用的传统观念。


<details>
  <summary>Details</summary>
Motivation: 在运动恢复结构中，四焦点张量比成对对应物（本质矩阵）包含更多信息，但传统上被认为不实用且仅具有理论价值。本研究旨在挑战这一观念，证明四焦点张量在实际应用中的价值。

Method: 提出新的四焦点张量同步框架：构建块四焦点张量，证明其具有Tucker分解形式，因子矩阵为堆叠相机矩阵，具有(4,4,4,4)的多线性秩。开发首个四焦点张量同步算法，结合Tucker分解、交替方向乘子法和迭代重加权最小二乘法。建立块四焦点、三焦点和双焦点张量之间的关系，并引入联合同步这三种实体的算法。

Result: 数值实验表明，该方法在现代数据集上表现有效，证明了在同步中使用高阶信息的潜力和重要性。

Conclusion: 四焦点张量在实际应用中具有实用价值，通过提出的同步框架可以有效恢复相机参数，为运动恢复结构提供了新的高阶信息利用途径。

Abstract: In structure from motion, quadrifocal tensors capture more information than their pairwise counterparts (essential matrices), yet they have often been thought of as impractical and only of theoretical interest. In this work, we challenge such beliefs by providing a new framework to recover $n$ cameras from the corresponding collection of quadrifocal tensors. We form the block quadrifocal tensor and show that it admits a Tucker decomposition whose factor matrices are the stacked camera matrices, and which thus has a multilinear rank of (4,~4,~4,~4) independent of $n$. We develop the first synchronization algorithm for quadrifocal tensors, using Tucker decomposition, alternating direction method of multipliers, and iteratively reweighted least squares. We further establish relationships between the block quadrifocal, trifocal, and bifocal tensors, and introduce an algorithm that jointly synchronizes these three entities. Numerical experiments demonstrate the effectiveness of our methods on modern datasets, indicating the potential and importance of using higher-order information in synchronization.

</details>


### [13] [Denoising as Path Planning: Training-Free Acceleration of Diffusion Models with DPCache](https://arxiv.org/abs/2602.22654)
*Bowen Cui,Yuanbin Wang,Huajiang Xu,Biaolong Chen,Aixi Zhang,Hao Jiang,Zhengzheng Jin,Xu Liu,Pipei Huang*

Main category: cs.CV

TL;DR: DPCache：一种基于全局路径规划的免训练扩散模型加速框架，通过动态规划选择关键时间步，在保持质量的同时实现显著加速


<details>
  <summary>Details</summary>
Motivation: 扩散模型虽然生成效果好，但多步迭代采样计算开销大。现有缓存方法使用固定或局部自适应调度，未考虑去噪轨迹的全局结构，容易导致误差累积和视觉伪影。

Method: 将扩散采样加速问题形式化为全局路径规划问题。构建路径感知成本张量来量化跳过时间步的路径相关误差，然后使用动态规划选择最小化总路径成本的关键时间步序列。推理时只在关键时间步进行完整计算，中间输出通过缓存特征高效预测。

Result: 在DiT、FLUX和HunyuanVideo上的实验表明，DPCache在4.87倍加速下获得+0.031 ImageReward提升，在3.54倍加速下甚至超过完整步长基线+0.028 ImageReward，优于现有加速方法。

Conclusion: DPCache通过全局路径感知调度框架，在保持扩散模型生成质量的同时实现显著加速，为扩散模型的实际部署提供了有效的免训练加速解决方案。

Abstract: Diffusion models have demonstrated remarkable success in image and video generation, yet their practical deployment remains hindered by the substantial computational overhead of multi-step iterative sampling. Among acceleration strategies, caching-based methods offer a training-free and effective solution by reusing or predicting features across timesteps. However, existing approaches rely on fixed or locally adaptive schedules without considering the global structure of the denoising trajectory, often leading to error accumulation and visual artifacts. To overcome this limitation, we propose DPCache, a novel training-free acceleration framework that formulates diffusion sampling acceleration as a global path planning problem. DPCache constructs a Path-Aware Cost Tensor from a small calibration set to quantify the path-dependent error of skipping timesteps conditioned on the preceding key timestep. Leveraging this tensor, DPCache employs dynamic programming to select an optimal sequence of key timesteps that minimizes the total path cost while preserving trajectory fidelity. During inference, the model performs full computations only at these key timesteps, while intermediate outputs are efficiently predicted using cached features. Extensive experiments on DiT, FLUX, and HunyuanVideo demonstrate that DPCache achieves strong acceleration with minimal quality loss, outperforming prior acceleration methods by $+$0.031 ImageReward at 4.87$\times$ speedup and even surpassing the full-step baseline by $+$0.028 ImageReward at 3.54$\times$ speedup on FLUX, validating the effectiveness of our path-aware global scheduling framework. Code will be released at https://github.com/argsss/DPCache.

</details>


### [14] [WaterVideoQA: ASV-Centric Perception and Rule-Compliant Reasoning via Multi-Modal Agents](https://arxiv.org/abs/2602.22923)
*Runwei Guan,Shaofeng Liang,Ningwei Ouyang,Weichen Fei,Shanliang Yao,Wei Dai,Chenhao Ge,Penglei Sun,Xiaohui Zhu,Tao Huang,Ryan Wen Liu,Hui Xiong*

Main category: cs.CV

TL;DR: WaterVideoQA是首个面向全水域环境的大规模视频问答基准，包含3,029个视频片段和五级认知框架，同时提出NaviMind多代理神经符号系统，显著提升自主水面舰艇的认知推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前自主导航系统在被动感知方面取得显著进展，但在知识驱动的交互式环境认知方面存在空白。特别是在高风险的海事导航领域，需要将原始视觉感知与复杂认知推理相结合，这是自主水面舰艇执行安全精确操作的关键前提。

Method: 提出WaterVideoQA基准，涵盖6种不同水道类别的3,029个视频片段，包含多变光照和动态天气等变量，采用五级分层认知框架。同时开发NaviMind多代理神经符号系统，整合自适应语义路由、情境感知分层推理和自主自反验证三大核心技术。

Result: 实验结果表明，该框架显著超越现有基线，在动态海事环境中建立了智能可信交互的新范式，使自主水面舰艇从浅层的模式匹配转向符合法规、可解释的决策制定。

Conclusion: WaterVideoQA基准和NaviMind系统为海事自主导航建立了新的认知推理标准，实现了从被动感知到知识驱动交互式环境认知的转变，为动态水域环境中的智能可信交互设定了新范式。

Abstract: While autonomous navigation has achieved remarkable success in passive perception (e.g., object detection and segmentation), it remains fundamentally constrained by a void in knowledge-driven, interactive environmental cognition. In the high-stakes domain of maritime navigation, the ability to bridge the gap between raw visual perception and complex cognitive reasoning is not merely an enhancement but a critical prerequisite for Autonomous Surface Vessels to execute safe and precise maneuvers. To this end, we present WaterVideoQA, the first large-scale, comprehensive Video Question Answering benchmark specifically engineered for all-waterway environments. This benchmark encompasses 3,029 video clips across six distinct waterway categories, integrating multifaceted variables such as volatile lighting and dynamic weather to rigorously stress-test ASV capabilities across a five-tier hierarchical cognitive framework. Furthermore, we introduce NaviMind, a pioneering multi-agent neuro-symbolic system designed for open-ended maritime reasoning. By synergizing Adaptive Semantic Routing, Situation-Aware Hierarchical Reasoning, and Autonomous Self-Reflective Verification, NaviMind transitions ASVs from superficial pattern matching to regulation-compliant, interpretable decision-making. Experimental results demonstrate that our framework significantly transcends existing baselines, establishing a new paradigm for intelligent, trustworthy interaction in dynamic maritime environments.

</details>


### [15] [IRSDE-Despeckle: A Physics-Grounded Diffusion Model for Generalizable Ultrasound Despeckling](https://arxiv.org/abs/2602.22717)
*Shuoqi Chen,Yujia Wu,Geoffrey P. Luke*

Main category: cs.CV

TL;DR: 基于扩散模型的超声去斑方法，通过仿真配对数据训练，在保持解剖结构的同时抑制斑点噪声，优于传统和近期学习方法。


<details>
  <summary>Details</summary>
Motivation: 超声成像虽然实时无创，但斑点噪声和伪影会降低图像质量，影响诊断解读。现有方法在去除斑点噪声的同时难以保持解剖结构的边缘和对比度。

Method: 采用基于随机微分方程的扩散模型框架进行图像恢复。通过Matlab超声工具箱从无斑点的磁共振图像仿真生成大规模配对训练数据，实现有监督训练。模型通过交叉模型方差量化预测不确定性。

Result: 在模拟测试集上，该方法持续优于经典滤波器和近期基于学习的去斑基线方法。不确定性量化显示，较高的不确定性区域与较高的重建误差相关，可作为困难区域的实用指标。评估发现对仿真探头设置敏感，存在域偏移问题。

Conclusion: 扩散模型在超声去斑任务中表现出色，但仿真与真实数据间的域偏移问题表明需要多样化的训练和适应性调整，以实现稳健的临床部署。不确定性量化提供了有价值的质量评估指标。

Abstract: Ultrasound imaging is widely used for real-time, noninvasive diagnosis, but speckle and related artifacts reduce image quality and can hinder interpretation. We present a diffusion-based ultrasound despeckling method built on the Image Restoration Stochastic Differential Equations framework. To enable supervised training, we curate large paired datasets by simulating ultrasound images from speckle-free magnetic resonance images using the Matlab UltraSound Toolbox. The proposed model reconstructs speckle-suppressed images while preserving anatomically meaningful edges and contrast. On a held-out simulated test set, our approach consistently outperforms classical filters and recent learning-based despeckling baselines. We quantify prediction uncertainty via cross-model variance and show that higher uncertainty correlates with higher reconstruction error, providing a practical indicator of difficult or failure-prone regions. Finally, we evaluate sensitivity to simulation probe settings and observe domain shift, motivating diversified training and adaptation for robust clinical deployment.

</details>


### [16] [SPATIALALIGN: Aligning Dynamic Spatial Relationships in Video Generation](https://arxiv.org/abs/2602.22745)
*Fengming Liu,Tat-Jen Cham,Chuanxia Zheng*

Main category: cs.CV

TL;DR: SPATIALALIGN是一个自改进框架，通过零阶正则化DPO微调T2V模型，使其更好地对齐文本提示中的动态空间关系，并提出了基于几何的DSR-SCORE评估指标。


<details>
  <summary>Details</summary>
Motivation: 当前文本到视频生成器过于关注美学质量，而忽略了生成视频中的空间约束，无法准确描绘文本提示中指定的动态空间关系。

Method: 提出SPATIALALIGN框架，使用零阶正则化直接偏好优化微调T2V模型；设计了基于几何的DSR-SCORE评估指标来量化视频与动态空间关系的对齐程度；构建了包含多样动态空间关系的文本-视频对数据集。

Result: 微调后的模型在空间关系描绘方面显著优于基线模型，证明了框架的有效性。

Conclusion: SPATIALALIGN框架成功提升了T2V模型对动态空间关系的描绘能力，为空间约束对齐提供了有效的解决方案。

Abstract: Most text-to-video (T2V) generators prioritize aesthetic quality, but often ignoring the spatial constraints in the generated videos. In this work, we present SPATIALALIGN, a self-improvement framework that enhances T2V models capabilities to depict Dynamic Spatial Relationships (DSR) specified in text prompts. We present a zeroth-order regularized Direct Preference Optimization (DPO) to fine-tune T2V models towards better alignment with DSR. Specifically, we design DSR-SCORE, a geometry-based metric that quantitatively measures the alignment between generated videos and the specified DSRs in prompts, which is a step forward from prior works that rely on VLM for evaluation. We also conduct a dataset of text-video pairs with diverse DSRs to facilitate the study. Extensive experiments demonstrate that our fine-tuned model significantly out performs the baseline in spatial relationships. The code will be released in Link.

</details>


### [17] [TrajTok: Learning Trajectory Tokens enables better Video Understanding](https://arxiv.org/abs/2602.22779)
*Chenhao Zheng,Jieyu Zhang,Jianing Zhang,Weikai Huang,Ashutosh Kumar,Quan Kong,Oncel Tuzel,Chun-Liang Li,Ranjay Krishna*

Main category: cs.CV

TL;DR: TrajTok是一个端到端的视频分词器模块，通过统一的段器在时空维度上隐式聚类像素直接生成物体轨迹，实现与视频时长无关的自适应分词粒度，显著提升视频理解效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频模型中的分词方法（如patchification）会产生过多冗余token，严重限制视频处理效率和可扩展性。基于轨迹的分词器虽然能解耦视频时长与token数量，但依赖复杂的外部分割和跟踪流程，速度慢且任务无关。

Method: 提出TrajTok端到端视频分词器模块，包含统一的段器在时空维度对像素进行隐式聚类，直接生成物体轨迹。模块与视频模型完全集成并针对下游目标联合训练，根据语义复杂度动态调整分词粒度。

Result: TrajTok实现的视频CLIP模型（TrajViT2）在分类和检索基准上取得最佳准确率，效率与最佳token合并方法相当。作为多功能组件，TrajTok还可作为预训练视觉特征的探测头（TrajAdapter）或视觉语言模型的对齐连接器（TrajVLM），在长视频推理中表现尤其出色。

Conclusion: TrajTok通过将轨迹生成与视频模型完全集成，实现了高效、自适应的视频分词，显著提升视频理解性能，同时保持了轻量级和高效性，展示了其在多种视频任务中的通用性。

Abstract: Tokenization in video models, typically through patchification, generates an excessive and redundant number of tokens. This severely limits video efficiency and scalability. While recent trajectory-based tokenizers offer a promising solution by decoupling video duration from token count, they rely on complex external segmentation and tracking pipelines that are slow and task-agnostic. We propose TrajTok, an end-to-end video tokenizer module that is fully integrated and co-trained with video models for a downstream objective, dynamically adapting its token granularity to semantic complexity, independent of video duration. TrajTok contains a unified segmenter that performs implicit clustering over pixels in both space and time to directly produce object trajectories in a single forward pass. By prioritizing downstream adaptability over pixel-perfect segmentation fidelity, TrajTok is lightweight and efficient, yet empirically improves video understanding performance. With TrajTok, we implement a video CLIP model trained from scratch (TrajViT2). It achieves the best accuracy at scale across both classification and retrieval benchmarks, while maintaining efficiency comparable to the best token-merging methods. TrajTok also proves to be a versatile component beyond its role as a tokenizer. We show that it can be seamlessly integrated as either a probing head for pretrained visual features (TrajAdapter) or an alignment connector in vision-language models (TrajVLM) with especially strong performance in long-video reasoning.

</details>


### [18] [SceneTransporter: Optimal Transport-Guided Compositional Latent Diffusion for Single-Image Structured 3D Scene Generation](https://arxiv.org/abs/2602.22785)
*Ling Wang,Hao-Xiang Guo,Xinzhou Wang,Fuchun Sun,Kai Sun,Pengkun Liu,Hang Xiao,Zhong Wang,Guangyuan Fu,Eric Li,Yang Liu,Yikai Wang*

Main category: cs.CV

TL;DR: SceneTransporter：通过最优传输解决单图像到结构化3D场景生成的端到端框架，改善实例级连贯性和几何保真度


<details>
  <summary>Details</summary>
Motivation: 现有方法生成部分级3D物体时，无法将这些部分组织成开放世界场景中的不同实例，主要原因是模型内部分配机制缺乏结构约束

Method: 将结构化3D场景生成重新定义为全局相关分配问题，在组合DiT模型的去噪循环中制定并解决熵最优传输目标，施加两个结构约束：运输计划门控交叉注意力强制图像块到3D潜在的一对一独占路由；竞争性传输结合基于边缘的成本鼓励相似块分组形成连贯对象

Result: 在开放世界场景生成中优于现有方法，显著提高实例级连贯性和几何保真度

Conclusion: SceneTransporter通过最优传输在生成过程中施加结构约束，有效解决了结构化3D场景生成的实例组织问题，为单图像到3D场景生成提供了新思路

Abstract: We introduce SceneTransporter, an end-to-end framework for structured 3D scene generation from a single image. While existing methods generate part-level 3D objects, they often fail to organize these parts into distinct instances in open-world scenes. Through a debiased clustering probe, we reveal a critical insight: this failure stems from the lack of structural constraints within the model's internal assignment mechanism. Based on this finding, we reframe the task of structured 3D scene generation as a global correlation assignment problem. To solve this, SceneTransporter formulates and solves an entropic Optimal Transport (OT) objective within the denoising loop of the compositional DiT model. This formulation imposes two powerful structural constraints. First, the resulting transport plan gates cross-attention to enforce an exclusive, one-to-one routing of image patches to part-level 3D latents, preventing entanglement. Second, the competitive nature of the transport encourages the grouping of similar patches, a process that is further regularized by an edge-based cost, to form coherent objects and prevent fragmentation. Extensive experiments show that SceneTransporter outperforms existing methods on open-world scene generation, significantly improving instance-level coherence and geometric fidelity. Code and models will be publicly available at https://2019epwl.github.io/SceneTransporter/.

</details>


### [19] [CMSA-Net: Causal Multi-scale Aggregation with Adaptive Multi-source Reference for Video Polyp Segmentation](https://arxiv.org/abs/2602.22821)
*Tong Wang,Yaolei Qi,Siwen Wang,Imran Razzak,Guanyu Yang,Yutong Xie*

Main category: cs.CV

TL;DR: CMSA-Net：一种用于视频息肉分割的新型框架，通过因果多尺度聚合模块和动态多源参考策略，在保持实时性的同时提高分割准确性。


<details>
  <summary>Details</summary>
Motivation: 视频息肉分割（VPS）在计算机辅助结肠镜检查中很重要，但面临两个主要挑战：1）息肉与周围黏膜相似，语义区分度弱；2）视频帧间息肉位置和尺度变化大，导致分割不稳定。现有方法难以同时保证准确性和实时性。

Method: 提出CMSA-Net框架，包含两个核心组件：1）因果多尺度聚合（CMA）模块：使用因果注意力机制，按严格时间顺序从多个历史帧的不同尺度聚合语义信息，减少噪声并提高特征可靠性；2）动态多源参考（DMR）策略：基于语义可分性和预测置信度自适应选择信息丰富且可靠的参考帧，提供多帧指导同时保持实时推理效率。

Result: 在SUN-SEG数据集上的大量实验表明，CMSA-Net达到了最先进的性能，在分割准确性和实时临床适用性之间取得了良好的平衡。

Conclusion: CMSA-Net通过因果多尺度聚合和动态参考选择，有效解决了视频息肉分割中的语义区分弱和帧间变化大的问题，为临床实时应用提供了准确可靠的分割解决方案。

Abstract: Video polyp segmentation (VPS) is an important task in computer-aided colonoscopy, as it helps doctors accurately locate and track polyps during examinations. However, VPS remains challenging because polyps often look similar to surrounding mucosa, leading to weak semantic discrimination. In addition, large changes in polyp position and scale across video frames make stable and accurate segmentation difficult. To address these challenges, we propose a robust VPS framework named CMSA-Net. The proposed network introduces a Causal Multi-scale Aggregation (CMA) module to effectively gather semantic information from multiple historical frames at different scales. By using causal attention, CMA ensures that temporal feature propagation follows strict time order, which helps reduce noise and improve feature reliability. Furthermore, we design a Dynamic Multi-source Reference (DMR) strategy that adaptively selects informative and reliable reference frames based on semantic separability and prediction confidence. This strategy provides strong multi-frame guidance while keeping the model efficient for real-time inference. Extensive experiments on the SUN-SEG dataset demonstrate that CMSA-Net achieves state-of-the-art performance, offering a favorable balance between segmentation accuracy and real-time clinical applicability.

</details>


### [20] [DyaDiT: A Multi-Modal Diffusion Transformer for Socially Favorable Dyadic Gesture Generation](https://arxiv.org/abs/2602.23165)
*Yichen Peng,Jyun-Ting Song,Siyeol Jung,Ruofan Liu,Haiyang Liu,Xuangeng Chu,Ruicong Liu,Erwin Wu,Hideki Koike,Kris Kitani*

Main category: cs.CV

TL;DR: DyaDiT是一个多模态扩散变换器，能够从双人对话音频生成上下文合适的人类手势动作，考虑了社交互动动态，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将单一音频流映射到单一说话者的动作，没有考虑社交上下文或建模对话中两人之间的相互动态，无法生成自然的社交互动手势。

Method: DyaDiT是一个多模态扩散变换器，输入双人对话音频和可选的社交上下文标记，输出上下文合适的动作。它融合双方信息捕捉互动动态，使用运动字典编码运动先验，并可选择性地利用对话伙伴的手势来生成更具响应性的动作。

Result: 在标准运动生成指标和定量用户研究中，DyaDiT不仅超越了现有方法的客观指标，而且用户强烈偏好其生成的动作，突显了其鲁棒性和社交友好的运动生成能力。

Conclusion: DyaDiT能够生成上下文合适且社交友好的对话手势，通过考虑双人互动动态显著提升了运动生成的自然度和社交适宜性。

Abstract: Generating realistic conversational gestures are essential for achieving natural, socially engaging interactions with digital humans. However, existing methods typically map a single audio stream to a single speaker's motion, without considering social context or modeling the mutual dynamics between two people engaging in conversation. We present DyaDiT, a multi-modal diffusion transformer that generates contextually appropriate human motion from dyadic audio signals. Trained on Seamless Interaction Dataset, DyaDiT takes dyadic audio with optional social-context tokens to produce context-appropriate motion. It fuses information from both speakers to capture interaction dynamics, uses a motion dictionary to encode motion priors, and can optionally utilize the conversational partner's gestures to produce more responsive motion. We evaluate DyaDiT on standard motion generation metrics and conduct quantitative user studies, demonstrating that it not only surpasses existing methods on objective metrics but is also strongly preferred by users, highlighting its robustness and socially favorable motion generation. Code and models will be released upon acceptance.

</details>


### [21] [ColoDiff: Integrating Dynamic Consistency With Content Awareness for Colonoscopy Video Generation](https://arxiv.org/abs/2602.23203)
*Junhu Fu,Shuyu Liang,Wutong Li,Chen Ma,Peng Huang,Kehao Wang,Ke Chen,Shengli Lin,Pinghong Zhou,Zeju Li,Yuanyuan Wang,Yi Guo*

Main category: cs.CV

TL;DR: ColoDiff是一个基于扩散的结肠镜视频生成框架，通过时间解耦和内容感知模块实现动态一致且可控的视频生成，解决医疗数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 结肠镜视频生成对于诊断肠道疾病至关重要，特别是在数据稀缺场景下。高质量视频生成需要时间一致性和对临床属性的精确控制，但面临肠道结构不规则、疾病表现多样和成像模式各异等挑战。

Method: 提出ColoDiff框架：1) TimeStream模块通过跨帧标记化机制解耦时间依赖，实现复杂动态建模；2) Content-Aware模块结合噪声注入嵌入和可学习原型，实现临床属性精确控制；3) 采用非马尔可夫采样策略，减少90%以上步骤实现实时生成。

Result: 在三个公共数据集和一个医院数据库上评估，基于生成指标和下游任务（疾病诊断、模态判别、肠道准备评分、病变分割）。实验表明ColoDiff能生成过渡平滑、动态丰富的视频。

Conclusion: ColoDiff在可控结肠镜视频生成方面做出努力，展示了合成视频在补充真实表示和缓解临床数据稀缺方面的潜力。

Abstract: Colonoscopy video generation delivers dynamic, information-rich data critical for diagnosing intestinal diseases, particularly in data-scarce scenarios. High-quality video generation demands temporal consistency and precise control over clinical attributes, but faces challenges from irregular intestinal structures, diverse disease representations, and various imaging modalities. To this end, we propose ColoDiff, a diffusion-based framework that generates dynamic-consistent and content-aware colonoscopy videos, aiming to alleviate data shortage and assist clinical analysis. At the inter-frame level, our TimeStream module decouples temporal dependency from video sequences through a cross-frame tokenization mechanism, enabling intricate dynamic modeling despite irregular intestinal structures. At the intra-frame level, our Content-Aware module incorporates noise-injected embeddings and learnable prototypes to realize precise control over clinical attributes, breaking through the coarse guidance of diffusion models. Additionally, ColoDiff employs a non-Markovian sampling strategy that cuts steps by over 90% for real-time generation. ColoDiff is evaluated across three public datasets and one hospital database, based on both generation metrics and downstream tasks including disease diagnosis, modality discrimination, bowel preparation scoring, and lesion segmentation. Extensive experiments show ColoDiff generates videos with smooth transitions and rich dynamics. ColoDiff presents an effort in controllable colonoscopy video generation, revealing the potential of synthetic videos in complementing authentic representation and mitigating data scarcity in clinical settings.

</details>


### [22] [Plug-and-Play Diffusion Meets ADMM: Dual-Variable Coupling for Robust Medical Image Reconstruction](https://arxiv.org/abs/2602.23214)
*Chenhe Du,Xuanyu Tian,Qing Wu,Muyu Liu,Jingyi Yu,Hongjiang Wei,Yuyao Zhang*

Main category: cs.CV

TL;DR: 提出Dual-Coupled PnP Diffusion框架，通过引入对偶变量提供积分反馈，解决传统PnP扩散先验方法中的稳态偏差问题，同时使用Spectral Homogenization技术将结构化残差转化为符合AWGN假设的输入，避免幻觉伪影。


<details>
  <summary>Details</summary>
Motivation: 现有PnP扩散先验框架（如HQS或Proximal Gradient）作为无记忆算子，仅基于瞬时梯度更新估计，导致在强噪声下存在非零稳态偏差，无法严格满足物理测量约束。同时，严格几何耦合产生的结构化残差违反扩散先验的AWGN假设，引发严重幻觉伪影。

Method: 提出Dual-Coupled PnP Diffusion框架：1）引入经典对偶变量提供积分反馈，理论上保证渐近收敛到精确数据流形；2）提出Spectral Homogenization（SH）技术，在频域调制结构化残差，将其转化为统计上符合AWGN假设的伪AWGN输入，使优化轨迹与去噪器有效统计流形对齐。

Result: 在CT和MRI重建任务上的大量实验表明，该方法解决了偏差与幻觉之间的权衡问题，实现了最先进的保真度，并显著加速了收敛速度。

Conclusion: 通过结合对偶耦合和谱均匀化，提出的框架有效解决了PnP扩散先验方法中的稳态偏差问题，同时避免了结构化残差引起的幻觉伪影，在医学成像逆问题中取得了优越性能。

Abstract: Plug-and-Play diffusion prior (PnPDP) frameworks have emerged as a powerful paradigm for solving imaging inverse problems by treating pretrained generative models as modular priors. However, we identify a critical flaw in prevailing PnP solvers (e.g., based on HQS or Proximal Gradient): they function as memoryless operators, updating estimates solely based on instantaneous gradients. This lack of historical tracking inevitably leads to non-vanishing steady-state bias, where the reconstruction fails to strictly satisfy physical measurements under heavy corruption. To resolve this, we propose Dual-Coupled PnP Diffusion, which restores the classical dual variable to provide integral feedback, theoretically guaranteeing asymptotic convergence to the exact data manifold. However, this rigorous geometric coupling introduces a secondary challenge: the accumulated dual residuals exhibit spectrally colored, structured artifacts that violate the Additive White Gaussian Noise (AWGN) assumption of diffusion priors, causing severe hallucinations. To bridge this gap, we introduce Spectral Homogenization (SH), a frequency-domain adaptation mechanism that modulates these structured residuals into statistically compliant pseudo-AWGN inputs. This effectively aligns the solver's rigorous optimization trajectory with the denoiser's valid statistical manifold. Extensive experiments on CT and MRI reconstruction demonstrate that our approach resolves the bias-hallucination trade-off, achieving state-of-the-art fidelity with significantly accelerated convergence.

</details>


### [23] [Risk-Aware World Model Predictive Control for Generalizable End-to-End Autonomous Driving](https://arxiv.org/abs/2602.23259)
*Jiangxin Sun,Feng Xue,Teng Long,Chang Liu,Jian-Fang Hu,Wei-Shi Zheng,Nicu Sebe*

Main category: cs.CV

TL;DR: 提出RaWMPC框架，通过风险感知世界模型预测控制实现端到端自动驾驶，无需专家动作监督，解决长尾场景泛化问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于模仿学习的端到端自动驾驶方法依赖专家演示，在罕见长尾场景下泛化能力有限且存在安全隐患。需要探索无需专家监督的可靠决策方法。

Method: 1. 构建风险感知世界模型预测控制框架；2. 设计风险感知交互策略，让世界模型学习危险行为的后果；3. 引入自评估蒸馏方法，将风险规避能力从世界模型蒸馏到生成动作提议网络。

Result: 在分布内和分布外场景中均优于现有方法，同时提供更好的决策可解释性。

Conclusion: RaWMPC框架通过风险感知世界模型预测控制，无需专家监督即可实现可靠的端到端自动驾驶决策，有效解决长尾场景泛化问题。

Abstract: With advances in imitation learning (IL) and large-scale driving datasets, end-to-end autonomous driving (E2E-AD) has made great progress recently. Currently, IL-based methods have become a mainstream paradigm: models rely on standard driving behaviors given by experts, and learn to minimize the discrepancy between their actions and expert actions. However, this objective of "only driving like the expert" suffers from limited generalization: when encountering rare or unseen long-tail scenarios outside the distribution of expert demonstrations, models tend to produce unsafe decisions in the absence of prior experience. This raises a fundamental question: Can an E2E-AD system make reliable decisions without any expert action supervision? Motivated by this, we propose a unified framework named Risk-aware World Model Predictive Control (RaWMPC) to address this generalization dilemma through robust control, without reliance on expert demonstrations. Practically, RaWMPC leverages a world model to predict the consequences of multiple candidate actions and selects low-risk actions through explicit risk evaluation. To endow the world model with the ability to predict the outcomes of risky driving behaviors, we design a risk-aware interaction strategy that systematically exposes the world model to hazardous behaviors, making catastrophic outcomes predictable and thus avoidable. Furthermore, to generate low-risk candidate actions at test time, we introduce a self-evaluation distillation method to distill riskavoidance capabilities from the well-trained world model into a generative action proposal network without any expert demonstration. Extensive experiments show that RaWMPC outperforms state-of-the-art methods in both in-distribution and out-of-distribution scenarios, while providing superior decision interpretability.

</details>


### [24] [Towards Long-Form Spatio-Temporal Video Grounding](https://arxiv.org/abs/2602.23294)
*Xin Gu,Bing Fan,Jiali Yao,Zhipeng Zhang,Yan Huang,Cheng Han,Heng Fan,Libo Zhang*

Main category: cs.CV

TL;DR: 提出ART-STVG方法解决长视频时空定位问题，通过自回归处理和记忆选择机制提升长视频处理能力


<details>
  <summary>Details</summary>
Motivation: 现有时空视频定位（STVG）研究主要针对几十秒的短视频，而现实场景中视频可能长达几分钟甚至几小时，这限制了实际应用。因此需要探索长视频时空定位（LF-STVG）问题。

Method: 提出自回归Transformer架构ART-STVG：1）将视频作为流式输入顺序处理帧；2）设计时空记忆库并引入记忆选择策略提供相关信息；3）采用级联时空设计，空间解码器连接时间解码器，利用空间线索辅助时间定位。

Result: 在新扩展的LF-STVG数据集上，ART-STVG显著优于现有方法，同时在传统短视频STVG上也能达到竞争性性能。

Conclusion: ART-STVG通过自回归处理、记忆选择机制和级联时空设计，有效解决了长视频时空定位的挑战，为实际应用提供了可行的解决方案。

Abstract: In real scenarios, videos can span several minutes or even hours. However, existing research on spatio-temporal video grounding (STVG), given a textual query, mainly focuses on localizing targets in short videos of tens of seconds, typically less than one minute, which limits real-world applications. In this paper, we explore Long-Form STVG (LF-STVG), which aims to locate targets in long-term videos. Compared with short videos, long-term videos contain much longer temporal spans and more irrelevant information, making it difficult for existing STVG methods that process all frames at once. To address this challenge, we propose an AutoRegressive Transformer architecture for LF-STVG, termed ART-STVG. Unlike conventional STVG methods that require the entire video sequence to make predictions at once, ART-STVG treats the video as streaming input and processes frames sequentially, enabling efficient handling of long videos. To model spatio-temporal context, we design spatial and temporal memory banks and apply them to the decoders. Since memories from different moments are not always relevant to the current frame, we introduce simple yet effective memory selection strategies to provide more relevant information to the decoders, significantly improving performance. Furthermore, instead of parallel spatial and temporal localization, we propose a cascaded spatio-temporal design that connects the spatial decoder to the temporal decoder, allowing fine-grained spatial cues to assist complex temporal localization in long videos. Experiments on newly extended LF-STVG datasets show that ART-STVG significantly outperforms state-of-the-art methods, while achieving competitive performance on conventional short-form STVG.

</details>


### [25] [ManifoldGD: Training-Free Hierarchical Manifold Guidance for Diffusion-Based Dataset Distillation](https://arxiv.org/abs/2602.23295)
*Ayush Roy,Wei-Yang Alex Lee,Rudrasis Chakraborty,Vishnu Suresh Lokhande*

Main category: cs.CV

TL;DR: ManifoldGD是一种无需训练的数据集蒸馏方法，通过扩散模型和流形一致性引导，在去噪过程中保持语义一致性，提高合成数据的代表性、多样性和保真度。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的无训练数据集蒸馏方法存在引导策略有限的问题，要么进行无引导去噪，要么依赖于简单的基于原型的模式引导，这些方法往往粗糙且次优。

Method: 提出Manifold-Guided Distillation框架，利用分层聚类VAE潜在特征得到多尺度IPC核心集，在扩散去噪的每个时间步，将模式对齐向量投影到估计潜在流形的局部切空间，使生成轨迹保持流形一致性。

Result: 实验结果表明，ManifoldGD在FID、真实与合成数据集嵌入的l2距离以及分类准确率等方面，均优于现有的无训练和基于训练的方法。

Conclusion: ManifoldGD是首个几何感知的无训练数据蒸馏框架，通过流形一致性引导在扩散去噪过程中保持语义一致性，显著提高了合成数据的质量。

Abstract: In recent times, large datasets hinder efficient model training while also containing redundant concepts. Dataset distillation aims to synthesize compact datasets that preserve the knowledge of large-scale training sets while drastically reducing storage and computation. Recent advances in diffusion models have enabled training-free distillation by leveraging pre-trained generative priors; however, existing guidance strategies remain limited. Current score-based methods either perform unguided denoising or rely on simple mode-based guidance toward instance prototype centroids (IPC centroids), which often are rudimentary and suboptimal. We propose Manifold-Guided Distillation (ManifoldGD), a training-free diffusion-based framework that integrates manifold consistent guidance at every denoising timestep. Our method employs IPCs computed via a hierarchical, divisive clustering of VAE latent features, yielding a multi-scale coreset of IPCs that captures both coarse semantic modes and fine intra-class variability. Using a local neighborhood of the extracted IPC centroids, we create the latent manifold for each diffusion denoising timestep. At each denoising step, we project the mode-alignment vector onto the local tangent space of the estimated latent manifold, thus constraining the generation trajectory to remain manifold-faithful while preserving semantic consistency. This formulation improves representativeness, diversity, and image fidelity without requiring any model retraining. Empirical results demonstrate consistent gains over existing training-free and training-based baselines in terms of FID, l2 distance among real and synthetic dataset embeddings, and classification accuracy, establishing ManifoldGD as the first geometry-aware training-free data distillation framework.

</details>


### [26] [Sensor Generalization for Adaptive Sensing in Event-based Object Detection via Joint Distribution Training](https://arxiv.org/abs/2602.23357)
*Aheli Saha,René Schuster,Didier Stricker*

Main category: cs.CV

TL;DR: 论文分析了事件相机固有参数对目标检测模型性能的影响，并利用这些发现扩展下游模型以实现传感器无关的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 事件相机具有异步、低延迟、高动态范围和低运动模糊等优势，但由于其输出信号新颖，存在数据可变性不足和信号参数分析缺乏的问题。

Method: 通过深入研究事件相机固有参数如何影响基于事件数据训练的目标检测模型性能，并利用这些发现来扩展下游模型。

Result: 提供了对事件相机参数如何影响目标检测性能的深入理解，并实现了传感器无关的鲁棒性扩展。

Conclusion: 该研究填补了事件相机信号参数分析的空白，为基于事件数据的目标检测模型提供了参数影响的深入理解，并成功扩展了模型对传感器变化的鲁棒性。

Abstract: Bio-inspired event cameras have recently attracted significant research due to their asynchronous and low-latency capabilities. These features provide a high dynamic range and significantly reduce motion blur. However, because of the novelty in the nature of their output signals, there is a gap in the variability of available data and a lack of extensive analysis of the parameters characterizing their signals. This paper addresses these issues by providing readers with an in-depth understanding of how intrinsic parameters affect the performance of a model trained on event data, specifically for object detection. We also use our findings to expand the capabilities of the downstream model towards sensor-agnostic robustness.

</details>


### [27] [SeeThrough3D: Occlusion Aware 3D Control in Text-to-Image Generation](https://arxiv.org/abs/2602.23359)
*Vaibhav Agrawal,Rishubh Parihar,Pradhaan Bhat,Ravi Kiran Sarvadevabhatla,R. Venkatesh Babu*

Main category: cs.CV

TL;DR: SeeThrough3D提出了一种显式建模遮挡关系的3D布局条件生成方法，通过引入遮挡感知的3D场景表示(OSCR)和视觉token，实现了对多物体场景中遮挡关系的精确建模和相机控制。


<details>
  <summary>Details</summary>
Motivation: 现有3D布局条件生成方法虽然能生成符合输入布局的真实场景，但往往无法精确建模物体间的遮挡关系，导致部分遮挡物体的几何和尺度不一致。遮挡推理是3D布局条件生成中被忽视但至关重要的方面。

Method: 1. 提出遮挡感知3D场景表示(OSCR)：将物体表示为半透明3D盒子放置在虚拟环境中，从指定相机视角渲染；2. 将渲染的3D表示转换为视觉token，条件化预训练的基于流的文生图模型；3. 使用掩码自注意力机制精确绑定每个物体边界框与其对应文本描述；4. 构建包含强遮挡关系的合成多物体场景数据集进行训练。

Result: SeeThrough3D能够有效泛化到未见过的物体类别，实现精确的3D布局控制，生成具有真实遮挡关系和一致相机控制的场景图像。

Conclusion: 通过显式建模遮挡关系和引入OSCR表示，SeeThrough3D解决了现有3D布局条件生成方法在遮挡推理方面的不足，实现了对多物体场景中遮挡关系的精确控制，为3D场景生成提供了更强大的布局控制能力。

Abstract: We identify occlusion reasoning as a fundamental yet overlooked aspect for 3D layout-conditioned generation. It is essential for synthesizing partially occluded objects with depth-consistent geometry and scale. While existing methods can generate realistic scenes that follow input layouts, they often fail to model precise inter-object occlusions. We propose SeeThrough3D, a model for 3D layout conditioned generation that explicitly models occlusions. We introduce an occlusion-aware 3D scene representation (OSCR), where objects are depicted as translucent 3D boxes placed within a virtual environment and rendered from desired camera viewpoint. The transparency encodes hidden object regions, enabling the model to reason about occlusions, while the rendered viewpoint provides explicit camera control during generation. We condition a pretrained flow based text-to-image image generation model by introducing a set of visual tokens derived from our rendered 3D representation. Furthermore, we apply masked self-attention to accurately bind each object bounding box to its corresponding textual description, enabling accurate generation of multiple objects without object attribute mixing. To train the model, we construct a synthetic dataset with diverse multi-object scenes with strong inter-object occlusions. SeeThrough3D generalizes effectively to unseen object categories and enables precise 3D layout control with realistic occlusions and consistent camera control.

</details>


### [28] [VGG-T$^3$: Offline Feed-Forward 3D Reconstruction at Scale](https://arxiv.org/abs/2602.23361)
*Sven Elflein,Ruilong Li,Sérgio Agostinho,Zan Gojcic,Laura Leal-Taixé,Qunjie Zhou,Aljosa Osep*

Main category: cs.CV

TL;DR: VGG-T³是一种可扩展的3D重建模型，通过将可变长度的键值空间表示蒸馏为固定大小的MLP，解决了传统前馈方法计算和内存需求随输入图像数量呈二次方增长的问题，实现了线性时间复杂度的重建。


<details>
  <summary>Details</summary>
Motivation: 解决现有离线前馈3D重建方法中存在的关键限制：计算和内存需求随输入图像数量呈二次方增长，这限制了方法的可扩展性。

Method: 基于关键洞察：瓶颈来自场景几何的可变长度键值空间表示。通过测试时训练将这种表示蒸馏为固定大小的多层感知机，实现线性时间复杂度的重建。

Result: VGG-T³在1000张图像集合上的重建仅需54秒，比基于softmax注意力的基线方法快11.6倍。点云重建误差大幅优于其他线性时间方法，并展示了通过未见图像查询场景表示的视觉定位能力。

Conclusion: 该方法成功解决了3D重建中的可扩展性问题，在保持全局场景聚合能力的同时实现了线性时间复杂度，为大规模场景重建提供了高效解决方案。

Abstract: We present a scalable 3D reconstruction model that addresses a critical limitation in offline feed-forward methods: their computational and memory requirements grow quadratically w.r.t. the number of input images. Our approach is built on the key insight that this bottleneck stems from the varying-length Key-Value (KV) space representation of scene geometry, which we distill into a fixed-size Multi-Layer Perceptron (MLP) via test-time training. VGG-T$^3$ (Visual Geometry Grounded Test Time Training) scales linearly w.r.t. the number of input views, similar to online models, and reconstructs a $1k$ image collection in just $54$ seconds, achieving a $11.6\times$ speed-up over baselines that rely on softmax attention. Since our method retains global scene aggregation capability, our point map reconstruction error outperforming other linear-time methods by large margins. Finally, we demonstrate visual localization capabilities of our model by querying the scene representation with unseen images.

</details>


### [29] [MediX-R1: Open Ended Medical Reinforcement Learning](https://arxiv.org/abs/2602.23363)
*Sahal Shaji Mullappilly,Mohammed Irfan Kurpath,Omair Mohamed,Mohamed Zidan,Fahad Khan,Salman Khan,Rao Anwer,Hisham Cholakkal*

Main category: cs.CV

TL;DR: MediX-R1是一个用于医学多模态大语言模型的开环强化学习框架，支持临床基础的开放式回答，超越了传统的多项选择题格式。


<details>
  <summary>Details</summary>
Motivation: 传统医学AI系统主要依赖可验证的答案或多选题格式，无法处理临床实践中常见的开放式、自由形式的医学问题。需要开发能够提供临床基础、自由形式答案的医学多模态大语言模型。

Method: 使用基于组的强化学习微调基线视觉语言骨干网络，采用复合奖励机制：1)基于LLM的准确性奖励（严格的YES/NO判断语义正确性）；2)基于医学嵌入的语义奖励（捕捉同义表达和术语变体）；3)轻量级格式和模态奖励（强制可解释推理和模态识别）。

Result: 仅使用约51K指令示例，MediX-R1在标准医学LLM（纯文本）和VLM（图像+文本）基准测试中取得优异结果，优于强大的开源基线模型，在开放式临床任务上表现尤为突出。

Conclusion: 具有全面奖励信号和基于LLM评估的开放式强化学习是实现多模态模型中可靠医学推理的实用路径，为临床医学AI提供了更灵活、更贴近实际应用的解决方案。

Abstract: We introduce MediX-R1, an open-ended Reinforcement Learning (RL) framework for medical multimodal large language models (MLLMs) that enables clinically grounded, free-form answers beyond multiple-choice formats. MediX-R1 fine-tunes a baseline vision-language backbone with Group Based RL and a composite reward tailored for medical reasoning: an LLM-based accuracy reward that judges semantic correctness with a strict YES/NO decision, a medical embedding-based semantic reward to capture paraphrases and terminology variants, and lightweight format and modality rewards that enforce interpretable reasoning and modality recognition. This multi-signal design provides stable, informative feedback for open-ended outputs where traditional verifiable or MCQ-only rewards fall short. To measure progress, we propose a unified evaluation framework for both text-only and image+text tasks that uses a Reference-based LLM-as-judge in place of brittle string-overlap metrics, capturing semantic correctness, reasoning, and contextual alignment. Despite using only $\sim51$K instruction examples, MediX-R1 achieves excellent results across standard medical LLM (text-only) and VLM (image + text) benchmarks, outperforming strong open-source baselines and delivering particularly large gains on open-ended clinical tasks. Our results demonstrate that open-ended RL with comprehensive reward signals and LLM-based evaluation is a practical path toward reliable medical reasoning in multimodal models. Our trained models, curated datasets and source code are available at https://medix.cvmbzuai.com

</details>


### [30] [SubspaceAD: Training-Free Few-Shot Anomaly Detection via Subspace Modeling](https://arxiv.org/abs/2602.23013)
*Camile Lendering,Erkut Akdag,Egor Bondarev*

Main category: cs.CV

TL;DR: SubspaceAD是一个无需训练、基于DINOv2特征和PCA的异常检测方法，在少样本工业异常检测中实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于基础模型的少样本异常检测方法通常依赖内存库、辅助数据集或多模态调整，作者质疑这种复杂性是否必要，并探索仅利用视觉基础模型特征表示的简单方案。

Method: 采用两阶段无训练方法：1)使用冻结的DINOv2骨干网络从少量正常图像中提取patch级特征；2)通过PCA拟合这些特征，估计正常变化的低维子空间。推理时通过重构残差检测异常。

Result: 在MVTec-AD数据集上，单样本设置下达到图像级AUROC 98.0%和像素级AUROC 97.6%；在VisA数据集上达到93.3%和98.3%，均超越先前SOTA结果。

Conclusion: 即使结构简单，SubspaceAD无需训练、提示调优或内存库，就能在少样本异常检测中实现最先进性能，证明基础模型特征表示本身已足够强大。

Abstract: Detecting visual anomalies in industrial inspection often requires training with only a few normal images per category. Recent few-shot methods achieve strong results employing foundation-model features, but typically rely on memory banks, auxiliary datasets, or multi-modal tuning of vision-language models. We therefore question whether such complexity is necessary given the feature representations of vision foundation models. To answer this question, we introduce SubspaceAD, a training-free method, that operates in two simple stages. First, patch-level features are extracted from a small set of normal images by a frozen DINOv2 backbone. Second, a Principal Component Analysis (PCA) model is fit to these features to estimate the low-dimensional subspace of normal variations. At inference, anomalies are detected via the reconstruction residual with respect to this subspace, producing interpretable and statistically grounded anomaly scores. Despite its simplicity, SubspaceAD achieves state-of-the-art performance across one-shot and few-shot settings without training, prompt tuning, or memory banks. In the one-shot anomaly detection setting, SubspaceAD achieves image-level and pixel-level AUROC of 98.0% and 97.6% on the MVTec-AD dataset, and 93.3% and 98.3% on the VisA dataset, respectively, surpassing prior state-of-the-art results. Code and demo are available at https://github.com/CLendering/SubspaceAD.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [31] [To Deceive is to Teach? Forging Perceptual Robustness via Adversarial Reinforcement Learning](https://arxiv.org/abs/2602.22227)
*Yicheng Bao,Xuhong Wang,Xin Tan*

Main category: cs.LG

TL;DR: AOT-SFT 是一个大规模对抗数据集，AOT 是一个自博弈框架，通过图像编辑攻击者和防御者 MLLM 的协同进化，提升多模态大语言模型的感知鲁棒性并减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在视觉复杂场景中存在感知脆弱性，这源于对有限训练数据的依赖，而扩大数据集成本高昂且存在鲁棒性上限。

Method: 提出 AOT-SFT 对抗数据集和 AOT 自博弈框架，通过图像编辑攻击者生成多样动态的图像操作课程，迫使防御者 MLLM 不断适应和改进。

Result: 实验表明 AOT 能显著提升防御者 MLLM 的感知鲁棒性并减少幻觉，为训练更可靠的多模态大语言模型提供了可扩展的范式。

Conclusion: AOT 框架通过自博弈的对抗训练机制，有效解决了 MLLM 的感知脆弱性问题，为提升模型鲁棒性提供了创新且可扩展的解决方案。

Abstract: Despite their impressive capabilities, Multimodal Large Language Models (MLLMs) exhibit perceptual fragility when confronted with visually complex scenes. This weakness stems from a reliance on finite training datasets, which are prohibitively expensive to scale and impose a ceiling on model robustness. We introduce \textbf{AOT-SFT}, a large-scale adversarial dataset for bootstrapping MLLM robustness. Building on this, we propose \textbf{AOT (Adversarial Opponent Training)}, a self-play framework that forges MLLM robustness by creating its own training data. Our method orchestrates a co-evolution between an image-editing Attacker and a Defender MLLM, where the Attacker generates a diverse and dynamic curriculum of image manipulations, forcing the Defender to adapt and improve. Extensive experiments demonstrate that AOT enhances the Defender's perceptual robustness and reduces hallucinations, establishing a scalable paradigm for training more reliable MLLMs.

</details>


### [32] [Patient-Centered, Graph-Augmented Artificial Intelligence-Enabled Passive Surveillance for Early Stroke Risk Detection in High-Risk Individuals](https://arxiv.org/abs/2602.22228)
*Jiyeong Kim,Stephen P. Ma,Nirali Vora,Nicholas W. Larsen,Julia Adler-Milstein,Jonathan H. Chen,Selen Bozkurt,Abeed Sarker,Juhee Cho,Jindeok Joo,Natali Pageler,Fatima Rodriguez,Christopher Sharp,Eleni Linos*

Main category: cs.LG

TL;DR: 开发了一个基于患者自述症状的被动监测系统，用于糖尿病患者的早期卒中风险检测，通过症状分类和机器学习识别卒中相关症状模式，构建了混合风险筛查系统。


<details>
  <summary>Details</summary>
Motivation: 卒中每年影响数百万人，但症状识别困难常常延误就医。为了解决风险识别差距，特别是针对糖尿病患者，需要开发早期卒中风险检测系统。

Method: 构建基于患者语言描述的症状分类学，采用双重机器学习流程（异质图神经网络和弹性网络/LASSO）识别与后续卒中相关的症状模式，开发混合风险筛查系统整合症状相关性和时间接近性。

Result: 在3-90天窗口内通过电子健康记录模拟评估，筛查系统在保守阈值下实现高特异性（1.00）和患病率调整阳性预测值（1.00），灵敏度为0.72，在90天窗口表现最佳。

Conclusion: 仅使用患者自述语言就能支持高精度、低负担的早期卒中风险检测，为高危个体提供了临床评估和干预的宝贵时间窗口。

Abstract: Stroke affected millions annually, yet poor symptom recognition often delayed care-seeking. To address risk recognition gap, we developed a passive surveillance system for early stroke risk detection using patient-reported symptoms among individuals with diabetes. Constructing a symptom taxonomy grounded in patients own language and a dual machine learning pipeline (heterogeneous GNN and EN/LASSO), we identified symptom patterns associated with subsequent stroke. We translated findings into a hybrid risk screening system integrating symptom relevance and temporal proximity, evaluated across 3-90 day windows through EHR-based simulations. Under conservative thresholds, intentionally designed to minimize false alerts, the screening system achieved high specificity (1.00) and prevalence-adjusted positive predictive value (1.00), with good sensitivity (0.72), an expected trade-off prioritizing precision, that was highest in 90-day window. Patient-reported language alone supported high-precision, low-burden early stroke risk detection, that could offer a valuable time window for clinical evaluation and intervention for high-risk individuals.

</details>


### [33] [Improving Spatial Allocation for Energy System Coupling with Graph Neural Networks](https://arxiv.org/abs/2602.22249)
*Xuanhao Mu,Jakob Geiges,Nan Liu,Thorsten Schlachter,Veit Hagenmeyer*

Main category: cs.LG

TL;DR: 该论文提出了一种使用自监督异构图神经网络的方法，解决能源系统分析中空间分辨率不匹配模型耦合的问题，通过整合多种地理特征生成物理意义明确的权重，显著提升了传统Voronoi分配方法的性能。


<details>
  <summary>Details</summary>
Motivation: 能源系统分析中，空间分辨率不匹配的模型耦合是一个重要挑战。传统方法仅使用单一地理空间属性进行高分辨率地理单元的权重分配和聚合，这种方法存在局限性，无法充分利用多种地理特征信息。

Method: 采用自监督异构图神经网络，将高分辨率地理单元建模为图节点，整合多种地理特征为每个网格点生成具有物理意义的权重。这些权重用于增强传统的基于Voronoi的分配方法，使其不仅考虑地理邻近性，还能融入重要的地理信息。

Result: 实验结果表明，应用该方法生成的权重到聚类Voronoi图后，在可扩展性、准确性和物理合理性方面均有显著提升，同时比传统方法具有更高的精度。

Conclusion: 该研究提出的自监督异构图神经网络方法有效解决了能源系统分析中的空间分辨率不匹配问题，通过整合多种地理特征生成物理意义明确的权重，显著优于传统单一属性的方法，且自监督学习范式克服了缺乏准确地面实况数据的限制。

Abstract: In energy system analysis, coupling models with mismatched spatial resolutions is a significant challenge. A common solution is assigning weights to high-resolution geographic units for aggregation, but traditional models are limited by using only a single geospatial attribute. This paper presents an innovative method employing a self-supervised Heterogeneous Graph Neural Network to address this issue. This method models high-resolution geographic units as graph nodes, integrating various geographical features to generate physically meaningful weights for each grid point. These weights enhance the conventional Voronoi-based allocation method, allowing it to go beyond simply geographic proximity by incorporating essential geographic information.In addition, the self-supervised learning paradigm overcomes the lack of accurate ground-truth data. Experimental results demonstrate that applying weights generated by this method to cluster-based Voronoi Diagrams significantly enhances scalability, accuracy, and physical plausibility, while increasing precision compared to traditional methods.

</details>


### [34] [Zatom-1: A Multimodal Flow Foundation Model for 3D Molecules and Materials](https://arxiv.org/abs/2602.22251)
*Alex Morehead,Miruna Cretu,Antonia Panescu,Rishabh Anand,Maurice Weiler,Tynan Perez,Samuel Blau,Steven Farrell,Wahid Bhimji,Anubhav Jain,Hrushikesh Sahasrabuddhe,Pietro Lio,Tommi Jaakkola,Rafael Gomez-Bombarelli,Rex Ying,N. Benjamin Erichson,Michael W. Mahoney*

Main category: cs.LG

TL;DR: Zatom-1是首个统一3D分子和材料生成与预测的基础模型，通过多模态流匹配Transformer联合建模离散原子类型和连续3D几何，实现了跨领域知识迁移并大幅提升推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有AI方法大多局限于单一化学领域（分子或材料）和单一任务（生成或预测），限制了表示共享和迁移学习。需要开发一个统一模型来处理通用3D化学建模的生成和预测需求。

Method: 采用Transformer架构，使用多模态流匹配目标联合建模离散原子类型和连续3D几何。通过联合生成预训练作为下游多任务预测的通用初始化，支持可扩展预训练和快速稳定采样。

Result: Zatom-1在生成和预测基准测试中达到或超越专用基线模型，同时将生成推理时间减少一个数量级以上。实验证明联合生成预训练在化学领域间存在正向预测迁移：预训练中建模材料能提高分子性质预测准确性。

Conclusion: Zatom-1首次实现了3D分子和材料生成与预测的统一基础模型，展示了跨领域联合学习的优势，为通用3D化学建模提供了高效解决方案。

Abstract: General-purpose 3D chemical modeling encompasses molecules and materials, requiring both generative and predictive capabilities. However, most existing AI approaches are optimized for a single domain (molecules or materials) and a single task (generation or prediction), which limits representation sharing and transfer. We introduce Zatom-1, the first foundation model that unifies generative and predictive learning of 3D molecules and materials. Zatom-1 is a Transformer trained with a multimodal flow matching objective that jointly models discrete atom types and continuous 3D geometries. This approach supports scalable pretraining with predictable gains as model capacity increases, while enabling fast and stable sampling. We use joint generative pretraining as a universal initialization for downstream multi-task prediction of properties, energies, and forces. Empirically, Zatom-1 matches or outperforms specialized baselines on both generative and predictive benchmarks, while reducing the generative inference time by more than an order of magnitude. Our experiments demonstrate positive predictive transfer between chemical domains from joint generative pretraining: modeling materials during pretraining improves molecular property prediction accuracy.

</details>


### [35] [Causal Direction from Convergence Time: Faster Training in the True Causal Direction](https://arxiv.org/abs/2602.22254)
*Abdulrahman Tamim*

Main category: cs.LG

TL;DR: 提出因果计算不对称性（CCA）原则，通过比较两个神经网络分别从X预测Y和从Y预测X的收敛速度来识别因果方向。因果方向收敛更快，该理论在加性噪声模型下被形式化证明，并在合成数据上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 现有因果方向识别方法如RESIT、IGCI、SkewScore等依赖统计独立性或分布不对称性，作者提出基于优化动态的新方法，通过比较双向预测模型的收敛速度来识别因果方向。

Method: 训练两个神经网络：一个预测Y|X，另一个预测X|Y。在加性噪声模型Y=f(X)+ε（ε⊥X，f非线性单射）下，理论证明反向预测时残差与输入保持统计依赖，导致更高的不可约损失和不可分离梯度噪声，使得反向模型需要更多梯度步数达到相同损失阈值。因此收敛更快的方向被推断为因果方向。

Result: 在合成基准测试中，CCA在六种神经网络架构上实现了26/30的正确因果识别，在正弦和指数数据生成过程中达到30/30的正确率。CCA被进一步嵌入到因果压缩学习（CCL）框架中，整合图结构学习、因果信息压缩和策略优化。

Conclusion: CCA提供了一种基于优化动态的因果方向识别新范式，区别于传统统计方法。理论保证被形式化证明并在合成数据集上经验验证。CCA可扩展为更广泛的因果压缩学习框架。

Abstract: We introduce Causal Computational Asymmetry (CCA), a principle for causal direction identification based on optimization dynamics in which one neural network is trained to predict $Y$ from $X$ and another to predict $X$ from $Y$, and the direction that converges faster is inferred to be causal. Under the additive noise model $Y = f(X) + \varepsilon$ with $\varepsilon \perp X$ and $f$ nonlinear and injective, we establish a formal asymmetry: in the reverse direction, residuals remain statistically dependent on the input regardless of approximation quality, inducing a strictly higher irreducible loss floor and non-separable gradient noise in the optimization dynamics, so that the reverse model requires strictly more gradient steps in expectation to reach any fixed loss threshold; consequently, the forward (causal) direction converges in fewer expected optimization steps. CCA operates in optimization-time space, distinguishing it from methods such as RESIT, IGCI, and SkewScore that rely on statistical independence or distributional asymmetries, and proper z-scoring of both variables is required for valid comparison of convergence rates. On synthetic benchmarks, CCA achieves 26/30 correct causal identifications across six neural architectures, including 30/30 on sine and exponential data-generating processes. We further embed CCA into a broader framework termed Causal Compression Learning (CCL), which integrates graph structure learning, causal information compression, and policy optimization, with all theoretical guarantees formally proved and empirically validated on synthetic datasets.

</details>


### [36] [Code World Models for Parameter Control in Evolutionary Algorithms](https://arxiv.org/abs/2602.22260)
*Camilo Chacón Sartori,Guillem Rodríguez Corominas*

Main category: cs.LG

TL;DR: LLM通过合成代码世界模型来学习优化器行为，并用于控制优化器，在组合优化问题上表现优异


<details>
  <summary>Details</summary>
Motivation: 研究LLM是否能够学习优化器的行为模式，并利用这种知识来控制优化器，特别是在组合优化问题中

Method: 使用LLM合成代码世界模型来预测环境动态，通过贪婪规划在模拟器上选择每一步的变异强度k

Result: 在LO和OneMax问题上接近理论最优策略，在Jump-k问题上100%成功率，在NK-Landscape上优于所有基线，样本效率优于DQN

Conclusion: 代码世界模型能够有效学习优化器行为并实现控制，在组合优化中表现出强大的性能和泛化能力

Abstract: Can an LLM learn how an optimizer behaves -- and use that knowledge to control it? We extend Code World Models (CWMs), LLM-synthesized Python programs that predict environment dynamics, from deterministic games to stochastic combinatorial optimization. Given suboptimal trajectories of $(1{+}1)$-$\text{RLS}_k$, the LLM synthesizes a simulator of the optimizer's dynamics; greedy planning over this simulator then selects the mutation strength $k$ at each step. On \lo{} and \onemax{}, CWM-greedy performs within 6\% of the theoretically optimal policy -- without ever seeing optimal-policy trajectories. On \jump{$_k$}, where a deceptive valley causes all adaptive baselines to fail (0\% success rate), CWM-greedy achieves 100\% success rate -- without any collection policy using oracle knowledge of the gap parameter. On the NK-Landscape, where no closed-form model exists, CWM-greedy outperforms all baselines across fifteen independently generated instances ($36.94$ vs.\ $36.32$; $p<0.001$) when the prompt includes empirical transition statistics. The CWM also outperforms DQN in sample efficiency (200 offline trajectories vs.\ 500 online episodes), success rate (100\% vs.\ 58\%), and generalization ($k{=}3$: 78\% vs.\ 0\%). Robustness experiments confirm stable synthesis across 5 independent runs.

</details>


### [37] [OmniZip: Learning a Unified and Lightweight Lossless Compressor for Multi-Modal Data](https://arxiv.org/abs/2602.22286)
*Yan Zhao,Zhengxue Cheng,Junxuan Zhang,Dajiang Zhou,Qunshan Gu,Qi Wang,Li Song*

Main category: cs.LG

TL;DR: OmniZip是一个统一轻量级的多模态无损压缩器，支持图像、文本、语音、触觉、数据库和基因序列等多种数据类型，在压缩效率和推理速度方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前基于学习的无损压缩器大多针对单一模态设计，在多模态场景下会导致冗余的压缩器部署。不同数据类型在格式、维度和统计特性上差异很大，设计统一的多模态压缩器既关键又具挑战性。多模态大语言模型虽然提供了可能解决方案，但过于复杂不实用。

Method: 1. 模态统一的分词器：可逆地将多样数据转换为令牌；2. 模态路由上下文学习机制：实现灵活的多模态上下文建模；3. 模态路由前馈设计：增强模型的非线性表示能力；4. 重参数化训练策略：提升模型容量。

Result: 在多个模态上优于或匹配其他最先进的压缩器，相比gzip在CLIC-M、TouchandGo、enwik9、LibriSpeech和WikiSQL数据集上分别提升42%、57%、62%和42%、53%的压缩效率。在资源受限的边缘设备上支持近实时推理，在MacBook CPU和iPhone NPU上达到约1MB/s的速度。

Conclusion: OmniZip成功实现了统一轻量级的多模态无损压缩，解决了多模态压缩的挑战，在保持高性能的同时支持边缘设备上的实时推理，具有实际应用价值。

Abstract: Lossless compression is essential for efficient data storage and transmission. Although learning-based lossless compressors achieve strong results, most of them are designed for a single modality, leading to redundant compressor deployments in multi-modal settings. Designing a unified multi-modal compressor is critical yet challenging, as different data types vary largely in format, dimension, and statistics. Multi-modal large language models offer a promising resolution but remain too complex for practical use. Thus, we propose \textbf{OmniZip}, \textbf{a unified and lightweight lossless compressor for multi-modal data (like image, text, speech, tactile, database, and gene sequence)}. Built on a lightweight backbone, OmniZip incorporates three key components to enable efficient multi-modal lossless compression: a modality-unified tokenizer that reversibly transforms diverse data into tokens, a modality-routing context learning mechanism that enables flexible multi-modal context modeling, and a modality-routing feedforward design that further enhances the model's nonlinear representation flexibility. A reparameterization training strategy is used to enhance model capacity. OmniZip outperforms or matches other state-of-the-art compressors on multiple modalities, achieving 42\%, 57\%, 62\% and 42\%, 53\% higher compression efficiency than gzip on CLIC-M, TouchandGo, enwik9, LibriSpeech, and WikiSQL datasets, respectively. It also supports near real-time inference on resource-constrained edge devices, reaching about 1MB/s on MacBook CPUs and iPhone NPUs. Our code is released at https://github.com/adminasmi/OmniZip-CVPR2026.

</details>


### [38] [A 1/R Law for Kurtosis Contrast in Balanced Mixtures](https://arxiv.org/abs/2602.22334)
*Yuda Bi,Wenjun Xiao,Linhao Bai,Vince D Calhoun*

Main category: cs.LG

TL;DR: 论文证明了基于峰度的独立成分分析(ICA)在宽平衡混合中会失效，提出了一个尖锐的冗余定律，并展示了通过"净化"选择符号一致源可以恢复对比度


<details>
  <summary>Details</summary>
Motivation: 传统基于峰度的ICA方法在处理宽平衡信号混合时效果显著下降，需要理论解释这种退化现象并提供解决方案

Method: 1. 证明冗余定律：标准化投影的总体超额峰度与有效宽度成反比 2. 建立不可能性条件：估计误差受混合维度限制 3. 提出净化方法：选择少量符号一致源恢复对比度

Result: 1. 理论证明了峰度对比度随混合宽度R衰减为O(1/R) 2. 发现估计精度需要R≲κ_max√T 3. 净化方法能恢复与R无关的Ω(1/m)对比度 4. 合成实验验证了理论预测

Conclusion: 宽平衡混合会削弱基于峰度的ICA，但通过净化选择少量符号一致源可以恢复对比度，为实际应用提供了理论指导和实用方法

Abstract: Kurtosis-based Independent Component Analysis (ICA) weakens in wide, balanced mixtures. We prove a sharp redundancy law: for a standardized projection with effective width $R_{\mathrm{eff}}$ (participation ratio), the population excess kurtosis obeys $|κ(y)|=O(κ_{\max}/R_{\mathrm{eff}})$, yielding the order-tight $O(c_bκ_{\max}/R)$ under balance (typically $c_b=O(\log R)$). As an impossibility screen, under standard finite-moment conditions for sample kurtosis estimation, surpassing the $O(1/\sqrt{T})$ estimation scale requires $R\lesssim κ_{\max}\sqrt{T}$. We also show that \emph{purification} -- selecting $m\!\ll\!R$ sign-consistent sources -- restores $R$-independent contrast $Ω(1/m)$, with a simple data-driven heuristic. Synthetic experiments validate the predicted decay, the $\sqrt{T}$ crossover, and contrast recovery.

</details>


### [39] [Learning geometry-dependent lead-field operators for forward ECG modeling](https://arxiv.org/abs/2602.22367)
*Arsenii Dokuchaev,Francesca Bonizzoni,Stefano Pagani,Francesco Regazzoni,Simone Pezzuto*

Main category: cs.LG

TL;DR: 提出了一种形状感知的替代模型，用于心电正向模拟中的导联场算子，通过几何编码和条件神经替代实现高精度、低数据需求和高计算效率的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有心电正向计算模型面临三个挑战：1) 临床实践中难以获得完整躯干的高精度解剖表示；2) 导联场方法的计算成本随电极数量线性增长，限制了高密度记录的应用；3) 现有方法无法同时实现高解剖保真度、低数据需求和计算效率。

Method: 提出一个包含两个组件的框架：1) 几何编码模块，将解剖形状映射到低维潜在空间；2) 几何条件神经替代模型，根据空间坐标、电极位置和潜在编码预测导联场梯度。该模型可作为完整模型在正向心电模拟中的直接替代。

Result: 方法在躯干内（平均角度误差5°）和心脏内部都能高精度逼近导联场，实现高精度心电模拟（相对均方误差<2.5%）。该替代模型持续优于广泛使用的伪导联场近似，同时保持可忽略的推理成本。紧凑的潜在表示使其无需完整的躯干分割即可部署。

Conclusion: 提出的形状感知替代模型解决了现有心电正向模拟方法的局限性，在保持高保真度心电模拟的同时，实现了对数据需求低和计算效率高的平衡，可在临床数据有限的环境中部署。

Abstract: Modern forward electrocardiogram (ECG) computational models rely on an accurate representation of the torso domain. The lead-field method enables fast ECG simulations while preserving full geometric fidelity. Achieving high anatomical accuracy in torso representation is, however, challenging in clinical practice, as imaging protocols are typically focused on the heart and often do not include the entire torso. In addition, the computational cost of the lead-field method scales linearly with the number of electrodes, limiting its applicability in high-density recording settings. To date, no existing approach simultaneously achieves high anatomical fidelity, low data requirements and computational efficiency. In this work, we propose a shape-informed surrogate model of the lead-field operator that serves as a drop-in replacement for the full-order model in forward ECG simulations. The proposed framework consists of two components: a geometry-encoding module that maps anatomical shapes into a low-dimensional latent space, and a geometry-conditioned neural surrogate that predicts lead-field gradients from spatial coordinates, electrode positions and latent codes. The proposed method achieves high accuracy in approximating lead fields both within the torso (mean angular error 5°) and inside the heart, resulting in highly accurate ECG simulations (relative mean squared error <2.5%. The surrogate consistently outperforms the widely used pseudo lead-field approximation while preserving negligible inference cost. Owing to its compact latent representation, the method does not require a fully detailed torso segmentation and can therefore be deployed in data-limited settings while preserving high-fidelity ECG simulations.

</details>


### [40] [A Learning-Based Hybrid Decision Framework for Matching Systems with User Departure Detection](https://arxiv.org/abs/2602.22412)
*Ruiqi Zhou,Donghao Zhu,Houcai Shen*

Main category: cs.LG

TL;DR: 提出基于学习的混合框架，通过自适应调整即时匹配与延迟匹配策略，在动态匹配市场中平衡匹配效率与等待时间。


<details>
  <summary>Details</summary>
Motivation: 传统固定匹配策略在动态环境中不够灵活：延迟匹配能提高市场效率但会增加等待时间和市场拥堵，而即时匹配则相反。需要一种能自适应调整策略的方法。

Method: 提出基于学习的混合框架：持续收集用户离开时间数据，通过回归估计离开分布，基于决策阈值决定下一周期是否延迟匹配，阈值控制对匹配效率损失的容忍度。

Result: 该框架能显著减少等待时间和市场拥堵，同时只牺牲有限的匹配效率。通过动态调整策略，系统性能可在贪婪策略和耐心策略之间灵活调整。

Conclusion: 混合框架为静态匹配机制提供了鲁棒且自适应的替代方案，能够在动态匹配市场中智能平衡效率与等待时间。

Abstract: In matching markets such as kidney exchanges and freight exchanges, delayed matching has been shown to improve overall market efficiency. The benefits of delay are highly sensitive to participants' sojourn times and departure behavior, and delaying matches can impose significant costs, including longer waiting times and increased market congestion. These competing effects make fixed matching policies inherently inflexible in dynamic environments. We propose a learning-based Hybrid framework that adaptively combines immediate and delayed matching. The framework continuously collects data on user departures over time, estimates the underlying departure distribution via regression, and determines whether to delay matching in the subsequent period based on a decision threshold that governs the system's tolerance for matching efficiency loss. The proposed framework can substantially reduce waiting times and congestion while sacrificing only a limited amount of matching efficiency. By dynamically adjusting its matching strategy, the Hybrid framework enables system performance to flexibly interpolate between purely greedy and purely patient policies, offering a robust and adaptive alternative to static matching mechanisms.

</details>


### [41] [Sharp Convergence Rates for Masked Diffusion Models](https://arxiv.org/abs/2602.22505)
*Yuchen Liang,Zhiheng Tan,Ness Shroff,Yingbin Liang*

Main category: cs.LG

TL;DR: 该论文对离散扩散模型的采样器进行了理论分析，提出了基于TV距离的直接分析框架，改进了Euler方法的收敛保证，并首次分析了FHS采样器的理论性能


<details>
  <summary>Details</summary>
Motivation: 现有离散扩散模型采样器的理论分析存在局限：主要在KL散度下分析，参数依赖松散且需要强分数估计假设；现有理论无法覆盖高性能的FHS采样器；需要更严格的收敛分析框架

Method: 1) 为Euler方法开发基于总变差（TV）距离的直接分析框架，放宽分数估计假设；2) 建立Euler采样器的收敛下界；3) 分析FHS采样器，证明其采样误差仅来自分数估计误差；4) 提出基于CTMC轨迹的TV误差分解和FHS的基于解耦的路径分析

Result: 1) Euler方法的TV分析放宽了分数估计假设，改进了参数依赖，无需代理初始化；2) 建立了Euler采样器的收敛下界，证明在数据维度d和目标精度ε方面的紧致性；3) FHS采样器仅产生分数估计误差，并建立了匹配的下界证明其紧致性

Conclusion: 该工作为离散扩散模型采样器提供了更严格的理论分析框架，改进了现有Euler方法的理论保证，首次为FHS采样器建立了理论分析，提出的TV误差分解和路径分析方法可能具有独立价值

Abstract: Discrete diffusion models have achieved strong empirical performance in text and other symbolic domains, with masked (absorbing-rate) variants emerging as competitive alternatives to autoregressive models. Among existing samplers, the Euler method remains the standard choice in many applications, and more recently, the First-Hitting Sampler (FHS) has shown considerable promise for masked diffusion models. Despite their practical success, the theoretical understanding of these samplers remains limited. Existing analyses are conducted in Kullback-Leibler (KL) divergence, which often yields loose parameter dependencies and requires strong assumptions on score estimation. Moreover, these guarantees do not cover recently developed high-performance sampler of FHS. In this work, we first develop a direct total-variation (TV) based analysis for the Euler method that overcomes these limitations. Our results relax assumptions on score estimation, improve parameter dependencies, and establish convergence guarantees without requiring any surrogate initialization. Also for this setting, we provide the first convergence lower bound for the Euler sampler, establishing tightness with respect to both the data dimension $d$ and the target accuracy $\varepsilon$. Finally, we analyze the FHS sampler and show that it incurs no sampling error beyond that induced by score estimation, which we show to be tight with a matching lower error bound. Overall, our analysis introduces a direct TV-based error decomposition along the CTMC trajectory and a decoupling-based path-wise analysis for FHS, which may be of independent interest.

</details>


### [42] [Decentralized Ranking Aggregation: Gossip Algorithms for Borda and Copeland Consensus](https://arxiv.org/abs/2602.22847)
*Anna Van Elst,Kerrian Le Caillec,Igor Colin,Stephan Clémençon*

Main category: cs.LG

TL;DR: 该论文提出了一种在去中心化网络中实现排名聚合共识的方法，使用随机gossip通信让自主代理通过局部交互计算全局排名共识，无需中央协调。


<details>
  <summary>Details</summary>
Motivation: 现有排名聚合算法主要针对集中式设置，而许多技术（如P2P网络、物联网、多智能体系统）需要在去中心化环境中计算共识排名，这面临方法学挑战。

Method: 基于随机gossip通信，让自治智能体仅通过局部交互计算全局排名共识，无需协调或中央权威。提出了Borda、Copeland共识方法的去中心化实现，以及中位数排名规则和局部Kemenization的去中心化实现。

Result: 为Borda和Copeland共识方法提供了严格的收敛保证和明确的速率界限。在各种网络拓扑结构以及真实和合成排名数据集上的广泛实证评估表明，算法能快速可靠地收敛到正确的排名聚合结果。

Conclusion: 该研究成功实现了在去中心化设置中计算排名共识的方法，解决了关键挑战如对腐败节点的鲁棒性和降低通信成本，为分布式偏好分析提供了实用解决方案。

Abstract: The concept of ranking aggregation plays a central role in preference analysis, and numerous algorithms for calculating median rankings, often originating in social choice theory, have been documented in the literature, offering theoretical guarantees in a centralized setting, i.e., when all the ranking data to be aggregated can be brought together in a single computing unit. For many technologies (e.g. peer-to-peer networks, IoT, multi-agent systems), extending the ability to calculate consensus rankings with guarantees in a decentralized setting, i.e., when preference data is initially distributed across a communicating network, remains a major methodological challenge. Indeed, in recent years, the literature on decentralized computation has mainly focused on computing or optimizing statistics such as arithmetic means using gossip algorithms. The purpose of this article is precisely to study how to achieve reliable consensus on collective rankings using classical rules (e.g. Borda, Copeland) in a decentralized setting, thereby raising new questions, robustness to corrupted nodes, and scalability through reduced communication costs in particular. The approach proposed and analyzed here relies on random gossip communication, allowing autonomous agents to compute global ranking consensus using only local interactions, without coordination or central authority.
  We provide rigorous convergence guarantees, including explicit rate bounds, for the Borda and Copeland consensus methods. Beyond these rules, we also provide a decentralized implementation of consensus according to the median rank rule and local Kemenization. Extensive empirical evaluations on various network topologies and real and synthetic ranking datasets demonstrate that our algorithms converge quickly and reliably to the correct ranking aggregation.

</details>


### [43] [Exploratory Memory-Augmented LLM Agent via Hybrid On- and Off-Policy Optimization](https://arxiv.org/abs/2602.23008)
*Zeyuan Liu,Jeonghye Kim,Xufang Luo,Dongsheng Li,Yuqing Yang*

Main category: cs.LG

TL;DR: EMPO²是一个混合强化学习框架，通过记忆增强探索，结合on-和off-policy更新，解决LLM智能体在需要发现新状态环境中的探索瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 探索是大型语言模型智能体在强化学习训练中的关键瓶颈。现有方法虽然利用预训练知识，但在需要发现新状态的环境（如ScienceWorld和WebShop）中表现不佳。

Method: 提出EMPO²（探索性记忆增强on-和off-policy优化）混合RL框架：1）利用记忆进行探索；2）结合on-policy和off-policy更新，使LLM在有记忆时表现良好，无记忆时仍保持鲁棒性。

Result: 在ScienceWorld和WebShop上，EMPO²相比GRPO分别提升128.6%和11.3%。在分布外测试中，EMPO²对新任务展现出卓越的适应性，仅需少量记忆试验且无需参数更新。

Conclusion: EMPO²是构建更具探索性和泛化能力的LLM智能体的有前景框架，有效解决了探索瓶颈问题。

Abstract: Exploration remains the key bottleneck for large language model agents trained with reinforcement learning. While prior methods exploit pretrained knowledge, they fail in environments requiring the discovery of novel states. We propose Exploratory Memory-Augmented On- and Off-Policy Optimization (EMPO$^2$), a hybrid RL framework that leverages memory for exploration and combines on- and off-policy updates to make LLMs perform well with memory while also ensuring robustness without it. On ScienceWorld and WebShop, EMPO$^2$ achieves 128.6% and 11.3% improvements over GRPO, respectively. Moreover, in out-of-distribution tests, EMPO$^2$ demonstrates superior adaptability to new tasks, requiring only a few trials with memory and no parameter updates. These results highlight EMPO$^2$ as a promising framework for building more exploratory and generalizable LLM-based agents.

</details>


### [44] [Regularized Online RLHF with Generalized Bilinear Preferences](https://arxiv.org/abs/2602.23116)
*Junghyun Lee,Minju Hong,Kwang-Sung Jun,Chulhee Yun,Se-Young Yun*

Main category: cs.LG

TL;DR: 该论文研究了上下文在线RLHF（强化学习与人类反馈）中一般偏好的纳什均衡识别问题，采用广义双线性偏好模型（GBPM）处理非传递性偏好，并提出了两种具有理论保证的简单算法。


<details>
  <summary>Details</summary>
Motivation: 现有RLHF研究大多局限于反向KL正则化，且在高维环境中缺乏统计效率保证。本文旨在解决一般偏好学习问题，允许任意强凸正则化器，并建立高维环境中的高效在线学习算法。

Method: 1. 采用广义双线性偏好模型（GBPM）通过低秩斜对称矩阵建模非传递性偏好
2. 基于强凸性和GBPM斜对称性，证明贪婪策略的对偶间隙受估计误差平方的约束
3. 提出两种简单算法：贪婪采样算法（Greedy Sampling）和探索-提交算法（Explore-Then-Commit）

Result: 1. 贪婪采样算法实现了$\tilde{O}(ηd^4 (\log T)^2)$的多对数遗憾，且与$e^{O(η)}$无关
2. 探索-提交算法利用低秩结构实现了$\tilde{O}(\sqrt{ηr T})$的遗憾，与$\mathrm{poly}(d)$无关，这是高维在线RLHF的首个统计效率保证

Conclusion: 本文为一般偏好的上下文在线RLHF提供了理论框架和高效算法，突破了现有方法在正则化类型和维度依赖性上的限制，为高维环境中的RLHF应用奠定了理论基础。

Abstract: We consider the problem of contextual online RLHF with general preferences, where the goal is to identify the Nash Equilibrium. We adopt the Generalized Bilinear Preference Model (GBPM) to capture potentially intransitive preferences via low-rank, skew-symmetric matrices. We investigate general preference learning with any strongly convex regularizer (where $η^{-1}$ is the regularization strength), generalizing beyond prior works limited to reverse KL-regularization. Central to our analysis is proving that the dual gap of the greedy policy is bounded by the square of the estimation error - a result derived solely from strong convexity and the skew-symmetricity of GBPM.Building on this insight and a feature diversity assumption, we establish two regret bounds via two simple algorithms: (1) Greedy Sampling achieves polylogarithmic, $e^{O(η)}$-free regret $\tilde{O}(ηd^4 (\log T)^2)$. (2) Explore-Then-Commit achieves $\mathrm{poly}(d)$-free regret $\tilde{O}(\sqrt{ηr T})$ by exploiting the low-rank structure; this is the first statistically efficient guarantee for online RLHF in high-dimensions.

</details>


### [45] [Closing the gap on tabular data with Fourier and Implicit Categorical Features](https://arxiv.org/abs/2602.23182)
*Marius Dragoi,Florin Gogianu,Elena Burceanu*

Main category: cs.LG

TL;DR: 该论文提出了一种结合统计特征处理和傅里叶学习的方法，以提升深度学习在表格数据上的性能，使其能够接近甚至超越XGBoost等树模型的表现。


<details>
  <summary>Details</summary>
Motivation: 深度学习在表格数据上表现不如树模型，作者认为这是因为树模型能更好地处理具有分类特征的非线性交互，而神经网络偏向于均匀数值处理和平滑解，难以有效利用这些模式。

Method: 使用基于统计的特征处理技术识别与目标强相关的离散化特征，并通过Learned Fourier方法缓解深度学习模型对过度平滑解的偏好，使其更适应数据固有特性。

Result: 提出的特征预处理方法显著提升了深度学习模型的性能，使其在综合表格数据基准测试中能够接近甚至超越XGBoost的表现。

Conclusion: 通过针对性地处理表格数据的特征特性和模型偏差，深度学习可以在表格数据领域取得与树模型相媲美的性能，为神经网络的"最后堡垒"提供了有效解决方案。

Abstract: While Deep Learning has demonstrated impressive results in applications on various data types, it continues to lag behind tree-based methods when applied to tabular data, often referred to as the last "unconquered castle" for neural networks. We hypothesize that a significant advantage of tree-based methods lies in their intrinsic capability to model and exploit non-linear interactions induced by features with categorical characteristics. In contrast, neural-based methods exhibit biases toward uniform numerical processing of features and smooth solutions, making it challenging for them to effectively leverage such patterns. We address this performance gap by using statistical-based feature processing techniques to identify features that are strongly correlated with the target once discretized. We further mitigate the bias of deep models for overly-smooth solutions, a bias that does not align with the inherent properties of the data, using Learned Fourier. We show that our proposed feature preprocessing significantly boosts the performance of deep learning models and enables them to achieve a performance that closely matches or surpasses XGBoost on a comprehensive tabular data benchmark.

</details>


### [46] [InnerQ: Hardware-aware Tuning-free Quantization of KV Cache for Large Language Models](https://arxiv.org/abs/2602.23200)
*Sayed Mohammadreza Tayaranian Hosseini,Amir Ardakani,Warren J. Gross*

Main category: cs.LG

TL;DR: InnerQ是一种硬件感知的KV缓存量化方案，通过对内部维度进行分组量化，结合混合量化、高精度窗口和每通道归一化等技术，在保持精度的同时显著降低解码延迟。


<details>
  <summary>Details</summary>
Motivation: 大语言模型解码过程中的KV缓存占用大量内存，成为长序列生成的主要瓶颈。现有量化方法主要关注压缩KV缓存但未充分考虑硬件效率。需要一种既能压缩KV缓存又能降低解码延迟的硬件感知量化方案。

Method: InnerQ采用内部维度分组量化，将缓存矩阵在内部维度上分组，使反量化与向量矩阵乘法对齐，实现尺度因子在GPU计算单元间的复用。包含三个关键技术：1) 基于局部统计的混合量化；2) 对最近token和注意力汇聚token的高精度窗口；3) 键缓存的每通道归一化。

Result: 在Llama模型上的评估显示，InnerQ比先前工作加速达22%，比半精度向量矩阵乘法加速达88%。在GSM8K few-shot任务上保持与非量化KV缓存相当的性能，优于现有KV缓存量化方法。

Conclusion: InnerQ通过硬件感知的KV缓存量化设计，在保持模型精度的同时显著提升解码效率，为大语言模型的长序列生成提供了有效的内存优化解决方案。

Abstract: Reducing the hardware footprint of large language models (LLMs) during decoding is critical for efficient long-sequence generation. A key bottleneck is the key-value (KV) cache, whose size scales with sequence length and easily dominates the memory footprint of the model. Previous work proposed quantization methods that are focused on compressing the KV cache while maintaining its information. We introduce InnerQ, a hardware-aware KV-cache quantization scheme that lowers decode latency without sacrificing accuracy. InnerQ applies group-wise quantization while grouping the cache matrices over their inner dimension. Unlike previous work that group over the outer dimension, InnerQ aligns dequantization with the vector-matrix multiplication and enables scale factor reuse across GPU compute units. This reduces memory accesses and accelerates dequantization, yielding up to $22\%$ speedup over previous work and up to $88\%$ over half-precision vector-matrix multiplication. To preserve fidelity under aggressive compression, InnerQ incorporates (i) hybrid quantization, selecting symmetric or asymmetric quantization per group based on local statistics; (ii) high-precision windows for both the most recent tokens and the attention sink tokens to mitigate outlier leakage; and (iii) per-channel normalization of the key cache, computed once during prefill and folded into the query to avoid runtime overhead. Our evaluation experiments on Llama models shows that InnerQ maintains a few-shot GSM8K performance comparable to non-quantized KV caches and surpasses prior KV cache quantization methods.

</details>


### [47] [Entropy-Controlled Flow Matching](https://arxiv.org/abs/2602.22265)
*Chika Maduabuchi*

Main category: cs.LG

TL;DR: 提出熵控制流匹配（ECFM），通过约束熵率预算来避免传统流匹配中的低熵瓶颈问题，确保语义模式覆盖


<details>
  <summary>Details</summary>
Motivation: 标准流匹配方法不直接控制轨迹的信息几何结构，容易出现低熵瓶颈，导致语义模式暂时性丢失，影响生成质量

Method: 基于连续方程路径的约束变分原理，强制执行全局熵率预算d/dt H(mu_t) >= -lambda，构建凸优化问题，具有KKT/Pontryagin系统和随机控制表示

Result: ECFM在纯传输机制下恢复熵最优传输测地线，Gamma收敛到经典最优传输；提供模式覆盖和密度下界保证，具有Lipschitz稳定性；构建了无约束流匹配的近乎最优崩溃反例

Conclusion: ECFM通过熵控制解决了传统流匹配的模式丢失问题，提供了理论保证和稳定性，是连接流匹配与最优传输的桥梁

Abstract: Modern vision generators transport a base distribution to data through time-indexed measures, implemented as deterministic flows (ODEs) or stochastic diffusions (SDEs). Despite strong empirical performance, standard flow-matching objectives do not directly control the information geometry of the trajectory, allowing low-entropy bottlenecks that can transiently deplete semantic modes. We propose Entropy-Controlled Flow Matching (ECFM): a constrained variational principle over continuity-equation paths enforcing a global entropy-rate budget d/dt H(mu_t) >= -lambda. ECFM is a convex optimization in Wasserstein space with a KKT/Pontryagin system, and admits a stochastic-control representation equivalent to a Schrodinger bridge with an explicit entropy multiplier. In the pure transport regime, ECFM recovers entropic OT geodesics and Gamma-converges to classical OT as lambda -> 0. We further obtain certificate-style mode-coverage and density-floor guarantees with Lipschitz stability, and construct near-optimal collapse counterexamples for unconstrained flow matching.

</details>


### [48] [Differentiable Zero-One Loss via Hypersimplex Projections](https://arxiv.org/abs/2602.23336)
*Camilo Gomez,Pengyang Wang,Liansheng Tang*

Main category: cs.LG

TL;DR: 本文提出了一种可微的零一损失近似方法，通过约束优化框架构建平滑的保序投影到n,k维超单纯形上，称为Soft-Binary-Argmax算子，解决了传统零一损失不可微的问题。


<details>
  <summary>Details</summary>
Motivation: 零一损失被认为是分类性能的黄金标准，但由于其不可微性无法用于基于梯度的优化。需要一种可微的近似方法，能够保持零一损失的优势同时兼容梯度优化。

Method: 通过约束优化框架构建平滑的保序投影到n,k维超单纯形上，提出Soft-Binary-Argmax算子。推导其数学性质，展示其Jacobian的高效计算方法，并将其集成到二元和多类学习系统中。

Result: 该方法在大批量训练中通过施加几何一致性约束显著提高了泛化性能，缩小了传统大批量训练中观察到的性能差距。

Conclusion: 提出的Soft-Binary-Argmax算子为机器学习中集成结构化优化组件提供了有效工具，实现了零一损失的可微近似，在保持性能优势的同时兼容梯度优化。

Abstract: Recent advances in machine learning have emphasized the integration of structured optimization components into end-to-end differentiable models, enabling richer inductive biases and tighter alignment with task-specific objectives. In this work, we introduce a novel differentiable approximation to the zero-one loss-long considered the gold standard for classification performance, yet incompatible with gradient-based optimization due to its non-differentiability. Our method constructs a smooth, order-preserving projection onto the n,k-dimensional hypersimplex through a constrained optimization framework, leading to a new operator we term Soft-Binary-Argmax. After deriving its mathematical properties, we show how its Jacobian can be efficiently computed and integrated into binary and multiclass learning systems. Empirically, our approach achieves significant improvements in generalization under large-batch training by imposing geometric consistency constraints on the output logits, thereby narrowing the performance gap traditionally observed in large-batch training.

</details>


### [49] [FlashOptim: Optimizers for Memory Efficient Training](https://arxiv.org/abs/2602.23349)
*Jose Javier Gonzalez Ortiz,Abhay Gupta,Chris Renard,Davis Blalock*

Main category: cs.LG

TL;DR: FlashOptim通过优化技术将训练时每个参数的内存占用减少50%以上，同时保持模型质量和API兼容性


<details>
  <summary>Details</summary>
Motivation: 混合精度训练需要大量加速器内存（每个参数16字节），使得训练70亿参数模型对内存小于100GB的研究者不切实际

Method: 1. 改进主权重分割技术，通过寻找和利用量化误差的紧界；2. 设计压缩扩展函数，大幅减少8位优化器状态量化的误差；3. 结合16位梯度

Result: 将AdamW内存从16字节/参数降至7字节/参数（梯度释放时为5字节），模型检查点大小减少一半以上，在SGD、AdamW、Lion优化器上无质量损失

Conclusion: FlashOptim显著降低训练内存需求，使大规模模型训练对资源有限的研究者更加可行，且不牺牲模型性能

Abstract: Standard mixed-precision training of neural networks requires many bytes of accelerator memory for each model parameter. These bytes reflect not just the parameter itself, but also its gradient and one or more optimizer state variables. With each of these values typically requiring 4 bytes, training even a 7 billion parameter model can be impractical for researchers with less than 100GB of accelerator memory.
  We introduce FlashOptim, a suite of optimizations that reduces per-parameter memory by over 50% while preserving model quality and API compatibility. Our approach introduces two key techniques. First, we improve master weight splitting by finding and exploiting a tight bound on its quantization error. Second, we design companding functions that greatly reduce the error in 8-bit optimizer state quantization. Together with 16-bit gradients, these techniques reduce AdamW memory from 16 bytes to 7 bytes per parameter, or 5 bytes with gradient release. They also cut model checkpoint sizes by more than half.
  Experiments with FlashOptim applied to SGD, AdamW, and Lion show no measurable quality degradation on any task from a collection of standard vision and language benchmarks, including Llama-3.1-8B finetuning.

</details>


### [50] [DP-aware AdaLN-Zero: Taming Conditioning-Induced Heavy-Tailed Gradients in Differentially Private Diffusion](https://arxiv.org/abs/2602.22610)
*Tao Huang,Jiayang Meng,Xu Yang,Chen Hou,Hong Chen*

Main category: cs.LG

TL;DR: DP-aware AdaLN-Zero：一种针对条件扩散模型的敏感性感知条件注入机制，通过限制条件表示幅度和调制参数来抑制梯度尾部事件，从而在差分隐私SGD训练中减少全局剪裁偏差，提升模型效用。


<details>
  <summary>Details</summary>
Motivation: 异构条件上下文（如观测历史、缺失模式或异常协变量）在条件扩散模型中会导致重尾的每样本梯度。在差分隐私SGD训练中，这些罕见但重尾的梯度会过度触发全局剪裁，导致异常值主导更新、增加剪裁偏差，并在固定隐私预算下降低模型效用。

Method: 提出DP-aware AdaLN-Zero，一种即插即用的敏感性感知条件注入机制。通过有界重参数化联合约束条件表示幅度和AdaLN调制参数，在梯度剪裁和噪声注入之前抑制极端梯度尾部事件，无需修改DP-SGD机制本身。

Result: 在相同隐私设置下，配备DP-aware AdaLN-Zero的DP-SGD在插值/填补和预测任务上表现更优。在真实世界电力数据集和两个公开ETT基准测试中均观察到一致的性能提升。梯度诊断显示条件特定的尾部重塑和减少的剪裁失真，同时保持非私有训练中的表达能力。

Conclusion: 敏感性感知条件注入可以显著改善私有条件扩散训练，而不会牺牲标准性能。该方法通过限制条件表示幅度和调制参数来抑制梯度尾部事件，从而减少DP-SGD中的剪裁偏差，提升模型在隐私保护设置下的效用。

Abstract: Condition injection enables diffusion models to generate context-aware outputs, which is essential for many time-series tasks. However, heterogeneous conditional contexts (e.g., observed history, missingness patterns or outlier covariates) can induce heavy-tailed per-example gradients. Under Differentially Private Stochastic Gradient Descent (DP-SGD), these rare conditioning-driven heavy-tailed gradients disproportionately trigger global clipping, resulting in outlier-dominated updates, larger clipping bias, and degraded utility under a fixed privacy budget. In this paper, we propose DP-aware AdaLN-Zero, a drop-in sensitivity-aware conditioning mechanism for conditional diffusion transformers that limits conditioning-induced gain without modifying the DP-SGD mechanism. DP-aware AdaLN-Zero jointly constrains conditioning representation magnitude and AdaLN modulation parameters via bounded re-parameterization, suppressing extreme gradient tail events before gradient clipping and noise injection. Empirically, DP-SGD equipped with DP-aware AdaLN-Zero improves interpolation/imputation and forecasting under matched privacy settings. We observe consistent gains on a real-world power dataset and two public ETT benchmarks over vanilla DP-SGD. Moreover, gradient diagnostics attribute these improvements to conditioning-specific tail reshaping and reduced clipping distortion, while preserving expressiveness in non-private training. Overall, these results show that sensitivity-aware conditioning can substantially improve private conditional diffusion training without sacrificing standard performance.

</details>


### [51] [SOTAlign: Semi-Supervised Alignment of Unimodal Vision and Language Models via Optimal Transport](https://arxiv.org/abs/2602.23353)
*Simon Roschmann,Paul Krzakala,Sonia Mazelet,Quentin Bouniot,Zeynep Akata*

Main category: cs.LG

TL;DR: SOTAlign：一种两阶段的半监督对齐框架，利用少量配对数据和大量非配对数据对齐预训练的单模态编码器，通过最优传输方法在非配对数据上传递关系结构。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖对比损失和数百万配对样本，本文探讨是否能用更少的监督实现有意义的模态对齐。

Method: 提出SOTAlign两阶段框架：第一阶段用少量配对数据通过线性教师恢复粗略共享几何；第二阶段通过最优传输散度在非配对数据上精炼对齐，传递关系结构而不过度约束目标空间。

Result: SOTAlign能有效利用非配对图像和文本，学习跨数据集和编码器对的鲁棒联合嵌入，显著优于有监督和半监督基线方法。

Conclusion: 通过结合少量配对数据和大量非配对数据，SOTAlign实现了有效的模态对齐，为半监督表示对齐提供了新思路。

Abstract: The Platonic Representation Hypothesis posits that neural networks trained on different modalities converge toward a shared statistical model of the world. Recent work exploits this convergence by aligning frozen pretrained vision and language models with lightweight alignment layers, but typically relies on contrastive losses and millions of paired samples. In this work, we ask whether meaningful alignment can be achieved with substantially less supervision. We introduce a semi-supervised setting in which pretrained unimodal encoders are aligned using a small number of image-text pairs together with large amounts of unpaired data. To address this challenge, we propose SOTAlign, a two-stage framework that first recovers a coarse shared geometry from limited paired data using a linear teacher, then refines the alignment on unpaired samples via an optimal-transport-based divergence that transfers relational structure without overconstraining the target space. Unlike existing semi-supervised methods, SOTAlign effectively leverages unpaired images and text, learning robust joint embeddings across datasets and encoder pairs, and significantly outperforming supervised and semi-supervised baselines.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [52] [SODA-CitrON: Static Object Data Association by Clustering Multi-Modal Sensor Detections Online](https://arxiv.org/abs/2602.22243)
*Jan Nausner,Kilian Wohlleben,Michael Hubner*

Main category: cs.RO

TL;DR: SODA-CitrON是一种用于静态对象数据关联的在线聚类方法，通过无监督机器学习处理异构传感器检测，实现实时位置估计和轨迹跟踪。


<details>
  <summary>Details</summary>
Motivation: 传统数据关联方法（如JPDA）主要针对动态目标，但在静态对象间歇性观测、异构不确定性场景下效果不佳，因为运动模型对杂波区分能力有限。

Method: 提出SODA-CitrON方法，通过在线聚类多模态传感器检测，同时估计未知数量静态对象的位置并维持持久轨迹，采用完全在线无监督学习，处理时间无关的多传感器测量。

Result: 在蒙特卡洛仿真中，SODA-CitrON在F1分数、位置RMSE、MOTP和MOTA指标上均优于贝叶斯滤波、DBSTREAM聚类和JPDA等先进方法。

Conclusion: SODA-CitrON为静态对象数据关联提供了高效解决方案，具有对数线性复杂度、完全可解释性，在静态地图构建场景中表现优异。

Abstract: The online fusion and tracking of static objects from heterogeneous sensor detections is a fundamental problem in robotics, autonomous systems, and environmental mapping. Although classical data association approaches such as JPDA are well suited for dynamic targets, they are less effective for static objects observed intermittently and with heterogeneous uncertainties, where motion models provide minimal discriminative with respect to clutter. In this paper, we propose a novel method for static object data association by clustering multi-modal sensor detections online (SODA-CitrON), while simultaneously estimating positions and maintaining persistent tracks for an unknown number of objects. The proposed unsupervised machine learning approach operates in a fully online manner and handles temporally uncorrelated and multi-sensor measurements. Additionally, it has a worst-case loglinear complexity in the number of sensor detections while providing full output explainability. We evaluate the proposed approach in different Monte Carlo simulation scenarios and compare it against state-of-the-art methods, including Bayesian filtering, DBSTREAM clustering, and JPDA. The results demonstrate that SODA-CitrON consistently outperforms the compared methods in terms of F1 score, position RMSE, MOTP, and MOTA in the static object mapping scenarios studied.

</details>


### [53] [Detection and Recognition: A Pairwise Interaction Framework for Mobile Service Robots](https://arxiv.org/abs/2602.22346)
*Mengyu Liang,Sarah Gillet Schlegel,Iolanda Leite*

Main category: cs.RO

TL;DR: 该论文提出了一种基于成对几何和运动线索的轻量级人类交互感知方法，适用于移动服务机器人，在计算成本较低的情况下实现足够的交互识别精度。


<details>
  <summary>Details</summary>
Motivation: 移动服务机器人（如割草机、清洁机器人）在人类环境中需要理解人类交互以实现安全、社会感知的导航。现有方法要么过于复杂（整体群体活动识别），要么依赖骨骼表示（在户外环境效果有限）。该研究认为成对人类交互是机器人社会理解的最小且充分的感知单元。

Method: 采用两阶段框架：首先基于轻量级几何和运动线索识别候选交互对，然后使用关系网络对交互类型进行分类。这种方法避免使用复杂的骨骼表示或高计算成本的外观特征。

Result: 在JRDB数据集上，该方法以较低的计算成本和模型大小实现了足够的精度。在Collective Activity Dataset上的实验和在割草机收集数据集上的零样本测试进一步证明了该框架的通用性。

Conclusion: 成对几何和运动线索为移动服务机器人提供了实用的交互感知基础，有望集成到未来移动机器人导航栈中。该方法在计算效率和准确性之间取得了良好平衡。

Abstract: Autonomous mobile service robots, like lawnmowers or cleaning robots, operating in human-populated environments need to reason about local human-human interactions to support safe and socially aware navigation while fulfilling their tasks. For such robots, interaction understanding is not primarily a fine-grained recognition problem, but a perception problem under limited sensing quality and computational resources. Many existing approaches focus on holistic group activity recognition, which often requires complex and large models which may not be necessary for mobile service robots. Others use pairwise interaction methods which commonly rely on skeletal representations but their use in outdoor environments remains challenging. In this work, we argue that pairwise human interaction constitute a minimal yet sufficient perceptual unit for robot-centric social understanding. We study the problem of identifying interacting person pairs and classifying coarse-grained interaction behaviors sufficient for downstream group-level reasoning and service robot decision-making. To this end, we adopt a two-stage framework in which candidate interacting pairs are first identified based on lightweight geometric and motion cues, and interaction types are subsequently classified using a relation network. We evaluate the proposed approach on the JRDB dataset, where it achieves sufficient accuracy with reduced computational cost and model size compared to appearance-based methods. Additional experiments on the Collective Activity Dataset and zero shot test on a lawnmower-collected dataset further illustrate the generality of the proposed framework. These results suggest that pairwise geometric and motion cues provide a practical basis for interaction perception on mobile service robot providing a promising method for integration into mobile robot navigation stacks in future work. Code will be released soon

</details>


### [54] [Hierarchical Trajectory Planning of Floating-Base Multi-Link Robot for Maneuvering in Confined Environments](https://arxiv.org/abs/2602.22459)
*Yicheng Chen,Jinjie Li,Haokun Liu,Zicheng Luo,Kotaro Kaneko,Moju Zhao*

Main category: cs.RO

TL;DR: 提出了一种用于浮基多连杆机器人的分层轨迹规划框架，通过全局引导与局部优化相结合，直接从点云数据生成连续、无碰撞、动态可行的轨迹。


<details>
  <summary>Details</summary>
Motivation: 浮基多连杆机器人能够在飞行中改变形状，适合在受限环境中执行自主检查和搜救任务。然而，轨迹规划面临高维、约束丰富的挑战，需要同时处理碰撞避免、运动学限制和动态可行性。

Method: 1. 利用机器人的双重特性（根连杆作为刚体引导，关节提供灵活性）生成全局锚点状态，将规划问题分解为可处理的片段。2. 设计局部轨迹规划器，通过可微目标函数和约束并行优化每个片段，系统保证运动学可行性并避免控制奇点。3. 实现完整系统，直接处理点云数据，无需人工障碍物建模。

Result: 大量仿真和真实世界实验证实，该框架使关节式空中机器人能够利用其形态实现刚性机器人无法完成的机动。这是首个在实际机器人上演示的规划框架，能够直接从原始点云输入生成连续、无碰撞、动态可行的轨迹。

Conclusion: 该分层轨迹规划框架成功解决了浮基多连杆机器人的轨迹规划挑战，通过全局引导与局部优化的结合，实现了直接从点云数据生成可行轨迹的能力，为受限环境中的自主应用提供了有效解决方案。

Abstract: Floating-base multi-link robots can change their shape during flight, making them well-suited for applications in confined environments such as autonomous inspection and search and rescue. However, trajectory planning for such systems remains an open challenge because the problem lies in a high-dimensional, constraint-rich space where collision avoidance must be addressed together with kinematic limits and dynamic feasibility. This work introduces a hierarchical trajectory planning framework that integrates global guidance with configuration-aware local optimization. First, we exploit the dual nature of these robots - the root link as a rigid body for guidance and the articulated joints for flexibility - to generate global anchor states that decompose the planning problem into tractable segments. Second, we design a local trajectory planner that optimizes each segment in parallel with differentiable objectives and constraints, systematically enforcing kinematic feasibility and maintaining dynamic feasibility by avoiding control singularities. Third, we implement a complete system that directly processes point-cloud data, eliminating the need for handcrafted obstacle models. Extensive simulations and real-world experiments confirm that this framework enables an articulated aerial robot to exploit its morphology for maneuvering that rigid robots cannot achieve. To the best of our knowledge, this is the first planning framework for floating-base multi-link robots that has been demonstrated on a real robot to generate continuous, collision-free, and dynamically feasible trajectories directly from raw point-cloud inputs, without relying on handcrafted obstacle models.

</details>


### [55] [EgoAVFlow: Robot Policy Learning with Active Vision from Human Egocentric Videos via 3D Flow](https://arxiv.org/abs/2602.22461)
*Daesol Cho,Youngseok Jang,Danfei Xu,Sehoon Ha*

Main category: cs.RO

TL;DR: EgoAVFlow：从第一人称视频学习操作和主动视觉，通过共享3D流表示实现几何可见性推理，无需机器人演示即可迁移


<details>
  <summary>Details</summary>
Motivation: 第一人称人类视频提供了可扩展的操作演示来源，但部署到机器人上需要主动视角控制以保持任务关键可见性。人类视角模仿常因人类特定先验而失败，无法提供所需的可见性维护

Method: 提出EgoAVFlow，通过共享3D流表示学习操作和主动视觉，支持几何可见性推理。使用扩散模型预测机器人动作、未来3D流和相机轨迹，在测试时通过奖励最大化去噪（基于预测运动和场景几何计算的可见性感知奖励）细化视角

Result: 在主动变化视角下的真实世界实验中，EgoAVFlow始终优于先前基于人类演示的基线方法，展示了有效的可见性维护和无需机器人演示的鲁棒操作

Conclusion: EgoAVFlow能够从第一人称视频有效学习操作技能和主动视觉策略，通过几何可见性推理实现机器人视角控制，无需专门的机器人演示数据

Abstract: Egocentric human videos provide a scalable source of manipulation demonstrations; however, deploying them on robots requires active viewpoint control to maintain task-critical visibility, which human viewpoint imitation often fails to provide due to human-specific priors. We propose EgoAVFlow, which learns manipulation and active vision from egocentric videos through a shared 3D flow representation that supports geometric visibility reasoning and transfers without robot demonstrations. EgoAVFlow uses diffusion models to predict robot actions, future 3D flow, and camera trajectories, and refines viewpoints at test time with reward-maximizing denoising under a visibility-aware reward computed from predicted motion and scene geometry. Real-world experiments under actively changing viewpoints show that EgoAVFlow consistently outperforms prior human-demo-based baselines, demonstrating effective visibility maintenance and robust manipulation without robot demonstrations.

</details>


### [56] [When to Act, Ask, or Learn: Uncertainty-Aware Policy Steering](https://arxiv.org/abs/2602.22474)
*Jessie Yuan,Yilin Wu,Andrea Bajcsy*

Main category: cs.RO

TL;DR: UPS是一个不确定性感知的策略引导框架，通过校准的视觉语言模型验证器来区分高置信动作、任务模糊场景和策略能力不足情况，从而最小化昂贵的人工干预。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉语言模型的策略引导框架通常假设模型校准良好，但实践中VLM的过度自信判断会降低引导性能，特别是在任务语义不确定性和预训练策略动作不确定性或能力不足的情况下。

Method: 提出不确定性感知策略引导框架，联合推理语义任务不确定性和低层动作可行性，通过符合性预测校准VLM和预训练策略的组合，提供统计保证。采用残差学习在部署中收集干预后改进预训练策略。

Result: 在仿真和硬件实验中证明，UPS能够区分自信、模糊和能力不足的场景，相比未校准基线和先前的人机门控持续学习方法，最小化了昂贵用户干预。

Conclusion: UPS框架通过不确定性感知的验证和校准，有效解决了VLM过度自信问题，实现了持续学习但最小化昂贵人工反馈的目标。

Abstract: Policy steering is an emerging way to adapt robot behaviors at deployment-time: a learned verifier analyzes low-level action samples proposed by a pre-trained policy (e.g., diffusion policy) and selects only those aligned with the task. While Vision-Language Models (VLMs) are promising general-purpose verifiers due to their reasoning capabilities, existing frameworks often assume these models are well-calibrated. In practice, the overconfident judgment from VLM can degrade the steering performance under both high-level semantic uncertainty in task specifications and low-level action uncertainty or incapability of the pre-trained policy. We propose uncertainty-aware policy steering (UPS), a framework that jointly reasons about semantic task uncertainty and low-level action feasibility, and selects an uncertainty resolution strategy: execute a high-confidence action, clarify task ambiguity via natural language queries, or ask for action interventions to correct the low-level policy when it is deemed incapable at the task. We leverage conformal prediction to calibrate the composition of the VLM and the pre-trained base policy, providing statistical assurances that the verifier selects the correct strategy. After collecting interventions during deployment, we employ residual learning to improve the capability of the pre-trained policy, enabling the system to learn continually but with minimal expensive human feedback. We demonstrate our framework through experiments in simulation and on hardware, showing that UPS can disentangle confident, ambiguous, and incapable scenarios and minimizes expensive user interventions compared to uncalibrated baselines and prior human- or robot-gated continual learning approaches. Videos can be found at https://jessie-yuan.github.io/ups/

</details>


### [57] [SignVLA: A Gloss-Free Vision-Language-Action Framework for Real-Time Sign Language-Guided Robotic Manipulation](https://arxiv.org/abs/2602.22514)
*Xinyu Tan,Ningwei Bai,Harry Gardener,Zhengyang Zhong,Luoyu Zhang,Liuhaichen Yang,Zhekai Duan,Monkgogi Galeitsiwe,Zezhi Tang*

Main category: cs.RO

TL;DR: 首个基于手语驱动的VLA框架，采用无注释词范式，将视觉手语手势直接映射为语义指令，实现直观包容的人机交互。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖注释词作为中间监督，存在标注成本高和信息丢失问题。需要更自然、可扩展的多模态人机交互方式，特别是在安全关键的实际环境中。

Method: 采用无注释词范式，直接映射视觉手语手势到语义指令。专注于实时字母级手指拼写接口，通过几何归一化、时序平滑和词汇精炼将连续手势流转换为连贯语言命令。

Result: 实验结果表明，该系统能在多样化交互场景中将手语指令有效映射为精确的机器人动作，展示了框架在实现可访问、可扩展多模态具身智能方面的潜力。

Conclusion: 该手语驱动的VLA框架通过无注释词范式降低了标注成本，避免了信息丢失，为构建直观包容的人机交互系统提供了可行方案，并支持未来扩展到词级和句级语义理解。

Abstract: We present, to our knowledge, the first sign language-driven Vision-Language-Action (VLA) framework for intuitive and inclusive human-robot interaction. Unlike conventional approaches that rely on gloss annotations as intermediate supervision, the proposed system adopts a gloss-free paradigm and directly maps visual sign gestures to semantic instructions. This design reduces annotation cost and avoids the information loss introduced by gloss representations, enabling more natural and scalable multimodal interaction.
  In this work, we focus on a real-time alphabet-level finger-spelling interface that provides a robust and low-latency communication channel for robotic control. Compared with large-scale continuous sign language recognition, alphabet-level interaction offers improved reliability, interpretability, and deployment feasibility in safety-critical embodied environments. The proposed pipeline transforms continuous gesture streams into coherent language commands through geometric normalization, temporal smoothing, and lexical refinement, ensuring stable and consistent interaction.
  Furthermore, the framework is designed to support future integration of transformer-based gloss-free sign language models, enabling scalable word-level and sentence-level semantic understanding. Experimental results demonstrate the effectiveness of the proposed system in grounding sign-derived instructions into precise robotic actions under diverse interaction scenarios. These results highlight the potential of the framework to advance accessible, scalable, and multimodal embodied intelligence.

</details>


### [58] [Metamorphic Testing of Vision-Language Action-Enabled Robots](https://arxiv.org/abs/2602.22579)
*Pablo Valle,Sergio Segura,Shaukat Ali,Aitor Arrieta*

Main category: cs.RO

TL;DR: 本文提出使用蜕变测试（Metamorphic Testing）来解决视觉-语言-动作（VLA）模型中的测试预言问题，通过定义蜕变关系模式来评估VLA机器人在输入变化时的行为一致性，无需为每个指令定义具体的测试预言。


<details>
  <summary>Details</summary>
Motivation: VLA模型面临严重的测试预言问题：一方面需要为每个指令定义测试预言，过程复杂且难以泛化；另一方面现有测试预言通常只关注任务完成与否的符号表示，无法评估任务执行质量。需要一种更通用、能自动检测多种故障的测试方法。

Method: 提出两种蜕变关系模式和五种具体蜕变关系，通过改变测试输入（如指令、视觉输入）来评估VLA机器人原始轨迹的变化。在五个VLA模型、两个仿真机器人和四个机器人任务上进行实证研究。

Result: 蜕变测试能有效缓解测试预言问题，自动检测多种类型的故障（包括未完成任务等）。更重要的是，提出的蜕变关系具有泛化性，可适用于不同VLA模型、机器人和任务，即使在缺乏测试预言的情况下也能应用。

Conclusion: 蜕变测试为解决VLA模型的测试预言问题提供了有效方法，提出的蜕变关系模式具有通用性和可扩展性，为VLA机器人系统的质量评估提供了新途径。

Abstract: Vision-Language-Action (VLA) models are multimodal robotic task controllers that, given an instruction and visual inputs, produce a sequence of low-level control actions (or motor commands) enabling a robot to execute the requested task in the physical environment. These systems face the test oracle problem from multiple perspectives. On the one hand, a test oracle must be defined for each instruction prompt, which is a complex and non-generalizable approach. On the other hand, current state-of-the-art oracles typically capture symbolic representations of the world (e.g., robot and object states), enabling the correctness evaluation of a task, but fail to assess other critical aspects, such as the quality with which VLA-enabled robots perform a task. In this paper, we explore whether Metamorphic Testing (MT) can alleviate the test oracle problem in this context. To do so, we propose two metamorphic relation patterns and five metamorphic relations to assess whether changes to the test inputs impact the original trajectory of the VLA-enabled robots. An empirical study involving five VLA models, two simulated robots, and four robotic tasks shows that MT can effectively alleviate the test oracle problem by automatically detecting diverse types of failures, including, but not limited to, uncompleted tasks. More importantly, the proposed MRs are generalizable, making the proposed approach applicable across different VLA models, robots, and tasks, even in the absence of test oracles.

</details>


### [59] [Rethinking the Practicality of Vision-language-action Model: A Comprehensive Benchmark and An Improved Baseline](https://arxiv.org/abs/2602.22663)
*Wenxuan Song,Jiayi Chen,Xiaoquan Sun,Huashuo Lei,Yikai Qin,Wei Zhao,Pengxiang Ding,Han Zhao,Tongxin Wang,Pengxu Hou,Zhide Zhong,Haodong Yan,Donglin Wang,Jun Ma,Haoang Li*

Main category: cs.RO

TL;DR: 提出CEBench基准和LLaVA-VLA模型，解决现有视觉-语言-动作模型参数过大、预训练成本高、适用性有限的问题，实现轻量化且强大的机器人代理。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作模型存在参数规模过大、预训练要求过高、对不同机器人本体适应能力有限的问题，限制了实际应用。需要更实用的解决方案。

Method: 1. 提出CEBench基准，包含模拟和真实世界的多样化机器人本体数据；2. 基于研究发现设计LLaVA-VLA模型，采用紧凑VLM骨干、多视角感知、本体感知标记化和动作分块；3. 采用两阶段训练范式（后训练+微调），避免昂贵预训练；4. 统一导航和操作的动作空间。

Result: LLaVA-VLA在多种机器人本体上展示了泛化能力和多功能性，在真实世界移动操作实验中成为首个端到端VLA模型，可在消费级GPU上部署。

Conclusion: 通过CEBench基准和LLaVA-VLA模型，显著提升了视觉-语言-动作模型的实用性，为轻量化、可部署的通用机器人代理提供了有效解决方案。

Abstract: Vision-Language-Action (VLA) models have emerged as a generalist robotic agent. However, existing VLAs are hindered by excessive parameter scales, prohibitive pre-training requirements, and limited applicability to diverse embodiments. To improve the practicality of VLAs, we propose a comprehensive benchmark and an improved baseline. First, we propose CEBench, a new benchmark spanning diverse embodiments in both simulation and the real world with consideration of domain randomization. We collect 14.4k simulated trajectories and 1.6k real-world expert-curated trajectories to support training on CEBench. Second, using CEBench as our testbed, we study three critical aspects of VLAs' practicality and offer several key findings. Informed by these findings, we introduce LLaVA-VLA, a lightweight yet powerful VLA designed for practical deployment on consumer-grade GPUs. Architecturally, it integrates a compact VLM backbone with multi-view perception, proprioceptive tokenization, and action chunking. To eliminate reliance on costly pre-training, LLaVA-VLA adopts a two-stage training paradigm including post-training and fine-tuning. Furthermore, LLaVA-VLA extends the action space to unify navigation and manipulation. Experiments across embodiments demonstrate the capabilities of generalization and versatility of LLaVA-VLA , while real-world mobile manipulation experiments establish it as the first end-to-end VLA model for mobile manipulation. We will open-source all datasets, codes, and checkpoints upon acceptance to foster reproducibility and future research.

</details>


### [60] [Unleashing the Potential of Diffusion Models for End-to-End Autonomous Driving](https://arxiv.org/abs/2602.22801)
*Yinan Zheng,Tianyi Tan,Bin Huang,Enguang Liu,Ruiming Liang,Jianlin Zhang,Jianwei Cui,Guang Chen,Kun Ma,Hangjun Ye,Long Chen,Ya-Qin Zhang,Xianyuan Zhan,Jingjing Liu*

Main category: cs.RO

TL;DR: 本研究提出Hyper Diffusion Planner（HDP），一种基于扩散模型的端到端自动驾驶规划器，通过大规模真实车辆数据和道路测试验证，在复杂真实世界场景中实现了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在决策任务中已广泛应用，但在端到端自动驾驶领域仍局限于模拟或实验室环境，其在复杂真实世界大规模场景中的潜力尚未充分探索。

Method: 1. 基于大量真实车辆数据进行系统化大规模研究；2. 深入分析扩散损失空间、轨迹表示和数据缩放对性能的影响；3. 提出强化学习后训练策略提升安全性；4. 开发Hyper Diffusion Planner（HDP）框架。

Result: 1. 在6个城市驾驶场景和200公里真实世界测试中，HDP相比基准模型实现了10倍性能提升；2. 成功在真实车辆平台上部署验证；3. 识别出影响端到端规划性能的关键因素。

Conclusion: 扩散模型经过适当设计和训练，可以作为复杂真实世界端到端自动驾驶任务的有效且可扩展的规划器，为自动驾驶领域提供了新的技术路径。

Abstract: Diffusion models have become a popular choice for decision-making tasks in robotics, and more recently, are also being considered for solving autonomous driving tasks. However, their applications and evaluations in autonomous driving remain limited to simulation-based or laboratory settings. The full strength of diffusion models for large-scale, complex real-world settings, such as End-to-End Autonomous Driving (E2E AD), remains underexplored. In this study, we conducted a systematic and large-scale investigation to unleash the potential of the diffusion models as planners for E2E AD, based on a tremendous amount of real-vehicle data and road testing. Through comprehensive and carefully controlled studies, we identify key insights into the diffusion loss space, trajectory representation, and data scaling that significantly impact E2E planning performance. Moreover, we also provide an effective reinforcement learning post-training strategy to further enhance the safety of the learned planner. The resulting diffusion-based learning framework, Hyper Diffusion Planner} (HDP), is deployed on a real-vehicle platform and evaluated across 6 urban driving scenarios and 200 km of real-world testing, achieving a notable 10x performance improvement over the base model. Our work demonstrates that diffusion models, when properly designed and trained, can serve as effective and scalable E2E AD planners for complex, real-world autonomous driving tasks.

</details>


### [61] [LeRobot: An Open-Source Library for End-to-End Robot Learning](https://arxiv.org/abs/2602.22818)
*Remi Cadene,Simon Aliberts,Francesco Capuano,Michel Aractingi,Adil Zouitine,Pepijn Kooijmans,Jade Choghari,Martino Russi,Caroline Pascal,Steven Palma,Mustafa Shukor,Jess Moss,Alexander Soare,Dana Aubakirova,Quentin Lhoest,Quentin Gallouédec,Thomas Wolf*

Main category: cs.RO

TL;DR: lerobot是一个开源的机器人学习库，整合了整个机器人学习栈，从底层电机控制到大规模数据集处理，支持多种硬件平台和算法，旨在降低机器人学习门槛。


<details>
  <summary>Details</summary>
Motivation: 机器人学习领域发展迅速，但现有工具往往碎片化、闭源且只关注特定子组件，这阻碍了整个领域的快速发展。需要一种整合整个机器人学习栈的开放工具。

Method: 开发了lerobot开源库，整合从底层电机控制通信到大规模数据集收集、存储和流式传输的完整机器人学习栈。支持多种硬件平台，实现了多种先进机器人学习算法，并包含通用异步推理栈。

Result: 创建了一个功能完整的开源机器人学习库，支持可扩展的学习方法，能够直接通过更多数据和计算来改进性能，为机器人学习研究提供了可复现的平台。

Conclusion: lerobot降低了机器人学习的研究门槛，为可复现、先进的机器人学习提供了平台，强调可扩展性、开放性和可访问性，有助于推动整个机器人学习领域的发展。

Abstract: Robotics is undergoing a significant transformation powered by advances in high-level control techniques based on machine learning, giving rise to the field of robot learning. Recent progress in robot learning has been accelerated by the increasing availability of affordable teleoperation systems, large-scale openly available datasets, and scalable learning-based methods. However, development in the field of robot learning is often slowed by fragmented, closed-source tools designed to only address specific sub-components within the robotics stack. In this paper, we present \texttt{lerobot}, an open-source library that integrates across the entire robot learning stack, from low-level middleware communication for motor controls to large-scale dataset collection, storage and streaming. The library is designed with a strong focus on real-world robotics, supporting accessible hardware platforms while remaining extensible to new embodiments. It also supports efficient implementations for various state-of-the-art robot learning algorithms from multiple prominent paradigms, as well as a generalized asynchronous inference stack. Unlike traditional pipelines which heavily rely on hand-crafted techniques, \texttt{lerobot} emphasizes scalable learning approaches that improve directly with more data and compute. Designed for accessibility, scalability, and openness, \texttt{lerobot} lowers the barrier to entry for researchers and practitioners to robotics while providing a platform for reproducible, state-of-the-art robot learning.

</details>


### [62] [DySL-VLA: Efficient Vision-Language-Action Model Inference via Dynamic-Static Layer-Skipping for Robot Manipulation](https://arxiv.org/abs/2602.22896)
*Zebin Yang,Yijiahao Qi,Tong Xie,Bo Yu,Shaoshan Liu,Meng Li*

Main category: cs.RO

TL;DR: DySL-VLA 是一个动态跳过 VLA 模型层的框架，通过识别动作重要性来降低计算成本，在保持准确性的同时实现显著加速。


<details>
  <summary>Details</summary>
Motivation: 当前 VLA 模型在机器人任务中表现出色，但高计算成本阻碍了实时应用。研究发现，任务中不同动作的重要性不同，关键步骤需要高精度，而不重要步骤可以容忍更多方差。

Method: 提出 DySL-VLA 框架，将层分为信息层（始终执行）和增量层（可选择性跳过）。设计先验-后验跳过指导机制决定何时开始跳层，并采用跳过感知的两阶段知识蒸馏算法训练标准 VLA 转换为 DySL-VLA。

Result: 在 Calvin 数据集上，DySL-VLA 相比 Deer-VLA 实现了 2.1% 的成功长度提升，同时训练参数减少 85.7 倍，在相同准确度下相比 RoboFlamingo 基线提供 3.75 倍加速。

Conclusion: DySL-VLA 通过动态层跳过机制有效解决了 VLA 模型的计算成本问题，在保持甚至提升性能的同时实现了显著的速度提升，为实时应用提供了可行方案。

Abstract: Vision-Language-Action (VLA) models have shown remarkable success in robotic tasks like manipulation by fusing a language model's reasoning with a vision model's 3D understanding. However, their high computational cost remains a major obstacle for real-world applications that require real-time performance. We observe that the actions within a task have varying levels of importance: critical steps demand high precision, while less important ones can tolerate more variance. Leveraging this insight, we propose DySL-VLA, a novel framework that addresses computational cost by dynamically skipping VLA layers based on each action's importance. DySL-VLA categorizes its layers into two types: informative layers, which are consistently executed, and incremental layers, which can be selectively skipped. To intelligently skip layers without sacrificing accuracy, we invent a prior-post skipping guidance mechanism to determine when to initiate layer-skipping. We also propose a skip-aware two-stage knowledge distillation algorithm to efficiently train a standard VLA into a DySL-VLA. Our experiments indicate that DySL-VLA achieves 2.1% improvement in success length over Deer-VLA on the Calvin dataset, while simultaneously reducing trainable parameters by a factor of 85.7 and providing a 3.75x speedup relative to the RoboFlamingo baseline at iso-accuracy. Our code is available on https://github.com/PKU-SEC-Lab/DYSL_VLA.

</details>


### [63] [Sapling-NeRF: Geo-Localised Sapling Reconstruction in Forests for Ecological Monitoring](https://arxiv.org/abs/2602.22731)
*Miguel Ángel Muñoz-Bañón,Nived Chebrolu,Sruthi M. Krishna Moorthy,Yifu Tao,Fernando Torres,Roberto Salguero-Gómez,Maurice Fallon*

Main category: cs.RO

TL;DR: 提出一种融合NeRF、LiDAR SLAM和GNSS的三级表示管道，用于实现可重复、地理定位的树苗生态监测，相比传统方法能更精确地捕捉树苗的细尺度结构特征。


<details>
  <summary>Details</summary>
Motivation: 现有3D感知方法（TLS、MLS、传统摄影测量）难以捕捉树苗的细尺度结构特征（如细枝、密集叶片），且缺乏尺度一致性，无法满足长期监测需求。隐式3D重建方法（如NeRF、3DGS）虽然前景广阔，但无法恢复真实场景尺度且缺乏精确地理定位能力。

Method: 提出三级表示管道：1）GNSS实现粗略的地球坐标系定位；2）LiDAR SLAM提供厘米级精确定位和重建；3）NeRF实现以对象为中心的单个树苗密集重建。该融合方法支持可重复的定量评估和长期监测。

Result: 在英国Wytham Woods和芬兰Evo森林样地的实验表明，相比TLS，该方法能更精确地捕捉树苗的茎干高度、分枝模式和叶木比。能够对高度0.5-2米的树苗进行原位测量，获得准确的茎干骨架和叶片分布数据。

Conclusion: 该管道为生态学家提供了更丰富的结构和定量数据，支持森林动态分析。通过融合多传感器数据，实现了可重复、地理定位的树苗生态监测，解决了现有方法的局限性。

Abstract: Saplings are key indicators of forest regeneration and overall forest health. However, their fine-scale architectural traits are difficult to capture with existing 3D sensing methods, which make quantitative evaluation difficult. Terrestrial Laser Scanners (TLS), Mobile Laser Scanners (MLS), or traditional photogrammetry approaches poorly reconstruct thin branches, dense foliage, and lack the scale consistency needed for long-term monitoring. Implicit 3D reconstruction methods such as Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) are promising alternatives, but cannot recover the true scale of a scene and lack any means to be accurately geo-localised. In this paper, we present a pipeline which fuses NeRF, LiDAR SLAM, and GNSS to enable repeatable, geo-localised ecological monitoring of saplings. Our system proposes a three-level representation: (i) coarse Earth-frame localisation using GNSS, (ii) LiDAR-based SLAM for centimetre-accurate localisation and reconstruction, and (iii) NeRF-derived object-centric dense reconstruction of individual saplings. This approach enables repeatable quantitative evaluation and long-term monitoring of sapling traits. Our experiments in forest plots in Wytham Woods (Oxford, UK) and Evo (Finland) show that stem height, branching patterns, and leaf-to-wood ratios can be captured with increased accuracy as compared to TLS. We demonstrate that accurate stem skeletons and leaf distributions can be measured for saplings with heights between 0.5m and 2m in situ, giving ecologists access to richer structural and quantitative data for analysing forest dynamics.

</details>
